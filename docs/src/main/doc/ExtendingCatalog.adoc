= Extending DDF Catalog Application
include::../classes/config.adoc[]

== Overview

The DDF Catalog provides a framework for storing, searching, processing, and transforming information.  Clients typically perform query, create, read, update, and delete (QCRUD) operations against the Catalog.  At the core of the Catalog functionality is the Catalog Framework, which routes all requests and responses through the system, invoking additional processing per the system configuration.

This guide supports developers creating extensions of the existing framework.

=== Whitelist

The following packages have been exported by the DDF Catalog application and are approved for use by third parties:

* ddf.catalog

* ddf.catalog.util 

* ddf.catalog.event

* ddf.catalog

* ddf.catalog.validation

* ddf.catalog.source

* ddf.catalog.filter

* ddf.catalog.federation

* ddf.catalog.plugin

* ddf.catalog.operation

* ddf.catalog.transform

* ddf.catalog.data

* ddf.catalog.resource

* ddf.measure

* ddf.catalog.filter.delegate

* ddf.catalog.impl.filter

* ddf.services.schematron

* ddf.geo.formatter

== Catalog Application Services

As an OSGi system, DDF does Intra-module conversations via services. The following summarizes DDF internal services within the Catalog application.

=== Catalog Framework

The CatalogFramework is the routing mechanism between catalog components that provides integration points for the Catalog Plugins. An endpoint invokes the active Catalog Framework, which calls any configured Pre-query or Pre-ingest plug-ins. The selected federation strategy calls the active Catalog Provider and any connected or federated sources. Then, any Post-query or Post-ingest plug-ins are invoked. Finally, the appropriate response is returned to the calling endpoint.

=== Sources

A source is a system consisting of a catalog containing Metacards.

==== CatalogProvider

The Catalog Provider is an API is used to interact with data providers, such as files systems or databases, to query, create, update, or delete data. The provider also translates between DDF objects and native data formats.

==== ConnectedSource

A Connected Source is a local or remote source that is always included in every local and enterprise query, but is hidden from being queried individually.

==== FederatedSource

A Federated Source is a remote source that can be optionally included or excluded from queries.

==== Plugins

Plugins are additional tools to use to add additional business logic at certain points, depending on the type of plugin. Plugins can be designed to run before or after certain processes. They are often used for validation, optimization, or logging.

===== "Pre-" Plugins

These plugins are executed before an action is taken.
[cols="2*", options="header"]
|===

|Plugin
|Description

|Pre-IngestPlugin
|Performs any changes to a resource prior to ingesting it.

|Pre-Query Plugin
|Performs any changes to query before executing.

|Pre-Resource Plugin
|Performs any changes to a resource associated with a metacard prior to download.

|Pre-Subscription Plugin 
|Performs any changes before creating a subscription.

|Pre-Delivery Plugin
|Performs any changes before delivered a subscribed event.

|===

====== “Post-“ Plugins
[cols="2*", options="header"]
|===

|Plugin
|Description

|Post-Ingest Plugin
|Performs actions after ingest is completed.

|Post-Query Plugin
|Performs any changes to response after query completes.

|Post-Get Resource Plugin   
|performs any changes to a resource after download

|===

==== Transformers

Transformers are used to alter the format of a resource or its metadata to or from the catalog’s metacard format

[cols="2*", options="header"]
|===

|Transformer
|Description

|Input Transformers
|create metacards from input.

|Metacard Transformers
|translates a metacard from catalog metadata to a specific data format.

|Query Response Transformers
|translates a list of Result objects to a desired format.

|===

== Catalog Development Fundamentals

This section introduces the fundamentals of working with the Catalog API the OGC Filter for Queries.

=== Simple Catalog API Implementations

The Catalog API implementations, which are denoted with the suffix of 
`Impl`
 on the Java file names, have multiple purposes and uses.

* First, they provide a good starting point for other developers to extend functionality in the framework. For instance, extending the `MetacardImpl` allows developers to focus less on the inner workings of DDF and more on the developer's intended purposes and objectives. 

* Second, the Catalog API Implementations display the proper usage of an interface and an interface's intentions.  Also, they are good code examples for future implementations. If a developer does not want to extend the simple implementations, the developer can at least have a working code reference to base future development.

==== Use of the Whiteboard Design Pattern

The DDF Catalog makes extensive use of the Whiteboard Design Pattern. Catalog Components are registered as services in the OSGi Service Registry, and the Catalog Framework or any other clients tracking the OSGi Service Registry are automatically notified by the OSGi Framework of additions and removals of relevant services.

The Whiteboard Design Pattern is a common OSGi technique that is derived from a technical whitepaper provided by the OSGi Alliance in 2004. It is recommended to use the Whiteboard pattern over the Listener pattern in OSGi because it provides less complexity in code (both on the client and server sides), fewer deadlock possibilities than the Listener pattern, and closely models the intended usage of the OSGi framework.

=== Working with Queries

Clients use `ddf.catalog.operation.Query` objects to describe which metacards are needed from Sources. Query objects have two major components:

* Filter 
* Query Options

A Source uses the Filter criteria constraints to find the requested set of metacards within its domain of metacards. The Query Options are used to further restrict the 
Filter's set of requested metacards. See the Creating Filters section for more on Filters.

==== Query Options
[cols="2*", options="header"]
|===
|Option
|Description

|StartIndex
|1-based index that states which metacard the Source should return first out of the requested metacards.

|PageSize
|Represents the maximum amount of metacards the Source should return.

|SortBy
|Determines how the results are sorted and on which property.

|RequestsTotalResultsCount
|Determines whether the total number of results should be returned.

|TimeoutMillis
|The amount of time in milliseconds before the query is to be abandoned.

|===

==== Creating a query
The easiest way to create a `Query` is to use `ddf.catalog.operation.QueryImpl` object. It is first necessary to create an OGC Filter object then set the Query Options after `QueryImpl` has been constructed.

.QueryImpl Example 1
[source,java,linenums]
----
/*
  Builds a query that requests a total results count and
  that the first record to be returned is the second record found from
  the requested set of metacards.
 */ 

 String property = ...;

 String value = ...;  

 org.geotools.filter.FilterFactoryImpl filterFactory = new FilterFactoryImpl() ;

 QueryImpl query = new QueryImpl( filterFactory.equals(filterFactory.property(property),

filterFactory.literal(value))) ;

 query.setStartIndex(2) ;

 query.setRequestsTotalResultsCount(true); 
----
==== Evaluating a query

Every Source must be able to evaluate a Query object. Nevertheless, each Source
 could evaluate the Query differently depending on what that Source supports as to properties and query capabilities. For instance, a common property all Sources understand is id, but a Source could possibly store frequency values under the property name "frequency." Some Sources may not support frequency property inquiries and will
throw an error stating it cannot interpret the property. In addition, some Sources might be able to handle spatial operations, while others might not. A developer should consult a Source's documentation for the limitations, capabilities, and properties that a 
Source can support.

=== Working with Filters

An OGC Filter is a Open Geospatial Consortium (OGC) standard (
http://www.opengeospatial.org/standards/filter
) that describes a query expression
in terms of Extensible Markup Language (XML) and key-value pairs (KVP). The DDF Catalog Framework does not use the XML representation of
the OGC Filter standard. DDF instead utilizes the Java implementation provided by Geotools (
http://geotools.org/
). Geotools provides Java
equivalent classes for OGC Filter XML elements. Geotools originally provided the standard Java classes for the OGC Filter Encoding 1.0 under the
package name 
`org.opengis.filter`. The same package name is used today and is currently used by DDF.  Java developers do not parse or
view the XML representation of a 
Filter
 in DDF. Instead, developers use only the Java objects to complete query tasks.

Note that the ddf.catalog.operation.Query interface extends the org.opengis.filter.Filter interface, which means that a Query object is an OGC Java Filter with Query Options.

.A Query is an OGC Filter
[source,java]
----
public interface Query extends Filter 
----
=== Using Filters

==== FilterBuilder API

To abstract developers from the complexities of working with the Filter interface directly and implementing the DDF Profile of the Filter specification, the DDF Catalog includes an API, primarily in ddf.filter, to build Filters using a fluent API.

To use the FilterBuilder API, an instance of ddf.filter.FilterBuilder should be used via the OSGi registry.  Typically, this will be injected via a dependency injection framework.  Once an instance of FilterBuilder is available, methods can be called to create and combine Filters.

[TIP]
====
The fluent API is best accessed using an IDE that supports code-completion.  For additional details, refer to the Catalog API Javadoc.
====

==== Boolean Operators

`FilterBuilder.allOf(Filter ...)`:: creates a new Filter that requires all provided Filters are satisfied (Boolean AND), either from a List or Array of Filter instances.

`FilterBuilder.anyOf(Filter ...)`:: creates a new Filter that requires all provided Filters are satisfied (Boolean OR), either from a List or Array of Filter instances.

`FilterBuilder.not(Filter filter)`:: creates a new Filter that requires the provided Filter must not be match (Boolean NOT).

==== Attribute

`FilterBuilder.attribute(String attributeName)` begins a fluent API for creating an Attribute-based Filter, i.e., a Filter that matches on Metacards with Attributes of a particular value.

==== XPath

`FilterBuilder.xpath(String xpath)` begins a fluent API for creating an XPath-based Filter, i.e., a Filter that matches on Metacards with Attributes of type XML that match when evaluating a provided XPath selector.

==== Contextual Operators

[source,java,linenums]
----
FilterBuilder.attribute(attributeName).is().like().text(String contextualSearchPhrase);
FilterBuilder.attribute(attributeName).is().like().caseSensitiveText(StringcaseSensitiveContextualSearchPhrase);
FilterBuilder.attribute(attributeName).is().like().fuzzyText(String fuzzySearchPhrase);
---- 

==== Directly Implementing the Filter (Advanced)
[WARNING]
====
Implementing the Filter interface directly is only for extremely advanced use cases and is highly discouraged. Instead, use of the DDF-specific FilterBuilder API is recommended.
====

Developers create a `Filter` object in order to filter or constrain the amount of records returned from a `Source`. The OGC Filter Specification has several types of filters that can be combined in a tree-like structure to describe the set of metacards that should be returned. 

==== Categories of Filters

* Comparison Operators
* Logical Operators
* Expressions
* Literals
* Functions
* Spatial Operators
* Temporal Operators

==== Units of Measure

According to the OGC Filter Specifications http://www.opengeospatial.org/standards/filter[09-026r1] and http://www.opengeospatial.org/standards/filter[04-095], units of measure can be expressed as a URI. To fulfill that requirement, DDF utilizes the Geotools class `org.geotools.styling.UomOgcMapping` for spatial filters requiring a standard for units of measure for scalar distances. Essentially, the 
UomOgcMapping
 maps the OGC Symbology Encoding (
http://www.opengeospatial.org/standards/symbol
) standard URIs to Java Units. This class provides three options for units of measure: 

* FOOT
* METRE
* PIXEL

DDF only supports FOOT and METRE since they are the most applicable to scalar distances.

==== Creating Filters

The common way to create a `Filter` is to use the Geotools `FilterFactoryImpl` object, which provides Java implementations for the various types of filters in the Filter Specification. Examples are the easiest way to understand how to properly create a `Filter` and a `Query`. 

[NOTE]
====
Refer to the Geotools javadocz for more information on `FilterFactoryImpl`.
====

The example below illustrates creating a query, and thus an OGC Filter, that does a case-insensitive search for the phrase "mission" in the entire metacard's text. Note that the OGC `PropertyIsLike` Filter is used for this simple contextual query.

===== Example Creating-Filters-1 
.Simple Contextual Search
[source,java,linenums]
----
org.opengis.filter.FilterFactory filterFactory = new FilterFactoryImpl() ;
boolean isCaseSensitive = false ; 

String wildcardChar = "*" ; // used to match zero or more characters
String singleChar = "?" ; // used to match exactly one character
String escapeChar = "\\" ; // used to escape the meaning of the wildCard, singleChar,
and the escapeChar itself

String searchPhrase = "mission" ;
org.opengis.filter.Filter propertyIsLikeFilter = 
    filterFactory.like(filterFactory.property(Metacard.ANY_TEXT), searchPhrase, wildcardChar, singleChar, escapeChar, isCaseSensitive);  
ddf.catalog.operation.QueryImpl query = new QueryImpl( propertyIsLikeFilter );
----

The example below illustrates creating an absolute temporal query, meaning the query is searching for Metacards whose modified timestamp occurred during a specific time range. Note that this query uses the `During` OGC Filter for an absolute temporal query.


===== Example Creating-Filters-2

.Absolute Temporal Search
[source,java,linenums]
----
org.opengis.filter.FilterFactory filterFactory = new FilterFactoryImpl() ;
org.opengis.temporal.Instant startInstant = new org.geotools.temporal.object.DefaultInstant(new DefaultPosition(start));

org.opengis.temporal.Instant endInstant = new org.geotools.temporal.object.DefaultInstant(new DefaultPosition(end));

org.opengis.temporal.Period period =  new org.geotools.temporal.object.DefaultPeriod(startInstant, endInstant);

String property = Metacard.MODIFIED ; // modified date of a metacard

org.opengis.filter.Filter filter = filterFactory.during( filterFactory.property(property), filterFactory.literal(period)  );
 
ddf.catalog.operation.QueryImpl query = new QueryImpl(filter) ;
----

===== Contextual Searches

Most contextual searches can be expressed using the `PropertyIsLike` filter. The special haracters that have meaning in a `PropertyIsLike` filter are the wildcard, single wildcard, and escape characters (see Example Creating-Filters-1).

====== PropertyIsLike Special Characters
[cols="2*", options="header"]
|===
|Character
|Description

|Wildcard
|Matches zero or more characters.

|Single Wildcard
|Matches exactly one character.

|Escape
|Escapes the meaning of the Wildcard, Single Wildcard, and the Escape character itself
|===
Characters and words, such as `AND`, `&`, `and`, `OR`, `|`, `or`, `NOT`, `~`, `not`, `{`, and `}`, are treated as literals in a `PropertyIsLike` filter. In order to create equivalent logical queries, a developer must instead use the Logical Operator filters {`AND`, `OR`, `NOT`}. The Logical Operator filters can be combined together with `PropertyIsLike` filters to create a tree that represents the search phrase expression. 

===== Example Creating-Filters-3
.Creating the search phrase "mission and planning"
[source,java,linenums]
----
org.opengis.filter.FilterFactory filterFactory = new FilterFactoryImpl() ; 

boolean isCaseSensitive = false ; 
 
String wildcardChar = "*" ; // used to match zero or more characters
String singleChar = "?" ; // used to match exactly one character
String escapeChar = "\\" ; // used to escape the meaning of the wildCard, singleChar, and the escapeChar itself

Filter filter = 
    filterFactory.and(
       filterFactory.like(filterFactory.property(Metacard.METADATA), "mission" ,
wildcardChar, singleChar, escapeChar, isCaseSensitive),
       filterFactory.like(filterFactory.property(Metacard.METADATA), "planning" ,
wildcardChar, singleChar, escapeChar, isCaseSensitive) 
    );

ddf.catalog.operation.QueryImpl query = new QueryImpl( filter ); 
---- 
====== Tree View of Example Creating-Filters-3 

Filters used in DDF can always be represented in a tree diagram.

[ditaa,tree1, png]
....
+--------------------\
|cEEE /-------\      |
|     |  And  |      |
|     \-+---+-/      |
|       |   |        |
|     +-+   +-+      |
|     |       |      |
|     v       v      |
|/-------\ /--------\|
||mission| |planning||
|\-------/ \--------/|
\--------------------/
....

====== XML View of Example Creating-Filters-3

Another way to view this type of Filter is through an XML model, which is shown below.

.Pseudo XML of Example Creating-Filters-3
[source,xml,linenums]
----
<Filter>
   <And> 
      <PropertyIsLike wildCard="*" singleChar="?" escapeChar="\">
           <PropertyName>metadata</PropertyName>
           <Literal>mission</Literal>
      </PropertyIsLike>
      <PropertyIsLike wildCard="*" singleChar="?" escapeChar="\">
           <PropertyName>metadata</PropertyName>
           <Literal>planning</Literal>
      </PropertyIsLike> 
   <And> 
</Filter>
----
Using the Logical Operators and 
`PropertyIsLike`
 filters, a developer can create a whole language of search phrase expressions.

===== Fuzzy Operation 

DDF only supports one custom function. The Filter specification does not include a fuzzy operator, so a Filter function was created to represent a fuzzy operation. The function and class is called `FuzzyFunction`, which is used by clients to notify the Sources to perform a fuzzy search. The syntax expected by providers is similar to the Fuzzy Function. Refer to the example below.

[source,java,linenums]
----
String wildcardChar = "*" ; // used to match zero or more characters
String singleChar = "?" ; // used to match exactly one character
String escapeChar = "\\" ; // used to escape the meaning of the wildCard, singleChar 

boolean isCaseSensitive = false ; 

Filter fuzzyFilter = filterFactory.like(
     new ddf.catalog.impl.filter.FuzzyFunction(
          Arrays.asList((Expression) (filterFactory.property(Metacard.ANY_TEXT))),
          filterFactory.literal("")), 
     searchPhrase, 
     wildcardChar, 
     singleChar, 
     escapeChar, 
     isCaseSensitive);

QueryImpl query = new QueryImpl(fuzzyFilter); 
----

==== Parsing Filters

According to the OGC Filter Specification (04-095: http://www.opengeospatial.org/standards/filter), a "(filter expression) representation can be...parsed and then transformed into whatever target language is required to retrieve or modify object instances stored in some persistent object store." Filters can be thought of as the `WHERE` clause for a SQL SELECT statement to "fetch data stored in a SQL-based relational database." 

Sources can parse OGC Filters using the `FilterAdapter` and `FilterDelegate`. See Developing a Filter Delegate for more details on implementing a new `FilterDelegate`. This is the preferred way to handle OGC Filters in a consistent manner.

Alternately, `org.opengis.filter.Filter` implementations can be parsed using implementations of the interface `org.opengis.filter.FilterVisitor`. The `FilterVisitor` uses the Visitor pattern (`http://www.oodesign.com/visitor-pattern.html`). Essentially, `FilterVisitor` instances "visit" each part of the `Filter` tree allowing developers to implement logic to handle the filter's operations. Geotools 8 includes implementations of the `FilterVisitor` interface. The `DefaultFilterVisitor`, as an example, provides only business logic to visit every node in the `Filter` tree. The `DefaultFilterVisitor` methods are meant to be overwritten with the correct business logic.  The simplest approach when using `FilterVisitor` instances is to build the appropriate query syntax for a target language as each part of the `Filter` is visited. For instance, when given an incoming `Filter` object to be evaluated against a RDBMS, a `CatalogProvider instance could use a `FilterVisitor` to interpret each filter operation on the `Filter` object and translate those operations into SQL.  The `FilterVisitor` may be needed to support `Filter` functionality not currently handled by the `FilterAdapter` and `FilterDelegate` reference implementation.

===== Examples

====== Interpreting a Filter to Create SQL

If the `FilterAdapter` encountered or "visited" a `PropertyIsLike` filter with its property assigned as `title` and its literal expression assigned as `mission`, the `FilterDelegate` could create the proper SQL syntax similar to title LIKE mission.

.Figure Parsing-Filters1
[ditaa,tree2,png]
....
+-------------------------\
|    /----------------\   |
|    | PropertyIsLike |   |
|    \----------------/   |
| cEEE      |  |          |
|      /----/  \----\     |
|      |            |     |
|      v            v     |
|/----------\  /---------\|
||Property- |  |Literal- ||
|| title    |  | mission ||
|\----------/  \---------/|
\-------------------------/
....

====== Interpreting a Filter to Create XQuery

If the 
`FilterAdapter`
 encountered an 
`OR` filter, such as in Figure Parsing-Filters2 and the target language was XQuery, the `FilterDelegate` could yield an expression such as 
----
ft:query(//inventory:book/@subject,'math') union 
ft:query(//inventory:book/@subject,'science').
----

.Figure Parsing-Filters2
[ditaa, tree3, png]
....	
+---------------------------------------------------\
|                       /----\                      |
|  cEEE                 | OR |                      |
|                       \----/                      |
|                        |  |                       |
|             /----------/  \----------\            |
|             |                        |            |
|             v                        v            |
|    /----------------\        /----------------\   |
|    | PropertyIsLike |        | PropertyIsLike |   |
|    \----------------/        \----------------/   |
|           |  |                      |  |          |
|      /----/  \----\            /----/  \----\     |
|      |            |            |            |     |
|      v            v            v            v     |
|/----------\  /---------\  /---------\  /---------\|
||Property- |  |Literal- |  |Property-|  |Literal- ||
|| title    |  | mission |  | Subject |  | science ||
|\----------/  \---------/  \---------/  \---------/|
\---------------------------------------------------/
....


====== FilterAdapter/Delegate Process for Figure Parsing-Filters2

. `FilterAdapter` visits the `OR` filter first.
. `OR` filter visits its children in a loop. 
. The first child in the loop that is encountered is the LHS `PropertyIsLike`.
. The `FilterAdapter` will call the `FilterDelegate` `PropertyIsLike`method with the LHS property and literal.
. The LHS `PropertyIsLike` delegate method builds the XQuery syntax that makes sense for this particular underlying object store. In this case, the _subject_ property is specific to this XML database, and the business logic maps the _subject_ property to its index at `//inventory:book/@subject` Note that `ft:query` in this instance is a custom XQuery module for this specific XML database that does full text searches.
. The `FilterAdapter` then moves back to the `OR` filter, which visits its second child.
. The `FilterAdapter` will call the `FilterDelegate` `PropertyIsLike` method with the RHS property and literal.
. The RHS `PropertyIsLike` delegate method builds the XQuery syntax that makes sense for this particular underlying object store. In this case, the _subject_ property is specific to this XML database, and the business logic maps the _subject_ property to its index at `//inventory:book/@subject` Note that `ft:query` in this instance is a custom XQuery module for this specific XML database that does full text searches.
. The `FilterAdapter` then moves back to its `OR Filter which is now done with its children.
. It then collects the output of each child and sends the list of results to the `FilterDelegate OR` method.
. The final result object will be returned from the `FilterAdapter` adapt method.

====== FilterVisitor Process for Figure Parsing-Filters2

. FilterVisitor visits the `OR` filter first.
. `OR` filter visits its children in a loop. 
. The first child in the loop that is encountered is the LHS `PropertyIsLike`.
. The LHS `PropertyIsLike` builds the XQuery syntax that makes sense for this particular underlying object store. In this case, the _subject_ property is specific to this XML database, and the business logic maps the _subject_ property to its index at `//inventory:book/@subject`. Note that `ft:query` in this instance is a custom XQuery module for this specific XML database that does full text searches.
. The FilterVisitor then moves back to the `OR` filter, which visits its second child.
. The RHS `PropertyIsLike` builds the XQuery syntax that makes sense for this particular underlying object store. In this case, the _subject_ property is specific to this XML database, and the business logic maps the _subject_ property to its index at `//inventory:book/@subject`. Note that `ft:query` in this instance is a custom XQuery module for this specific XML database that does full text searches.
. The FilterVisitor then moves back to its `OR` filter, which is now done with its children. It then collects the output of each child and could potentially execute the following code to produce the above expression.

[source,java,linenums]
----
public visit( Or filter, Object data) {
... 
   /* the equivalent statement for the OR filter in this domain (XQuery) */
   xQuery = childFilter1Output + " union " + childFilter2Output;
... 
} 
----
==== Filter Profile

===== Role of the OGC Filter

Both Queries and Subscriptions extend the OGC GeoAPI Filter interface.

The Filter Builder and Adapter do not fully implement the OGC Filter Specification.  The filter support profile contains suggested filter to metacard type mappings.  For example, even though a Source could support a PropertyIsGreaterThan filter on XML_TYPE, it would not likely be useful.

===== Catalog Filter Profile

====== Metacard Attribute To Type Mapping

The filter profile maps filters to metacard types.  The following table displays the common metacard attributes with their respective types for reference.

[cols="2*", options="header"]
|===

|Metacard Attribute
|Metacard Type

|ANY_DATE
|DATE_TYPE

|ANY_GEO
|GEO_TYPE

|ANY_TEXT
|STRING_TYPE

|CONTENT_TYPE
|STRING_TYPE

|CONTENT_TYPE_VERSION
|STRING_TYPE

|CREATED
|DATE_TYPE

|EFFECTIVE
|DATE_TYPE

|GEOGRAPHY
|GEO_TYPE

|ID
|STRING_TYPE

|METADATA
|XML_TYPE

|MODIFIED
|DATE_TYPE

|RESOURCE_SIZE
|STRING_TYPE

|RESOURCE_URI
|STRING_TYPE

|SOURCE_ID
|STRING_TYPE

|TARGET_NAMESPACE
|STRING_TYPE

|THUMBNAIL
|BINARY_TYPE

|TITLE
|STRING_TYPE

|===

====== Comparison Operators

Comparison operators compare the value associated with a property name with a given Literal value.  Endpoints and sources should try to use metacard types other than the object type.  The object type only supports backwards compatibility with `java.net.URI`.  Endpoints that send other objects will not be supported by standard sources. The following table maps the metacard types to supported comparison operators.

[cols="12*", options="header"]
|===

|PropertyIs
|Between
|EqualTo
|GreaterThan
|GreaterThan
|OrEqualTo
|LessThan
|LessThan
|OrEqualTo
|Like
|NotEqualTo
|Null

|BINARY_TYPE
|
|*X*
|
|
|
|
|
|
|
|
|

|BOOLEAN_TYPE
|
|*X*
|
|
|
|
|
|
|
|
|

|DATE_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|DOUBLE_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|FLOAT_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

 

|GEO_TYPE
|
|
|
|
|
|
|
|
|
|
|*X*

|INTEGER_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|LONG_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|OBJECT_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|SHORT_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*

|STRING_TYPE
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*
|*X*

|XML_TYPE
|
|*X*
|
|
|
|
|
|
|*X*
|
|*X*
 
|===
The following table describes each comparison operator.

[cols="2*", options="header"]
|===

|Operator
|Description

|PropertyIsBetween
|Lower <= Property <= Upper

|PropertyIsEqualTo
|Property == Literal

|PropertyIsGreaterThan
|Property > Literal

|PropertyIsGreaterThanOrEqualTo
|Property >= Literal

|PropertyIsLessThan
|Property < Literal

|PropertyIsLessThanOrEqualTo
|Property <= Literal

|PropertyIsLike
|Property LIKE Literal

Equivalent to SQL "like" 

|PropertyIsNotEqualTo
|Property != Literal

|PropertyIsNull
|Property == null

|===
====== Logical Operators
Logical operators apply Boolean logic to one or more child filters.

[cols="4*", options="header"]
|===

|
|And
|Not
|Or

|Supported Filters
|*X*
|*X*
|*X*

|===

====== Temporal Operators
Temporal operators compare a date associated with a property name to a given Literal date or date range.  The following table displays the supported temporal operators.
[cols="12*", options="header"]
|===
|
|After
|AnyInteracts
|Before
|Begins
|BegunBy
|During
|EndedBy
|Meets
|MetBy
|OverlappedBy
|TContains

|DATE_TYPE
|*X*
|
|*X*
|
|
|*X*
|
|
|
|
|

|===

The following table describes each temporal operator. Literal values can be either date instants or date periods.
[cols="2*", options="header"]
|===

|Operator
|Description

|After
|Property > (Literal \|\| Literal.end)

|Before
|Property < (Literal \|\| Literal.start)

|During
|Literal.start < Property < Literal.end

|===
====== Spatial Operators

Spatial operators compare a geometry associated with a property name to a given Literal geometry.  The following table displays the supported spatial operators.

[cols="11*", options="headers"]
|===

|BBox
|Beyond
|Contains
|Crosses
|Disjoint
|Equals
|DWithin
|Intersects
|Overlaps
|Touches
|Within

|GEO_TYPE
|
|*X*
|*X*
|*X*
|*X*
|
|*X*
|*X*
|*X*
|

|===

The following table describes each spatial operator.  Geometries are usually represented as Well-Known Text (WKT).

[cols="2*", options="header"]
|===

|Operator
|Description

|Beyond
|Property geometries beyond given distance of Literal geometry

|Contains
|Property geometry contains Literal geometry

|Crosses
|Property geometry crosses Literal geometry

|Disjoint
|Property geometry direct positions are not interior to Literal geometry

|DWithin
|Property geometry lies within distance to Literal geometry

|Intersects
|Property geometry intersects Literal geometry; opposite to the Disjoint operator 

|Overlaps
|Property geometry interior somewhere overlaps Literal geometry interior

|Touches
|Property geometry touches but does not overlap Literal geometry

|Within
|Property geometry completely contains Literal geometry

|===

=== Commons-DDF Utilities
The 
`commons-ddf`
bundle, located in
 `<DDF_HOME_SOURCE_DIRECTORY>/common/commons-ddf`
, provides utilities and functionality commonly
used across other DDF components, such as the endpoints and providers. 

==== Noteworthy Classes

===== FuzzyFunction

`ddf.catalog.impl.filter.FuzzyFunction` class is used to indicate that a `PropertyIsLike`
 filter should interpret the search as a fuzzy query. 

===== XPathHelper

`ddf.util.XPathHelper` provides convenience methods for executing XPath operations on XML. It also provides convenience methods for converting XML as a `String` from a `org.w3c.dom.Document` object and vice versa.

=== Working with Settings

DDF provides the ability to obtain DDF settings/properties. For a list of DDF settings, refer to the Catalog API and Global Settings in the Integrator's Guide. The `DdfConfigurationWatcher` will provide an update of properties to watchers. For example, if the port number changes, the DDF_PORT property value will be propagated to the watcher(s) in the form of a map.

==== Property Values

To obtain the property values, complete the following procedure.

. Import and implement the `ddf.catalog.util.DdfConfigurationWatcher` interface.

.Implement DdfConfigurationWatcher
[source,java]
----
public class SettingsWatcher implements DdfConfigurationWatcher
----

. Get properties map and search for the property.

.Handle Properties
[source,java,linenums]
----
public void ddfConfigurationUpdated( Map properties )
{
  //Get property by name
  Object value = properties.get( DdfConfigurationManager.DDF_HOME_DIR );
  if ( value != null )
  {
    this.ddfHomeDir = value.toString();
    logger.debug( "ddfHomeDir = " + this.ddfHomeDir );
  }
}
----

. Export the watcher class as a service in the OSGi Registry. The example below uses the Blueprint dependency injection framework to add this watcher to the OSGi Registry. The 
`ddf.catalog.DdfConfigurationManager` will search for `ConfigurationWatcher`(s) to send
properties updates.

.Blueprint Example of Export
[source,xml,linenums]
----
<blueprint xmlns="http://www.osgi.org/xmlns/blueprint/v1.0.0" xmlns:cm="http://aries.apache.org/blueprint/xmlns/blueprint-cm/v1.0.0">

 <!-- create the bean -->
 <bean id="SettingsWatcher" class="ddf.catalog.SettingsWatcher">
   <cm:managed-properties
     persistent-id="ddf.catalog.SettingsWatcher"
     update-strategy="container-managed" />
 </bean>

 <!-- export the bean in the service registry as a DdfConfigurationWatcher -->
 <service ref="SettingsWatcher" interface="ddf.catalog.util.DdfConfigurationWatcher">
 </service>

</blueprint>
----
. Import the DDFpackages to the bundle's manifest for run-time (in addition to any other required packages).
`Import-Package: ddf.catalog, ddf.catalog.util, ddf.catalog.*`

. Deploy the packaged service to DDF (refer to the Working with OSGi - Bundles section).


== Extending Catalog Plugins

The Catalog Framework calls Catalog Plugins to process requests and responses as they enter and leave the Framework. 

[ditaa, catalog_architecture_plugins, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       | 
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||c369           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....

=== Existing Plugins

==== Pre-Ingest Plugin

.Ingest Plugin Flow
[ditaa,ingest-plugin-flow,png]
....
/------\
|Client|
|cDEF  |
\------/
    ^
    |
+-------------------------------------------\
|DDF|                                  cCCC |
|   v                                       |
|/--------\   /-----------------\   /------\|
||Endpoint|<->|Catalog Framework|<->|Source||
|| cDEF   |   | cDEF            |   | cDEF ||
|\--------/   \-----------------/   \------/|
|                     | |                   |
|          /----------/ \--------\          |
|          |                     |          |
|          v                     v          |
|/------------------\  /-------------------\|
||PreIngest Plugins |  |PostIngest Plugins ||
|| cDEF             |  | cDEF              ||
|\------------------/  \-------------------/|
\-------------------------------------------/
....

===== Using

Pre-Ingest plugins are invoked before an ingest operation is sent to a Source.  This is an opportunity to take any action on the ingest request, including but not limited to:

* validation
* logging
* auditing
* optimization
* security filtering

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Pre-Ingest plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. 

The output of a Pre-Ingest plugin is sent to the next Pre-Ingest plugin, until all have executed and the ingest operation is sent to the requested Source.

==== Metacard Groomer

The Metacard Groomer Pre-Ingest plugin makes modifications to CreateRequest and UpdateRequest metacards.

This plugin makes the following modifications when metacards are in a CreateRequest:

* Overwrites the Metacard.ID field with a generated, unique, 32 character hexadecimal value
* Overwrites the Metacard.CREATED date with a current time stamp
* Overwrites the Metacard.MODIFIED date with a current time stamp

The plugin also makes the following modifications when metacards are in an UpdateRequest:

* If no value is provided for Metacard.ID in the new metacard, it will be set using the UpdateRequest ID if applicable.
* If no value is provided, sets the Metacard.CREATED date with the Metacard.MODIFIED date so that the Metacard.CREATEDdate is not null.
* Overwrites the Metacard.MODIFIED date with a current time stamp

===== Installing and UnInstalling
This plugin can be installed and uninstalled using the normal processes described in the Configuring DDF section.

===== Configuring
No configuration is necessary for this plugin. 

===== Using
Use this pre-ingest plugin as a convenience to apply basic rules for your metacards. 

===== Known Issues
None

==== Post-Ingest Plugin

===== Using

Post-ingest plugins are invoked after data has been created, updated, or deleted in a Catalog Provider.

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.

===== Invocation

Because the event has already occurred and changes from one post-ingest plugin cannot affect others, all Post-Ingest plugins are invoked in parallel and no priority is enforced.

.QueryPlugin Flow
[ditaa,query-plugin-flow,png]
....
/------\
|Client|
|cDEF  |
\------/
    ^
    |
+-------------------------------------------\
|DDF|                                  cCCC |
|   v                                       |
|/--------\   /-----------------\   /------\|
||Endpoint|<->|Catalog Framework|<->|Source||
|| cDEF   |   | cDEF            |   | cDEF ||
|\--------/   \-----------------/   \------/|
|                     | |                   |
|          /----------/ \--------\          |
|          |                     |          |
|          v                     v          |
|/------------------\  /-------------------\|
|| PreQuery Plugins |  | PostQuery Plugins ||
||  cDEF            |  |  cDEF             ||
|\------------------/  \-------------------/|
\-------------------------------------------/
....

==== Pre-Query Plugin

===== Using

Pre-query plugins are invoked before a query operation is sent to any of the Sources.  This is an opportunity to take any action on the query, including but not limited to:

* validation
* logging
* auditing
* optimization
* security filtering

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Pre-query plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. The output of a pre-query plugin is sent to the next pre-query plugin, until all have executed and the query operation is sent to the requested Source.

==== Post-Query Plugin

===== Using

Post-query plugins are invoked after a query has been executed successfully, but before the response is returned to the endpoint.  This is an opportunity to take any action on the query response, including but not limited to:

* logging
* auditing
* security filtering/redaction
* deduplication

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Post-query plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. The output of the first plugin is sent to the next plugin, until all have executed and the response is returned to the requesting endpoint.

==== Metacard Resource Size Plugin
This post-query plugin updates the resource size attribute of each metacard in the query results if there is a cached file for the product and it has a size greater than zero; otherwise, the resource size is unmodified and the original result is returned.

===== Installing and UnInstalling
This feature can be installed and uninstalled using the normal processes described in the Configuring DDF section.

===== Configuring
No configuration is necessary for this plugin. 

===== Using
Use this post-query plugin as a convenience to return query results with accurate resource sizes for cached products. 

===== Known Issues
None

=== Other Types of Plugins

==== Pre-Get Resource Plugin

===== Using
Pre-get resource plugins are invoked before a request to retrieve a resource is sent to a Source.  This is an opportunity to take any action on the request, including but not limited to:

* validation
* logging
* auditing
* optimization
* security filtering

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Pre-get resource plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. 

The output of the first plugin is sent to the next plugin, until all have executed and the request is sent to the targeted Source.

==== Post-Get Resource Plugin

===== Using

Post-get resource plugins are invoked after a resource has been retrieved, but before it is returned to the endpoint.  This is an opportunity to take any action on the response, including but not limited to:

* logging
* auditing
* security filtering/redaction

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Post-get resource plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. 

The output of the first plugin is sent to the next plugin, until all have executed and the response is returned to the requesting endpoint.

==== Pre-Subscription Plugin

===== Using

Pre-subscription plugins are invoked before a Subscription is activated by an Event Processor. This is an opportunity to take any action on the Subscription, including but not limited to:

* validation
* logging
* auditing
* optimization
* security filtering

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Pre-subscription plugins are invoked serially, prioritized by descending OSGi service ranking.  That is, the plugin with the highest service ranking will be executed first. 

The output of a pre-subscription plugin is sent to the next pre-subscription plugin, until all have executed and the create Subscription operation is sent to the Event Processor.

===== Examples

DDF includes a pre-subscription plugin example in the SDK that illustrates how to modify a subscription's filter. This example is located in the DDF trunk at `sdk/sample-plugins/ddf/sdk/plugin/presubscription`.

==== Pre-Delivery Plugin

===== Using

Pre-delivery plugins are invoked before a Delivery Method is invoked on a Subscription.  This is an opportunity to take any action before notification, including but not limited to:

* logging
* auditing
* security filtering/redaction

===== Failure Behavior

In the event that this Catalog Plugin cannot operate but does not wish to fail the transaction, a PluginExecutionException will be thrown.  For any other Exceptions, the Catalog will "fail safe" and the Operation will be cancelled.  If processing is to be explicitly stopped, a StopProcessingException will be thrown.

===== Invocation

Pre-delivery plugins are invoked serially, prioritized by descending OSGi service ranking. That is, the plugin with the highest service ranking will be executed first. 

The output of a pre-delivery plugin is sent to the next pre-delivery plugin, until all have executed and the Delivery Method is invoked on the associated Subscription.

=== Developing a Catalog Plugin

Plugins extend the functionality of the Catalog Framework by performing actions at specified times during a transaction.  Plugins can be Pre-Ingest, Post-Ingest, Pre-Query, Post-Query, Pre-Subscription, Pre-Delivery, Pre-Resource, or Post-Resource.  By implementing these interfaces, actions can be performed at the desired time. Refer to Catalog Framework for more information on how these plugins fit in the ingest and query flows.

==== Create New Plugins

===== Implement Plugin Interface

The following types of plugins can be created:

[cols="4*", options="header"]
|===

|Plugin Type
|Plugin Interface
|Description
|Example

|Pre-Ingest
|ddf.catalog.plugin.PreIngestPlugin
|Runs before the Create/Update/Delete method is sent to the CatalogProvider
|Metadata validation services

|Post-Ingest
|ddf.catalog.plugin.PostIngestPlugin
|Runs after the Create/Update/Delete method is sent to the CatalogProvider
|EventProcessor for processing and publishing event notifications to subscribers

|Pre-Query
|ddf.catalog.plugin.PreQueryPlugin
|Runs prior to the Query/Read method being sent to the Source
|An example is not included with DDF

|Post-Query
|ddf.catalog.plugin.PostQueryPlugin
|Runs after results have been retrieved from the query but before they are posted to the Endpoint
|An example is not included with DDF

|Pre-Subscription
|ddf.catalog.plugin.PreSubscription
|Runs prior to a Subscription being created or updated 
|Modify a query prior to creating a subscription

|Pre-Delivery
|ddf.catalog.plugin.PreDeliveryPlugin
|Runs prior to the delivery of a Metacard when an event is posted 
|Inspect a metacard prior to delivering it to the Event Consumer

|Pre-Resource
|ddf.catalog.plugin.PreResource
|Runs prior to a Resource being retrieved
|An example is not included with DDF

|Post-Resource
|ddf.catalog.plugin.PostResource
|Runs after a Resource is retrieved, but before it is sent to the Endpoint 
|Verification of a resource prior to returning to a client

|===

===== Implement Plugins

The procedure for implementing any of the plugins follows a similar format:

. Create a new class that implements the specified plugin interface.

. Implement the required methods.

. Create OSGi descriptor file to communicate with the OSGi registry (described in the OSGi Services section).

.. Import DDF packages.

.. Register plugin class as service to OSGi registry.

. Deploy to DDF. (Refer to the Working with OSGi - Bundles section.)

[TIP]
====
Refer to the Javadoc for more information on all Requests and Responses in the
 `ddf.catalog.operation`
 and 
`ddf.catalog.event`
packages.
====

===== Pre-Ingest

. Create a Java class that implements `PreIngestPlugin.` +
`public class SamplePreIngestPlugin implements ddf.catalog.plugin.PreIngestPlugin`

. Implement the required methods. +
`public CreateRequest process(CreateRequest input) throws PluginExecutionException;`
`public UpdateRequest process(UpdateRequest input) throws PluginExecutionException;`
`public DeleteRequest process(DeleteRequest input) throws PluginExecutionException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin`

. Export the service to the OSGi registry. +
*Blueprint descriptor example*
`<service ref="[[SamplePreIngestPlugin ]]"interface="ddf.catalog.plugin.PreIngestPlugin" />`

===== Post-Ingest

. Create a Java class that implements PostIngestPlugin. +
`public class SamplePostIngestPlugin implements ddf.catalog.plugin.PostIngestPlugin`

. Implement the required methods. +
`public CreateResponse process(CreateResponse input) *throws* PluginExecutionException;`
`public UpdateResponse process(UpdateResponse input) *throws* PluginExecutionException;`
`public DeleteResponse process(DeleteResponse input) *throws* PluginExecutionException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin`

. Export the service to the OSGi registry. + 
*Blueprint descriptor example*
`<service ref="[[SamplePostIngestPlugin ]]"interface="ddf.catalog.plugin.PostIngestPlugin" />`

===== Pre-Query

. Create a Java class that implements PreQueryPlugin. +
`public class SamplePreQueryPlugin implements ddf.catalog.plugin.PreQueryPlugin`

. Implement the required method. +
`public QueryRequest process(QueryRequest input) *throws* PluginExecutionException, StopProcessingException;`

An example of an implementation of a `PreQueryPlugin.process()` method's business logic is shown below and can be found in the DDF SDK in the sample-plugins project.

.How to build PreQueryPlugin filter
[source,java,linenums]
----
FilterDelegate<Filter> delegate = new CopyFilterDelegate(filterBuilder);
try {
    // Make a defensive copy of the original filter (just in case anyone else expects
    // it to remain unmodified)
    Filter copiedFilter = filterAdapter.adapt(query, delegate);
                
    // Define the extra query clause(s) to add to the copied filter
    // This will create a filter with a search phrase of:
    //     ((("schematypesearch") and ("test" and ({/ddms:Resource/ddms:security/@ICISM:releasableTo}:"ISAF" or {/ddms:Resource/ddms:security/@ICISM:releasableTo}:"CAN")))
    Filter contextualFilter = filterBuilder.attribute(Metacard.ANY_TEXT).like().text("test");
    Filter releasableToFilter1 = filterBuilder.attribute("/ddms:Resource/ddms:security/@ICISM:releasableTo").like().text("ISAF");
    Filter releasableToFilter2 = filterBuilder.attribute("/ddms:Resource/ddms:security/@ICISM:releasableTo").like().text("CAN");
    Filter orFilter = filterBuilder.anyOf(releasableToFilter1, releasableToFilter2);
    Filter extraFilter = filterBuilder.allOf(contextualFilter, orFilter);
                
    // AND this PreQueryPlugin's extra query clause(s) to the copied filter
    Filter modifiedFilter = filterBuilder.allOf(copiedFilter, extraFilter);

    // Create a new QueryRequest using the modified filter and the attributes from the original query
    QueryImpl newQuery = new QueryImpl(modifiedFilter, query.getStartIndex(), 
        query.getPageSize(), query.getSortBy(), 
        query.requestsTotalResultsCount(), query.getTimeoutMillis());
    newQueryRequest = new QueryRequestImpl(newQuery, input.isEnterprise(), input.getSourceIds(), input.getProperties());
} 
catch (UnsupportedQueryException e) 
{
    throw new PluginExecutionException(e);
}
----
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin`

. Export the service to the OSGi registry. +
`<service ref="[[SamplePreQueryPlugin]]"interface="ddf.catalog.plugin.PreQueryPlugin" />`

===== Post-Query

. Create a Java class that implements `PostQueryPlugin`. +
`public class SamplePostQueryPlugin implements ddf.catalog.plugin.PostQueryPlugin`

. Implement the required method. +
`public QueryResponse process(QueryResponse input) *throws* PluginExecutionException, StopProcessingException;

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin`

. Export the service to the OSGi registry. + 
`<service ref="[[SamplePostQueryPlugin]]"interface="ddf.catalog.plugin.PostQueryPlugin" />`

===== Pre-Delivery

. Create a Java class that implements PreDeliveryPlugin. +
`public class SamplePreDeliveryPlugin *implements* ddf.catalog.plugin.PreDeliveryPlugin`

. Implement the required methods. +
`public Metacard processCreate(Metacard metacard) *throws* PluginExecutionException, StopProcessingException;`
`public Update processUpdateMiss(Update update) *throws* PluginExecutionException, 
StopProcessingException;`
`public Update processUpdateHit(Update update) *throws* PluginExecutionException, StopProcessingException;`
`public Metacard processCreate(Metacard metacard) *throws* PluginExecutionException, StopProcessingException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin,ddf.catalog.operation,ddf.catalog.event`

. Export the service to the OSGi registry. +
*Blueprint descriptor example* +
`<service ref="[[SamplePreDeliveryPlugin]]"interface="ddf.catalog.plugin.PreDeliveryPlugin" />`

===== Pre-Subscription

. Create a Java class that implements PreSubscriptionPlugin. +
`public class SamplePreSubscriptionPlugin *implements* ddf.catalog.plugin.PreSubscriptionPlugin

. Implement the required method.
`public Subscription process(Subscription input) *throws* PluginExecutionException, StopProcessingException;`

An example of an implementation of a `PreSubscriptionPlugin.process()` method's business logic is shown below and can be found in the DDF SDK in the `sample-plugins` project.

.PreSubscriptionPlugin example
[source,java,linenums]
----
FilterDelegate<Filter> delegate = new CopyFilterDelegate(filterBuilder);
try {
    // Make a defensive copy of the original filter (just in case anyone else expects
    // it to remain unmodified)
    Filter copiedFilter = filterAdapter.adapt(input, delegate);
     
    // Define the extra query clause(s) to add to the copied filter
    Filter extraFilter = filterBuilder.attribute("/ddms:Resource/ddms:security/@ICISM:releasableTo").like().text("CAN");

    // AND the extra query clause(s) to the copied filter
    Filter modifiedFilter = filterBuilder.allOf(copiedFilter, extraFilter);

    // Create a new subscription with the modified filter
     newSubscription = new SubscriptionImpl(modifiedFilter, input.getDeliveryMethod(),
         input.getSourceIds(), input.isEnterprise());
} 
catch (UnsupportedQueryException e) 
{
   throw new PluginExecutionException(e);
}
----

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin,ddf.catalog.event`

. Export the service to the OSGi registry.

.Blueprint descriptor example
[source,xml,linenums]
----
<service ref="[[SamplePreSubscriptionPlugin]]"interface="ddf.catalog.plugin.PreSubscriptionPlugin" />
----

===== Pre-Resource

. Create a Java class that implements `PreResourcePlugin`.
`public class SamplePreResourcePlugin *implements* ddf.catalog.plugin.PreResourcePlugin`

. Implement the required method. +
`public ResourceRequest process(ResourceRequest input) *throws* PluginExecutionException, StopProcessingException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin,ddf.catalog.operation`

. Export the service to the OSGi registry. 
.Blueprint descriptor example
[source,xml]
----
<service ref="[[SamplePreResourcePlugin]]" interface="ddf.catalog.plugin.PreResourcePlugin" />
----

===== Post-Resource

. Create a Java class that implements `PostResourcePlugin`. +
`public class SamplePostResourcePlugin *implements* ddf.catalog.plugin.PostResourcePlugin`

. Implement the required method. +
`public ResourceResponse process(ResourceResponse input) *throws* PluginExecutionException, StopProcessingException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.plugin,ddf.catalog.operation`

. Export the service to the OSGi registry.
.Blueprint descriptor example
[source,xml]
----
<service ref="[[SamplePostResourcePlugin]]" interface="ddf.catalog.plugin.PostResourcePlugin" />
----

== Extending Operations

The Catalog provides the capability to query, create, update, and delete metacards; retrieve resources; and retrieve information about the sources in the enterprise.

Each of these operations follow a request/response paradigm. The request is the input to the operation and contains all of the input parameters needed by the Catalog Framework's operation to communicate with the Sources. The response is the output from the execution of the operation that is returned to the client, which contains all of the data returned by the sources. For each operation there is an associated request/response pair, e.g., the QueryRequest and QueryResponse pair for the Catalog Framework's query operation.

All of the request and response objects are extensible in that they can contain additional key/value properties on each request/response. This allows additional capability to be added without changing the Catalog API, helping to maintain backwards compatibility. Refer to the Developer's Guide for details about using this extensibility.

[ditaa, catalog_architecture_operations, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       |
|                |c369        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/| 
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....
== Extending Data and Metadata Basics

The catalog stores and translates Metadata which can be transformed into many data formats, shared, and queried. The primary form of this metadata is the metacard. A `Metacard` is a container for metadata. `CatalogProviders` accept `Metacards` as input for ingest, and `Sources` search for metadata and return matching `Results` that include `Metacards`.

[ditaa, catalog_architecture_data, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       |
|                |cDEF        |c369  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/| 
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....

=== Metacard

A single instance of metadata in the Catalog (an instance of a metacard type) which generally contains metadata providing a title for the product and describing a product's geo-location, created and modified dates, owner or producer, security classification, etc. 
==== Metacard Type

A metacard type indicates the attributes available for a particular metacard.  It is a model used to define the attributes of a metacard, much like a schema.

==== Default Metacard Type and Attributes

Most metacards within the system are created using with the default metacard type. The default metacard type of the system can be programmatically retrieved by calling `ddf.catalog.data.BasicTypes.BASIC_METACARD`. The name of the default MetacardType can be retrieved from `ddf.catalog.data.MetacardType.DEFAULT_METACARD_TYPE_NAME`.

The default metacard type has the following required attributes.  Though the following attributes are required on all metacard types, setting their values is optional except for ID.

===== Required Attributes

[cols="4*", options="header"]
|===

|ddf.catalog.data.Metacard Constant
|Attribute Name
|Attribute Format
|Description

|CONTENT_TYPE
|metadata-content-type
|STRING
|Attribute name accessing for the metadata content type of a Metacard.

|CONTENT_TYPE_VERSION
|metadata-content-type-version
|STRING
|Attribute name for the version of the metadata content accessing type of a Metacard.

|CREATED
|created
|DATE
|Attribute name for accessing the date/time *this Metacard* was created.

|EFFECTIVE
|effective
|DATE
|Attribute name for accessing the date/time of *the product* represented by the Metacard.

|EXPIRATION
|expiration
|DATE
|Attribute name for accessing the date/time the Metacard is no longer valid and could be removed.

|GEOGRAPHY
|location
|GEOMETRY
|Attribute name for accessing the location for this Metacard.

|ID
|id
|STRING
|Attribute name for accessing the ID of the Metacard.

|METADATA
|metadata
|XML
|Attribute name for accessing the XML metadata for this Metacard.

|MODIFIED
|modified
|DATE
|Attribute name for accessing the date/time this Metacard was last modified.

|RESOURCE_SIZE
|resource-size
|STRING
|Attribute name for accessing the size in bytes of the product this Metacard represents.

|RESOURCE_URI
|resource-uri
|STRING
|Attribute name for accessing the URI reference to the product this Metacard represents.

|TARGET_NAMESPACE
|metadata-target-namespace
|STRING
|Attribute name for the target namespace of the accessing metadata content type of a Metacard.

|THUMBNAIL
|thumbnail
|BINARY
|Attribute name for accessing the thumbnail image of the product this Metacard represents. The thumbnail must be of MIME Type `image/jpeg` and be less than 128 kilobytes. 

|TITLE
|title
|STRING
|Attribute name for accessing the title of the Metacard.

|===

[WARNING]
====
It is highly recommended when referencing a default attribute name to use the `ddf.catalog.data.Metacard` constants whenever possible.
====

[WARNING]
====
Every Source should at the very least return an ID attribute according to Catalog API. Other fields might or might not be applicable, but a unique ID must be returned by a Source.
====

==== Extensible Metacards

Metacard extensibility is achieved by creating a new MetacardType that supports attributes in addition to the required attributes listed above.

Required attributes must be the base of all extensible metacard types. 

[WARNING]
====
Not all Catalog Providers support extensible metacards. Nevertheless, each Catalog Provider should at least have support for the default MetacardType; i.e., it should be able to store and query on the attributes and attribute formats specified by the default metacard type. Consult the documentation of the Catalog Provider in use for more information on its support of extensible metacards.
====

===== Metacard Extensibility

Often, the BASIC_METACARD `MetacardType` does not provide all the functionality or attributes necessary for a specific task. For performance or convenience purposes, it may be necessary to create custom attributes even if others will not be aware of those attributes. One example could be if a user wanted to optimize a search for a date field that did not fit the definition of `CREATED`, `MODIFIED`, `EXPIRATION`, or `EFFECTIVE`.  The user could create an additional `java.util.Date` attribute in order to query the attribute separately. 

`Metacard` objects are extensible because they allow clients to store and retrieve standard and custom key/value Attributes from the `Metacard`.  All `Metacards` must return a `MetacardType` object that includes an `AttributeDescriptor` for each `Attribute`, indicating it's key and value type. `AttributeType` support is limited to those types defined by the Catalog.

New `MetacardType` implementations can be made by implementing the `MetacardType` interface.

==== Metacard Type Registry
[WARNING]
====
The MetacardTypeRegistry is experimental.  While this component has been tested and is functional, it may change as more information is gathered about what is needed and as it is used in more scenarios.
====

The MetacardTypeRegistry allows DDF components, primarily CatalogProviders and Sources, to make available the MetacardTypes that they support.  It maintains a list of all supported MetacardTypes in the CatalogFramework, so that other components such as Endpoints, Plugins, and Transformers can make use of those MetacardTypes.  The MetacardType is essential for a component in the CatalogFramework to understand how it should interpret a metacard by knowing what attributes are available in that metacard. 

For example, an endpoint receiving incoming metadata can perform a lookup in the MetacardTypeRegistry to find a corresponding MetacardType. The discovered MetacardType will then be used to help the endpoint populate a metacard based on the specified attributes in the MetacardType.  By doing this, all the incoming metadata elements can then be available for processing, cataloging, and searching by the rest of the CatalogFramework.

MetacardTypes should be registered with the MetacardTypeRegistry.  The MetacardTypeRegistry makes those MetacardTypes available to other DDF CatalogFramework components.  Other components that need to know how to interpret metadata or metacards should look up the appropriate MetacardType from the registry.  By having these MetacardTypes available to the CatalogFramework, these components can be aware of the custom attributes. 

The MetacardTypeRegistry is accessible as an OSGi service.  The following blueprint snippet shows how to inject that service into another component:

[source,xml,linenums]
----
<bean id="sampleComponent" class="ddf.catalog.SampleComponent">
    <argument ref="metacardTypeRegistry" />
</bean>

<!-- Access MetacardTypeRegistry -->
<reference id="metacardTypeRegistry" interface="ddf.catalog.data.MetacardTypeRegistry"/>
----

The reference to this service can then be used to register new MetacardTypes or to lookup existing ones. 

Typically, new MetacardTypes will be registered by CatalogProviders or Sources indicating they know how to persist, index, and query attributes from that type.  Typically, Endpoints or InputTransformers will use the lookup functionality to access a MetacardType based on a parameter in the incoming metadata.  Once the appropriate MetacardType is discovered and obtained from the registry, the component will know how to translate incoming raw metadata into a DDF Metacard.

===== Attribute

A single field of a metacard, an instance of an attribute type.  Attributes are typically indexed for searching by a Source or Catalog Provider.

====== Attribute Type

An attribute type indicates the attribute format of the value stored as an attribute.  It is a model for an attribute.

====== Attribute Format

An enumeration of attribute formats are available in the catalog.  Only these attribute formats may be used.

[cols="2*", options="header"]
|===

|AttributeFormat
|Description

|BINARY
|Attributes of this attribute format must have a value that is a Java byte[] and AttributeType.getBinding() should return Class<Array>of byte.

|BOOLEAN
|Attributes of this attribute format must have a value that is a Java boolean.

|DATE
|Attributes of this attribute format must have a value that is a Java date.

|DOUBLE
|Attributes of this attribute format must have a value that is a Java double.

|FLOAT
|Attributes of this attribute format must have a value that is a Java float.

|GEOMETRY
|Attributes of this attribute format must have a value that is a WKT-formatted Java string.

|INTEGER
|Attributes of this attribute format must have a value that is a Java integer.

|LONG
|Attributes of this attribute format must have a value that is a Java long.

|OBJECT
|Attributes of this attribute format must have a value that implements the serializable interface.

|SHORT
|Attributes of this attribute format must have a value that is a Java short.

|STRING
|Attributes of this attribute format must have a value that is a Java string and treated as plain text.

|XML
|Attributes of this attribute format must have a value that is a XML-formatted Java string.

|===

==== Result

A single "hit" included in a query response.

A result object consists of the following:

* a metacard
* a relevance score if included
* distance in meters if included

==== Creating Metacards

The quickest way to create a `Metacard` is to extend or construct the `MetacardImpl` object. `MetacardImpl` is the most commonly used and extended `Metacard` implementation in the system because it provides a convenient way for developers to retrieve and set `Attribute`s without having to create a new `MetacardType` (see below). `MetacardImpl` uses `BASIC_METACARD` as its `MetacardType`.  

==== Limitations

A given developer does not have all the information necessary to programmatically interact with any arbitrary `Source`. Developers hoping to query custom fields from extensible `Metacards` of other `Sources` cannot easily accomplish that task with the current API. A developer cannot question a random `Source` for all its _queryable_ fields. A developer only knows about the `MetacardTypes` which that individual developer has used or created previously. 

The only exception to this limitation is the `Metacard.ID` field, which is required in every `Metacard` that is stored in a `Source`. A developer can always request `Metacards` from a `Source` for which that developer has the `Metacard.ID` value.  The developer could also perform a wildcard search on the `Metacard.ID` field if the `Source` allows.

==== Processing Metacards

As `Metacard` objects are created, updated, and read throughout the Catalog, care should be taken by all Catalog Components to interrogate the `MetacardType` to ensure that additional `Attributes` are processed accordingly.

==== Basic Types

The Catalog includes definitions of several Basic Types all found in the `ddf.catalog.data.BasicTypes` class.

[cols="3*", options="header"]
|===

|Name
|Type
|Description

|BASIC_METACARD
|MetacardType
|representing all required Metacard Attributes

|BINARY_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.BINARY.

|BOOLEAN_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.BOOLEAN.

|DATE_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.DATE .

|DOUBLE_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.DOUBLE.

|FLOAT_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.FLOAT.

|GEO_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.GEOMETRY.

|INTEGER_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.INTEGER.

|LONG_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.LONG .

|OBJECT_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.OBJECT.

|SHORT_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.SHORT.

|STRING_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.STRING.

|XML_TYPE
|AttributeType
|A Constant for an AttributeType with AttributeType.AttributeFormat.XML.

|===

== Extending Catalog Framework

This section describes the core components of the Catalog app and Catalog Framework. The Catalog Framework wires all Catalog components together.

It is responsible for routing Catalog requests and responses to the appropriate target. 

Endpoints send Catalog requests to the Catalog Framework. The Catalog Framework then invokes Catalog Plugins, Transformers, and Resource Components as needed before sending requests to the intended destination, such as one or more Sources. 

The Catalog Framework functions as the routing mechanisms between all catalog components.  It decouples clients from service implementations and provides integration points for Catalog Plugins and convenience methods for Endpoint developers.

[ditaa, catalog_architecture_operations, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       |
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |c369               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/| 
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....
=== Included Catalog Frameworks

==== Catalog API

The Catalog API is an OSGi bundle (`catalog-core-api`) that contains the Java interfaces for the Catalog components and implementation classes for the Catalog Framework, Operations, and Data components.

==== Standard Catalog Framework

The Standard Catalog Framework provides the reference implementation of a Catalog Framework that implements all requirements of the DDF Catalog API. `CatalogFrameworkImpl` is the implementation of the DDF Standard Catalog Framework.

==== Installing and Uninstalling

The Standard Catalog Framework is bundled as the `catalog-core-standardframework` feature and can be installed and uninstalled using the normal processes described in Configuration.

When this feature is installed, the Catalog Fanout Framework App feature `catalog-core-fanoutframework` should be uninstalled, as both catalog frameworks should not be installed simultaneously.

==== Configuring

===== Configurable Properties

_Catalog Standard Framework_

[cols="5*", options="header"]
|===

|Property
|Type
|Description
|Default Value
|Required

|fanoutEnabled
|Boolean
|When enabled the Framework acts as a proxy, federating requests to all available sources. All requests are executed as federated queries and resource retrievals, allowing the framework to be the sole component exposing the functionality of all of its Federated Sources.
|false
|yes

|poolSize
|Integer
|The federation thread pool size

(0 for unlimited)
|0
|yes

|productCacheDirectory
|String
|Directory where retrieved products will be cached for faster, future retrieval. If a directory path is specified with directories that do not exist, Catalog Framework will attempt to create those directories. Out of the box (without configuration), the product cache directory is `<INSTALL_DIR>/data/product-cache`. If a relative path is provided it will be relative to the `<INSTALL_DIR>`.

It is recommended to enter an absolute directory path such as `/opt/product-cache`in Linux or `C:/product-cache` in Windows."
|`(empty)`
|no

|cacheEnabled
|Boolean
|Check to enable caching of retrieved products to provide faster retrieval for subsequent requests for the same product.
|false
|no

|delayBetweenRetryAttempts
|Integer
|The time to wait (in seconds) between each attempt to retry retrieving a product from the Source.
|10
|no

|maxRetryAttempts
|Integer
|The maximum number of attempts to try and retrieve a product from the Source.
|3
|no

|cachingMonitorPeriod
|Integer
|The number of seconds allowed for no data to be read from the product data before determining that the network connection to the Source where the product is located is considered to be down.
|5
|no

|cacheWhenCanceled
|Boolean
|Check to enable caching of retrieved products even if client cancels the download.
|false
|no

|===

[cols="2*", options="header"]
|===

|Managed Service PID
|`ddf.catalog.CatalogFrameworkImpl`
|Managed Service Factory PID
|N/A
|===

==== Using

The Standard Catalog Framework is the core class of DDF. It provides the methods for query, create, update, delete, and resource retrieval (QCRUD) operations on the `Sources`. By contrast, the Fanout Catalog Framework only allows for query and resource retrieval operations, no catalog modifications, and all queries are enterprise-wide.

Use this framework if:

* access to a catalog provider to create, update, and delete catalog entries are required
* queries to specific sites are required
* queries to only the local provider are required

It is possible to have only remote Sources configured with no local CatalogProvider configured and be able to execute queries to specific remote sources by specifying the site name(s) in the query request.

The Standard Catalog Framework also maintains a list of `ResourceReaders` for resource retrieval operations. A resource reader is matched to the scheme (i.e., protocol, such as `file://`) in the URI of the resource specified in the request to be retrieved.

Site information about the catalog provider and/or any federated source(s) can be retrieved using the Standard Catalog Framework. Site information includes the source's name, version, availability, and the list of unique content types currently stored in the source (e.g., NITF). If no local catalog provider is configured, the site information returned includes site info for the catalog framework with no content types included.

==== Implementation Details

===== Exported Services

[cols="3*", options="header"]
|===

|Registered Interface
|Service Property
|Value

|`ddf.catalog.federation.FederationStrategy`
|shortname
|sorted

|`org.osgi.service.event.EventHandler`
|event.topics
|ddf/catalog/event/CREATED, ddf/catalog/event/UPDATED, ddf/catalog/event/DELETED

|`ddf.catalog.CatalogFramework`
|
|

|`org.codice.ddf.configuration.ConfigurationWatcher`
|
| 

|`ddf.catalog.event.EventProcessor`
|
|

|`ddf.catalog.plugin.PostIngestPlugin`
|
|

|===

===== Imported Services

[cols="3*" options="header"]
|===

|Registered Interface
|Availability
|Multiple

|`ddf.catalog.plugin.PostFederatedQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PostIngestPlugin`
|optional
|true

|`ddf.catalog.plugin.PostQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PostResourcePlugin`
|optional
|true

|`ddf.catalog.plugin.PreDeliveryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreFederatedQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreIngestPlugin`
|optional
|true

|`ddf.catalog.plugin.PreQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreResourcePlugin`
|optional
|true

|`ddf.catalog.plugin.PreSubscriptionPlugin`
|optional
|true

|`ddf.catalog.resource.ResourceReader`
|optional
|true

|`ddf.catalog.source.CatalogProvider`
|optional
|true

|ddf.catalog.source.ConnectedSource`
|optional
|true

|`ddf.catalog.source.FederatedSource`
|optional
|true

|`ddf.cache.CacheManager`
| 
|false

|`org.osgi.service.event.EventAdmin`
| 
|false

|===

==== Known Issues
None

=== Catalog Fanout Framework 

The Fanout Catalog Framework (`fanout-catalogframework` bundle) provides an implementation of the Catalog Framework that acts as a proxy, federating requests to all available sources. All requests are executed as federated queries and resource retrievals, allowing the fanout site to be the sole site exposing the functionality of all of its Federated Sources. The Fanout Catalog Framework is the implementation of the Fanout Catalog Framework.

The Fanout Catalog Framework provides the capability to configure DDF to be a fanout proxy to other federated sources within the enterprise. The Fanout Catalog Framework has no catalog provider configured for it, so it does not allow catalog modifications to take place. Therefore, create, update, and delete operations are not supported.

.Catalog Fanout Framework
[ditaa,query-flow,png]
....
           /------\
           |Client|
           |cDEF  |
           \------/
              ^
              |
+-------------|------------------------------------------------------------\
|DDF          |                                                       cCCC |
|             v                                                            |
|         /--------\   /-----------------\   /-------------------\         |
|         |Endpoint|<->|Catalog Framework|<->|Federation Strategy|         |
|         | cDEF   |   | cDEF            |   | cDEF              |         | 
|         \--------/   \-----------------/   \-------------------/         |
|                                                     ^ ^                  |
|                                                     | |                  |
|                                          /----------/ \---------\        |
|                                          |                      |        |
| +----------------------------------------|----------------------|------+ |
| |Enterprise Query c369                   v                      v      | |
| |+--------------------------------------------+ +---------------------+| |
| ||Local Query                                 | |Federated Query      || |
| ||/------------------\ /---------------------\| |/-------------------\|| |
| ||| Catalog Provider | | Connected Source(s) || ||Federated Source(s)||| |
| |||  cDEF            | |  cDEF               || || cDEF              ||| |
| ||\------------------/ \---------------------/| |\-------------------/|| |
| |+-------^----------------------^-------------+ +----^----------^-----+| |
| +--------|----------------------|--------------------|----------|------+ |
\----------|----------------------|--------------------|----------|--------/
           |                      |                    |          \-------------------\
           |                      |                    |                              |
           v                      v                    v                              v
/=-------------------\ /----------------------\ /---------=------------\     /----------------------\
|Internal Data Source| |External Data Source 1| |External Data Source 3| ... |External Data Source N|
\--------------------/ \--------------------=-/ \----------------------/     \-------=--------------/
.... 

In addition, the Fanout Catalog Framework provides the following benefits:

* Backwards compatibility (e.g., federating with older versions) with existing older versions of {branding}
* A single node being exposed from an enterprise, thus hiding the enterprise from an external client
* Ensures all queries and resource retrievals are federated

==== Installing and Uninstalling
The Fanout Catalog Framework is bundled as the `catalog-core-fanoutframework` feature and can be installed and uninstalled using the normal processes described in Configuration.

[WARNING]
====
When this feature is installed, the Standard Catalog Framework feature `catalog-core-standardframework` should be uninstalled, as both catalog frameworks should not be installed simultaneously.
====

==== Configuring

The Fanout Catalog Framework can be configured using the normal processes described in Configuring DDF.

The configurable properties for the Fanout Catalog Framework are accessed from the 
Catalog Fanout Framework configuration in the Web Console.

===== Configurable Properties

[cols="6*" options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Federation Thread Pool Size
(0 for unlimited)
|poolSize
|Integer
|The federation thread pool size.
(0 for unlimited)
|0
|yes

|Default Timeout
(in milliseconds)
|defaultTimeout
|Integer
|The maximum amount of time to wait for a response from the Sources.
|60000
|yes

|Product Cache Directory
|productCacheDirectory
|String
|Directory where retrieved products will be cached for faster, future retrieval. If a directory path is specified with directories that do not exist, Catalog Framework will attempt to create those directories. Out of the box (without configuration), the product cache directory is `<INSTALL_DIR>/data/product-cache`. If a relative path is provided, it will be relative to the `<INSTALL_DIR>`.

It is recommended to enter an absolute directory path, such as `/opt/product-cache` in Linux or `C:/product-cache` in Windows.
|(empty)
|no

|Enable Product Caching
|cacheEnabled
|Boolean
|Check to enable caching of retrieved products to provide faster retrieval for subsequent requests for the same product.
|false
|no

|Delay (in seconds) between product retrieval retry attempts
|delayBetweenRetryAttempts
|Integer
|The time to wait (in seconds) between attempting to retry retrieving a product.
|10
|no

|Max product retrieval retry attempts
|maxRetryAttempts
|Integer
|The maximum number of attempts to retry retrieving a product.
|3
|no

|Caching Monitor Period
|cachingMonitorPeriod
|Integer
|How many seconds to wait and not receive product data before retrying to retrieve a product.
|5
|no

|Always Cache Product
|cacheWhenCanceled
|Boolean
|Check to enable caching of retrieved products, even if client cancels the download.
|false
|no

|===

[cols="2*" options="header"]
|===
|Managed Service PID
|`ddf.catalog.impl.service.fanout.FanoutCatalogFramework`
|Managed Service Factory PID
|N/A
|===

==== Using

The Fanout Catalog Framework is a core class of DDF when configured as a fanout proxy. It provides the methods for query and resource retrieval operations on the Sources, where all operations are enterprise-wide operations. By contrast, the Standard Catalog Framework supports create/update/delete operations of metacards, in addition to the query and resource retrieval operations.

Use the Fanout Catalog Framework if:

* exposing a single node for enterprise access and hiding the details of the enterprise, such as federate source's names, is desired
* access to individual federated sources is not required
* access to a catalog provider to create, update, and delete metacards is not required

The Fanout Catalog Framework also maintains a list of `ResourceReaders` for resource retrieval operations. A resource reader is matched to the scheme (i.e., protocol, such as `file://`) in the URI of the resource specified in the request to be retrieved.

Site information about the fanout configuration can be retrieved using the Fanout Catalog Framework. Site information includes the source's name, version, availability, and the list of unique content types currently stored in the source (e.g., NITF). Details of the individual federated sources is not included, only the fanout catalog framework.

==== Implementation Details

===== Exported Services

[cols="3*" options="header"]
|===
|Registered Interface
|Service Property
|Value

|`ddf.catalog.federation.FederationStrategy`
|shortname
|sorted

|`org.osgi.service.event.EventHandler`
|event.topics
|`ddf/catalog/event/CREATED`, `ddf/catalog/event/UPDATED`, `ddf/catalog/event/DELETED`

|ddf.catalog.CatalogFramework
|
|

|`org.codice.ddf.configuration.ConfigurationWatcher`
|
| 

|`ddf.catalog.event.EventProcessor`
|
| 

|`ddf.catalog.plugin.PostIngestPlugin`
|
|

|===

===== Imported Services

[cols="3*" options="header"]
|===

|Registered Interface
|Availability
|Multiple

|`ddf.cache.CacheManager`
|
|false

|`ddf.catalog.plugin.PostFederatedQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PostIngestPlugin`
|optional
|true

|`ddf.catalog.plugin.PostQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PostResourcePlugin`
|optional
|true

|`ddf.catalog.plugin.PreDeliveryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreFederatedQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreIngestPlugin`
|optional
|true

|`ddf.catalog.plugin.PreQueryPlugin`
|optional
|true

|`ddf.catalog.plugin.PreResourcePlugin`
|optional
|true

|`ddf.catalog.plugin.PreSubscriptionPlugin`
|optional
|true

|`ddf.catalog.resource.ResourceReader`
|optional
|true

|`ddf.catalog.source.ConnectedSource`
|optional
|true

|`ddf.catalog.source.FederatedSource`
|optional
|true

|`org.osgi.service.event.EventAdmin`
| 
|false

|===

==== Known Issues
None

=== Catalog Framework Camel Component

The catalog framework camel component supports creating, updating, and deleting metacards using the Catalog Framework from a Camel route.

==== URI Format

----
catalog:framework
----

===== Message Headers

====== Catalog Framework Producer

[cols="2*" options="header"]
|===
|Header
|Description

|operation
|the operation to perform using the catalog framework (possible values are CREATE \| UPDATE \| DELETE)
|===

===== Sending Messages to Catalog Framework Endpoint
	
====== Catalog Framework Producer

In Producer mode, the component provides the ability to provide different inputs and have the Catalog framework perform different operations based upon the header values.  

For the CREATE and UPDATE operation, the message body can contain a list of metacards or a single metacard object. 

For the DELETE operation, the message body can contain a list of strings or a single string object. The string objects represent the IDs of metacards to be deleted.  The exchange's "in" message will be set with the affected metacards. In the case of a CREATE, it will be updated with the created metacards. In the case of the UPDATE, it will be updated with the updated metacards and with the DELETE it will contain the deleted metacards.

[cols="3*" options="header"]
|===
|Header
|Message Body (Input)
|Exchange Modification (Output)

|operation = CREATE
|List<Metacard> or Metacard
|exchange.getIn().getBody() updated with List of Metacards created

|operation = UPDATE
|List<Metacard> or Metacard
|exchange.getIn().getBody() updated with List of Metacards updated

|operation = DELETE
|List<String> or String (representing metacard IDs)
|exchange.getIn().getBody() updated with List of Metacards deleted

|===

====== Samples

This example demonstrates:

. Reading in some sample data from the file system.
. Using a Java bean to convert the data into a metacard.
. Setting a header value on the Exchange.
. Sending the Metacard to the Catalog Framework component for ingestion.

[source,xml,linenums]
----
<route>
 <from uri="file:data/sampleData?noop=true“/>
    <bean ref="sampleDataToMetacardConverter" method="covertToMetacard"/>\
   <setHeader headerName="operation">
  <constant>CREATE</constant>
 </setHeader>
    <to uri="catalog:framework"/>
</route>
----


=== Working with the Catalog Framework

==== Catalog Framework Reference

The Catalog Framework can be requested from the OSGi registry.  See OSGi Services for more details on Blueprint injection.

.Blueprint Service Reference
[source,xml]
----
<reference id="catalogFramework" interface="ddf.catalog.CatalogFramework" /> 
----
===== Methods

====== Create, Update, and Delete

Create, Update, and Delete (CUD) methods add, change, or remove stored metadata in the local Catalog Provider.

.Create, Update, Delete Methods
[source,java,linenums]
----
public CreateResponse create(CreateRequest createRequest) throws IngestException, SourceUnavailableException;
public UpdateResponse update(UpdateRequest updateRequest) throws IngestException, SourceUnavailableException;
public DeleteResponse delete(DeleteRequest deleteRequest) throws IngestException, SourceUnavailableException; 
----

CUD operations process `PreIngestPlugin`s before execution and `PostIngestPlugin`s after execution.

====== Query

Query methods search metadata from available Sources based on the `QueryRequest` properties and Federation Strategy.  Sources could include Catalog Provider, Connected Sources, and Federated Sources.

.Query Methods
[source,java,linenums]
----
public QueryResponse query(QueryRequest query) throws UnsupportedQueryException,SourceUnavailableException, FederationException;
public QueryResponse query(QueryRequest queryRequest, FederationStrategy strategy) throws SourceUnavailableException, UnsupportedQueryException, FederationException;
----
Query requests process `PreQueryPlugin`s before execution and `PostQueryPlugin`s after execution.

====== Resources

Resource methods retrieve products from Sources.

.Resource Methods
[source,java,linenums]
----
public ResourceResponse getEnterpriseResource(ResourceRequest request) throwsIOException, ResourceNotFoundException, ResourceNotSupportedException;
public ResourceResponse getLocalResource(ResourceRequest request) throws IOException, ResourceNotFoundException, ResourceNotSupportedException;
public ResourceResponse getResource(ResourceRequest request, String resourceSiteName) throws IOException, ResourceNotFoundException, ResourceNotSupportedException; 
----
Resource requests process `PreResourcePlugin`s before execution and `PostResourcePlugin`s after execution.

====== Sources

Source methods can get a list of Source identifiers or request descriptions about Sources.

.Source Methods
[source,java,linenums]
----
public Set<String> getSourceIds();
public SourceInfoResponse getSourceInfo(SourceInfoRequest sourceInfoRequest) throws SourceUnavailableException;
----

====== Transforms

Transform methods provide convenience methods for using Metacard Transformers and Query Response Transformers.

.Transform Methods
[source,java,linenums]
----
// Metacard Transformer
public BinaryContent transform(Metacard metacard, String transformerId, Map<String,Serializable> requestProperties) throws CatalogTransformerException;

// Query Response Transformer 
public BinaryContent transform(SourceResponse response, String transformerId, Map<String, Serializable> requestProperties) throws CatalogTransformerException; 
----
=== Developing Complementary Frameworks

DDF and the underlying OSGi technology can serve as a robust infrastructure for developing frameworks that complement the DDF Catalog.

Recommendations for Framework Development

. Provide extensibility similar to that of the DDF Catalog.
.. Provide a stable API with interfaces and simple implementations (refer to `http://www.ibm.com/developerworks/websphere/techjournal/1007_charters/1007_charters.html`).
. Make use of the DDF Catalog wherever possible to store, search, and transform information.
. Utilize OSGi standards wherever possible.
.. ConfigurationAdmin
.. MetaType
. Utilize the sub-frameworks available in DDF.
.. Karaf
.. CXF
.. PAX Web and Jetty

=== Developing Console Commands

==== Console Commands

DDF supports development of custom console commands. For more information, see the Karaf website on Extending the Console (`http://karaf.apache.org/manual/latest-2.2.x/developers-guide/extending-console.html`). 

==== Custom DDF Console Commands

DDF includes custom commands for working with the Catalog, as described in the Console Commands section.

== Extending Sources
Catalog sources are used to connect Catalog components to data sources, local and remote. Sources act as proxies to the actual external data sources, e.g., a RDBMS database or a NoSQL database.

[ditaa, sources_architecture, png]
....
+----------------------------------------------------------------------------------------------+
|                /-------------------\                                               +-=------+|
|                |cDEFEndpoints      |            /-----------------------------\    |External||
|                +------------+------+            |c369   Remote Sources        |    | Data{s}||
|                |cDEF        |cDEF  |            | /-------------------------\ |    |Holdings||
|                | Operations | Data |            | |c369Federated Sources    |-+--> +--------+|
|/---------------+------------+------+------------+ +-------------------------+ |              |
||cDEF           |cDEF               |cDEF        | |c369Connected Sources    |-+--> +-=------+|
||  Transformers |                   | Federation | \-------------------------/ |    |External||
|+---------------+ Catalog Framework +------------+-----------------------------+    | Data{s}||
||cDEF           |                   |cDEF           Eventing                   |    |Holdings||
||   Catalog     |                   +------------------------------------------+    +--------+|
||   Plugins     |                   |cDEF           Resources                  |              |
|\---------------+-------------------+------------------------------------------/              |
|                |c369               |                                                         |
|                | Catalog Provider  |                                                         |
|                \-------------------/                                                         |
|                          |                                                                   |
|                          v                                                                   |
|                  +-=-------------+                                                           |
|                  |               |                                                           |
|                  |{s}Data Store  |                                                           |
|                  +---------------+                                                           |
+----------------------------------------------------------------------------------------------
....
=== Existing Source Types

==== Catalog Provider
A Catalog provider provides an implementation of a searchable and writable catalog.  All sources, including federated source and connected source, support queries, but a Catalog provider also allows metacards to be created, updated, and deleted.

A Catalog provider typically connects to an external application or a storage system (e.g., a database), acting as a proxy for all catalog operations.
===== Using
The Standard Catalog Framework uses only one Catalog provider, determined by the OSGi Framework as the service reference with the highest service ranking.  In the case of a tie, the service with the lowest service ID (first created) is used.

The Catalog Fanout Framework App does not use a Catalog provider and will fail any create/update/delete operations even if there are active Catalog providers configured.

The Catalog reference implementation comes with a Solr Catalog Provider out of the box.

==== Remote Sources
Remote sources are read-only data sources that support query operations but cannot be used to create, update, or delete metacards. 

[TIP]
====
Remote sources currently extend the ResourceReader interface. However, a RemoteSource is not treated as a ResourceReader. The getSupportedSchemes() method should never be called on a RemoteSource, thus the suggested implementation for a RemoteSource is to return an empty set. TheretrieveResource( ... ) and getOptions( ... ) methods will be called and MUST be properly implemented by a RemoteSource.
====

==== Connected Source
A connected source is a remote source that is included in all local and federated queries but remains hidden from external clients. A connected source's identifier is removed in all query results by replacing it with DDF's source identifier. The Catalog Framework does not reveal a connected source as a separate source when returning source information responses.

.Connected Sources
image::query-flow.png[]

==== Federated Source
A federated source is a remote source that can be included in federated queries by request or as part of an enterprise query. Federated sources support query and site information operations only. Catalog modification operations, such as create, update, and delete, are not allowed. Federated sources also expose an event service, which allows the Catalog Framework to subscribe to even notifications when metacards are created, updated, and deleted.
DDF Catalog instances can also be federated to each other. Therefore, a DDF Catalog can also act as a federated source to another DDF Catalog.

==== OpenSearch Source
The OpenSearch source provides a Federated Source that has the capability to do OpenSearch (http://www.opensearch.org/Home) queries for metadata from Content Discovery and Retrieval (CDR) Search V1.1 compliant sources. See http://www.dni.gov/index.php/about/organization/chief-information-officer/cdr-search for the CDR apecifications. The OpenSearch source does not provide a Connected Source interface.
The OpenSearch source converts a query into OpenSearch format and then sends that request to the CDR-compliant search service. It then accepts the response, formatted in Atom, and translates the Atom entries to DDMS resources (using the Atom Query Response Transformer). Existing DDMS is used from the Atom entries when available. If it is not available, a new DDMS document is created from the Atom information. If no (or incomplete) security markings are present, this bundle adds security markings per the security settings that were configured in the Default Security Settings feature. The OpenSearch source then splits out the DDMS documents into results, which are sent back to the endpoint/client via the Catalog Framework.

===== Installing and Uninstalling
The OpenSearch source can be installed and uninstalled using the normal processes described in the Configuring DDF section.

===== Configuring
This component can be configured using the normal processes described in the Configuring DDF section.
The configurable properties for the OpenSearch source are accessed from the Catalog OpenSearch Federated Source Configuration in the Web Console.

===== Configuring the OpenSearch Source

====== Configurable Properties
[cols="6*" options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Source Name	
|shortname	
|String	 	
|
|DDF-OS	
|Yes

|OpenSearch service URL	
|endpointUrl	
|String	
|The OpenSearch endpoint URL, e.g., DDF's OpenSearch endpoint (http://0.0.0.0:8181/services/catalog/query?q={searchTerms}...)	
|https://example.com?q={searchTerms}&amp;src={fs:routeTo?}&amp;mr={fs:maxResults?}&amp;count={count?}&amp;mt={fs:maxTimeout?}&amp;dn={idn:userDN?}&amp;lat={geo:lat?}&amp;lon={geo:lon?}&amp;radius={geo:radius?}&amp;bbox={geo:box?}&amp;polygon={geo:polygon?}&amp;dtstart={time:start?}&amp;dtend={time:end?}&amp;dateName={cat:dateName?}&amp;filter={fsa:filter?}&amp;sort={fsa:sort?}	
|Yes

|Username	
|username	
|String	
|Username to use with HTTP Basic Authentication. This auth info will overwrite any federated auth info. Only set this if the OpenSearch endpoint requires basic authentication.	 	
|
|No

|Password	
|password	
|String	
|Password to use with HTTP Basic Authentication. This auth info will overwrite any federated auth info. Only set this if the OpenSearch endpoint requires basic authentication.	 	
|
|No

|Always perform local query
|localQueryOnly	
|Boolean	
|Always performs a local query by setting src=local OpenSearch parameter in endpoint URL. *This must be set if federating to another DDF*. 
|false	
|Yes

|Convert to BBox	
|shouldConvertToBBox	
|Boolean	
|Converts Polygon and Point-Radius searches to a Bounding Box for compatibility with legacy interfaces. Generated bounding box is a very rough representation of the input geometry	
|true	
|Yes
 
|===

===== Using
Use the OpenSearch source if querying a CDR-compliant search service is desired. 

===== Source Details

====== Default Security Settings (applicable to all OpenSearch Sources)
These settings are used to provide default security settings for the Title, Description, and Security elements in a DDMS record. The purpose of these defaults is that many providers fail to deliver a classification and Owner/Producer with the metadata returned. These default settings are used if a metadata record is returned without security settings. *This feature can be turned on or off*.
. Open the Web Console.
.. `http://localhost:8181/system/console`
.. Username/Password: admin/admin
. Click on the `Configuration` tab.
. Find `Catalog Security Defaults`
. Select whether or not to apply these defaults by checking or unchecking the box marked "Apply Default Security Settings."
[TIP]
====
If checked, the default security settings specified in this configuration are applied to all records returned from the CDR-compliant Search Service that do not contain DDMS metadata. (If a metadata record is returned without DDMS, it also is without security markings). If unchecked, the records without the DDMS metadata are removed from the result set.
====
. If the applied defaults are selected, change the settings in the console to the default metadata security.
.. These settings can also be changed by editing the file `<INSTALL_DIRECTORY>/etc/ddf/ddf.DefaultSiteSecurity.cfg`
. Click Save at the bottom of the configuration window (or save the file).

[WARNING]
====
* In the CDR Open Search Service, if one of the properties has a blank value, the "last-resort" default is U and USA.
* If the DefaultSiteSecurity.cfg file is deleted, it needs to be replaced otherwise all classification values are set to "last-resort" defaults U and USA.
* After the file is replaced, either restart DDF or the restart the CDR Open Search Service to reload the property values.
====
[IMPORTANT]
====
If this feature is turned off, the records from a CDR-compliant Search Service without DDMS metadata are dropped out of the result set. This means that a Max Results of 20 query parameters is specified and there are only 15 records containing DDMS metadata, the result set only contains 15 records. The total count will accurately specify the number of records that match the query criteria in the Source that is queried.
====

===== Query Format

====== OpenSearch Parameter to DDF Query Mapping

[cols="2*" options="header"]
|===
|OpenSearch/CDR Parameter
|DDF Data Location

|q={searchTerms}	
|Pulled verbatim from DDF query.

|src={fs:routeTo?}	
|Unused

|mr={fs:maxResults?}	
|Pulled verbatim from DDF query.

|count={count?}	
|Pulled verbatim from DDF query.

|mt={fs:maxTimeout?}	
|Pulled verbatim from DDF query.

|dn={idn:userDN?}	
|DDF Subject

|lat={geo:lat?}	
|Pulled verbatim from DDF query.

|lon={geo:lon?}	
|Pulled verbatim from DDF query.

|radius={geo:radius?}	
|Pulled verbatim from DDF query.

|bbox={geo:box?}	
|Converted from Point-Radius DDF query.

|polygon={geo:polygon?}	
|Pulled verbatim from DDF query.

|dtstart={time:start?}	
|Pulled verbatim from DDF query.

|dtend={time:end?}	
|Pulled verbatim from DDF query.

|dateName={cat:dateName?}	
|Unused

|filter={fsa:filter?}	
|Unused

|sort={fsa:sort?}	
|Translated from DDF query.
Format: "relevance" or "date"
Supports "asc" and "desc" using colon as delimiter.

|===
===== Implementation Details
====== Exported Services

[cols="3*" options="header"]
|===

|Registered Interface
|Service Property
|Value

|ddf.catalog.source.FederatedSource
|
|

|===
 	 
===== Imported Services
[cols="4*" options="header"]
|===

|Registered Interface
|Availability
|Multiple
|Filter

|ddf.catalog.transform.InputTransformer
|required	
|false	
|(&amp;(mime-type=text/xml)(id=xml))

|===

===== Known Issues
The OpenSearch source does not provide a Connected Source interface.

=== Developing a Source
Sources are components that enable DDF to talk to back-end services. They let DDF perform query and ingest operations on catalog stores and query operations on federated sources. Sources reside in the Sources area of the DDF Overview.

==== Creating a New Source

===== Implement a Source Interface
There are three types of sources that can be created. All of these types of sources can perform a query operation. Operating on queries is the foundation for all sources. All of these sources must also be able to return their availability and the list of content types currently stored in their back-end data stores.

* Catalog Provider - `ddf.catalog.source.CatalogProvider` +
_Used to communicate with back-end storage. Allows for Query and Create/Update/Delete operations._
* Federated Source - `ddf.catalog.source.FederatedSource` +
_Used to communicate with remote systems. Only allows query operations._
* Connected Source - `ddf.catalog.source.ConnectedSource` +
_Similar to a Federated Source with the following exceptions:_
** _Queried on all local queries_
** _SiteName is hidden (masked with the DDF sourceId) in query results_
** _SiteService does not show this Source's information separate from DDF's._

The procedure for implementing any of the source types follows a similar format:
. Create a new class that implements the specified Source interface.
. Implement the required methods.
. Create an OSGi descriptor file to communicate with the OSGi registry. (Refer to the OSGi Services  section.)
.. Import DDF packages.
.. Register source class as service to the OSGi registry.
. Deploy to DDF. (Refer to the Working with OSGi - Bundles section.)

===== Catalog Provider
. Create a Java class that implements CatalogProvider. +
`public class TestCatalogProvider implements ddf.catalog.source.CatalogProvider`
. Implement the required methods from the `ddf.catalog.source.CatalogProvider` interface. +
`public CreateResponse create(CreateRequest createRequest) throws IngestException;` 
`public UpdateResponset update(UpdateRequest updateRequest) throws IngestException;`
`public DeleteResponse delete(DeleteRequest deleteRequest) throws IngestException;`

. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog, ddf.catalog.source`
. Export the service to the OSGi registry.

.Blueprint example
[source,xml]
----
<service ref="[[TestCatalogProvider]]" interface="ddf.catalog.source.CatalogProvider" />
----
The DDF Integrator's Guide provides details on the following Catalog Providers that come with DDF out of the box (refer to the Dummy Catalog Provider).
[NOTE]
====
A code example of a Catalog Provider delivered with DDF is the Catalog Solr Embedded Provider.
====

===== Federated Source
. Create a Java class that implements `FederatedSource`. +
`public class TestFederatedSource implements ddf.catalog.source.FederatedSource`
. Implement the required methods of the `ddf.catalog.source.FederatedSource` interface.
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog, ddf.catalog.source`
. Export the service to the OSGi registry.

.Blueprint example
[source,xml]
----
<service ref="[[TestFederatedSource]]" interface="ddf.catalog.source.FederatedSource" />
----
The DDF Integrator's Guide provides details on the following Federated Sources that come with DDF out of the box (refer to OpenSearch Source).
[NOTE]
====
A code example of a Federated Source delivered with DDF can be found in `ddf.catalog.source.solr`
====

===== Connected Source
. Create a Java class that implements `ConnectedSource`. +
`public class TestConnectedSource implements ddf.catalog.source.ConnectedSource`
. Implement the required methods of the `ddf.catalog.source.ConnectedSource` interface.
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog, ddf.catalog.source`
. Export the service to the OSGi registry.

.Blueprint example
[source,xml,linenums]
----
<service ref="[[TestConnectedSource]]" interface="ddf.catalog.source.ConnectedSource" />
----
[IMPORTANT]
====
In some Providers that are created, there is a need to make Web Service calls through JAXB clients. It is best NOT to create your JAXB client as a global variable. We have seen intermittent failures with the creation of Providers and federated sources when clients are created in this manner. Create your JAXB clients every single time within the methods that require it in order to avoid this issue.
====

===== Exception Handling
In general, sources should only send information back related to the call, not implementation details.

===== Examples
* "Site XYZ not found" message rather than the full stack trace with the original site not found exception.
* The caller issues a malformed search request. Return an error describing the right form, or specifically what was not recognized in the request. Do not return the exception and stack trace where the parsing broke.
* The caller leaves something out. Do not return the null pointer exception with a stack trace, rather return a generic exception with the message "xyz was missing."

====== Additional Information 
* Three Rules for Effective Exception Handling (http://today.java.net/pub/a/today/2003/12/04/exceptions.html)

==== Developing a Filter Delegate
Filter Delegates help reduce the complexity of parsing OGC Filters.  The reference Filter Adapter implementation contains the necessary boilerplate visitor code and input normalization to handle commonly supported OGC Filters.

===== Creating a New Filter Delegate
A Filter Delegate contains the logic that converts normalized filter input into a form that the targeted data source can handle.  Delegate methods will be called in a depth first order as the Filter Adapter visits filter nodes.

===== Implementing the Filter Delegate
. Create a Java class extending FilterDelegate. +
`public class ExampleDelegate extends ddf.catalog.filter.FilterDelegate<ExampleReturnObjectType> {`
. FilterDelegate will throw an appropriate exception for all methods not implemented.  Refer to the DDF JavaDoc for more details about what is expected of each FilterDelegate method.

[NOTE]
====
A code example of a Filter Delegate can be found in ddf.catalog.filter.proxy.adapter.test of the filter-proxy bundle.
====

===== Throwing Exceptions
Filter delegate methods can throw `UnsupportedOperationException` run-time exceptions.  The `GeotoolsFilterAdapterImpl` will catch and re-throw these exceptions as UnsupportedQueryExceptions.

===== Using the Filter Adapter
The FilterAdapter can be requested from the OSGi registry. (Refer to Working with OSGi for more details on Blueprint injection.)
[source,xml]
----
<reference id="filterAdapter" interface="ddf.catalog.filter.FilterAdapter" />
----
The Query in a QueryRequest implements the Filter interface.  The Query can be passed to a `FilterAdapter` and `FilterDelegate` to process the Filter.

[source,java,linenums]
----
@Override
public ddf.catalog.operation.QueryResponse query(ddf.catalog.operation.QueryRequest queryRequest) 
    throws ddf.catalog.source.UnsupportedQueryException {
     
    ddf.catalog.operation.Query query = queryRequest.getQuery();
     
    ddf.catalog.filter.FilterDelegate<ExampleReturnObjectType> delegate = new ExampleDelegate();
 
    // ddf.catalog.filter.FilterAdapter adapter injected via Blueprint
    ExampleReturnObjectType result = adapter.adapt(query, delegate);
}
----
Import the DDF Catalog API Filter package and the reference implementation package of the Filter Adapter in the bundle manifest  (in addition to any other required packages). +
`Import-Package: ddf.catalog, ddf.catalog.filter, ddf.catalog.source`
===== Filter Support
Not all OGC Filters are exposed at this time.  If demand for further OGC Filter functionality is requested, it can be added to the Filter Adapter and Delegate so sources can support more complex filters.  The following OGC Filter types are currently available:

[cols="1" options="header"]
|===
|Logical
|And
|Or
|Not
|Include
|Exclude
|===

[cols="1" options="header"]
|===
|Property Comparison
|PropertyIsBetween
|PropertyIsEqualTo
|PropertyIsGreaterThan
|PropertyIsGreaterThanOrEqualTo
|PropertyIsLessThan
|PropertyIsLessThanOrEqualTo
|PropertyIsLike
|PropertyIsNotEqualTo
|PropertyIsNull
|===

[cols="2,5" options="header"]
|===
|Spatial
|Definition

|Beyond	
|True if the geometry being tested is beyond the stated distance of the geometry provided.

|Contains	
|True if the second geometry is wholly inside the first geometry.

|Crosses
|True if the intersection of the two geometries results in a value whose dimension is less than the geometries and the maximum dimension of the intersection value includes points interior to both the geometries, and the intersection value is not equal to either of the geometries.

|Disjoint	
|True if the two geometries do not touch or intersect.

|DWithin	
|True if the geometry being tested is within the stated distance of the geometry provided.

|Intersects	
|True if the two geometries intersect. This is a convenience method as you could always ask for Not Disjoint(A,B) to get the same result.

|Overlaps	
|True if the intersection of the geometries results in a value of the same dimension as the geometries that is different from both of the geometries.

|Touches
|True if and only if the only common points of the two geometries are in the union of the boundaries of the geometries.

|Within	
|True if the first geometry is wholly inside the second geometry.
|===

[cols="1" options="header"]
|===
|Temporal
|After (http://docs.geotools.org/latest/javadocs/org/opengis/filter/temporal/After.html)
|Before (http://docs.geotools.org/latest/javadocs/org/opengis/filter/temporal/Before.html)
|During (http://docs.geotools.org/latest/javadocs/org/opengis/filter/temporal/During.html)
|===

== Extending Catalog Transformers

Transformers transform data to and from various formats. Transformers can be categorized on the basis of when they are invoked and used. The existing types are Input transformers, Metacard transformers, and Query Response transformers. Additionally, XSLT transformers are provided to aid in developing custom, lightweight Metacard and Query Response transformers.
Transformers are utility objects used to transform a set of standard DDF components into a desired format, such as into PDF, GeoJSON, XML, or any other format. For instance, a transformer can be used to convert a set of query results into an easy-to-read GeoJSON format (GeoJSON Transformer) or convert a set of results into a RSS feed that can be easily published to a URL for RSS feed subscription. A major benefit of transformers is that they can be registered in the OSGi Service Registry so that any other developer can access them based on their standard interface and self-assigned identifier, referred to as its "shortname." Transformers are often used by endpoints for data conversion in a system standard way. Multiple endpoints can use the same transformer, a different transformer, or their own published transformer. 

[ditaa, catalog_architecture_plugins, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       | 
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||c369           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....
[WARNING]
====
The current transformers do not support Non-Western Characters (e.g., Hebrew). If the data being transformed contains these characters, they may not be displayed properly. For example, the characters after transformation are not displayed properly (e.g., the word will show up as squares). In other words, transformers only work for UTF-8. It is recommend not to use international character sets.
====

.Communication Diagram
[ditaa, transformer_communication_diagram, png]
....
/------\
|Client|
|cDEF  |
\------/
    ^
    |
+-------------------------------------------\
|DDF|                                  cCCC |
|   v                                       |
|/--------\   /-----------------\   /------\|
||Endpoint|<->|Catalog Framework|<->|Source||
|| cDEF   |   | cDEF            |   | cDEF ||
|\--------/   \-----------------/   \------/|
|                      ^                    |
|                      |                    |
|                      v                    |
|               /-------------\             |
|               | Transformer |             |
|               |  cDEF       |             |
|               \-------------/             |
\-------------------------------------------/
....

=== Working with Transformers
The `ddf.catalog.transform` package includes the `InputTransformer`, `MetacardTransformer`, and `QueryResponseTransformer` interfaces. All implementations can be accessed using the Catalog Framework or OSGi Service Registry, as long as the implementations have been registered with the Service Registry. 

==== Catalog Framework
The `CatalogFramework` provides convenient methods to transform `Metacards` and `QueryResponses` using a reference to the `CatalogFramework`. See Working with the Catalog Framework for more details on the method signatures.
It is easy to execute the convenience `transform` methods on the `CatalogFramework` instance.
.Query Response Transform Example
[source,java,linenums]
----
// inject CatalogFramework instance or retrieve an instance 
private CatalogFramework catalogFramework; 

public RSSEndpoint(CatalogFramework catalogFramework)
{
     this.catalogFramework = catalogFramework ;
     // implementation
}

 // Other implementation details ...

private void convert(QueryResponse queryResponse ) {
    // ...
    String transformerId = "rss";

    BinaryContent content = catalogFramework.transform(queryResponse, transformerId, null);
   
    // ...

}
----

[cols="2,5" options="header"]
|===
|Line #
|Action
|4	
|`CatalogFramework` is injected, possibly by dependency injection framework.

|16	
|`queryResponse` is transformed into the RSS format, which is stored in the `BinaryContent` instance
|===

==== Dependency Injection
Using Blueprint or another injection framework, transformers can be injected from the OSGi Service Registry. See OSGi Services for more details on how to use injected instances.

.Blueprint Service Reference
[source,xml]
----
<reference id="[[Reference Id]]" interface="ddf.catalog.transform.[[Transformer Interface Name]]" filter="(shortname=[[Transformer Identifier]])" />
----
Each transformer has one or more `transform` methods that can be used to get the desired output.

.Input Transformer Example
[source,java,linenums]
----
ddf.catalog.transform.InputTransformer inputTransformer = retrieveInjectedInstance() ;
  
Metacard entry = inputTransformer.transform(messageInputStream);
----

.Metacard Transformer Example
[source,java,linenums]
----
ddf.catalog.transform.MetacardTransformer metacardTransformer = retrieveInjectedInstance() ;
 
BinaryContent content = metacardTransformer.transform(metacard, arguments);
----

.Query Response Transformer Example
[source,java,linenums]
----
ddf.catalog.transform.QueryResponseTransformer queryResponseTransformer = retrieveInjectedInstance() ;
 
BinaryContent content = queryResponseTransformer.transform(sourceSesponse, arguments);
----
See Working with OSGi - Service Registry for more details.

==== OSGi Service Registry
[IMPORTANT]
====
In the vast majority of cases, working with the OSGi Service Reference directly should be avoided. Instead, dependencies should be injected via a dependency injection framework like Blueprint.
====
Transformers are registered with the OSGi Service Registry. Using a `BundleContext` and a filter, references to a registered service can be retrieved. 

.OSGi Service Registry Reference Example
[source,java,linenums]
----
ServiceReference[] refs =
    bundleContext.getServiceReferences(ddf.catalog.transform.InputTransformer.class.getName(),"(shortname=" + transformerId + ")");
InputTransformer inputTransformer = (InputTransformer) context.getService(refs[0]);
Metacard entry = inputTransformer.transform(messageInputStream);
----

==== Included Input Transformers
An input transformer transforms raw data (text/binary) into a Metacard.

Once converted to a Metacard, the data can be used in a variety of ways, such as in an UpdateRequest, CreateResponse, or within Catalog Endpoints or Extending Sources. For instance, an input transformer could be used to receive and translate XML into a Metacard so that it can be placed within a CreateRequest in order to be ingested within the Catalog. Input transformers should be registered within the Service Registry with the following interface ddf.catalog.transform.InputTransformer in order to notify some Catalog components of any new transformers.

===== Tika Input Transformer
The Tika Input Transformer is the default input transformer responsible for translating Microsoft Word, Microsoft Excel, Microsoft PowerPoint, OpenOffice Writer, and PDF documents into a Catalog Metacard. This input transformer utilizes Apache Tika to provide basic support for these mime types. As such, the metadata extracted from these types of documents is the metadata that is common across all of these document types, e.g., creation date, author, last modified date, etc. The Tika Input Transformer's main purpose is to ingest these types of content into the DDF Content Repository and the Metadata Catalog.

The Tika input transformer is given a service ranking (prioity) of -1 so that it is guaranteed to be the last input transformer that is invoked. This allows any registered input transformer that are more specific for any of these document types to be invoked instead of this rudimentary default input transformer.

====== Installing and Uninstalling
Install the catalog-transformer-tika feature using the Web Console (http://localhost:8181/system/console) or System Console. This feature is uninstalled by default.

====== Configuring
None

====== Using
Use the Tika Input Transformer for ingesting Microsoft documents, OpenOffice documents, or PDF documents into the DDF Content Repository and/or the Metadata Catalog.

====== Service Properties

[cols="2,5" options="header"]
|===

|Key
|Value

|mime-type	
|application/pdf
application/vnd.openxmlformats-officedocument.wordprocessingml.document
application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
application/vnd.openxmlformats-officedocument.presentationml.presentation
application/vnd.openxmlformats-officedocument.presentationml.presentation
application/vnd.ms-powerpoint.presentation.macroenabled.12
application/vnd.ms-powerpoint.slideshow.macroenabled.12
application/vnd.openxmlformats-officedocument.presentationml.slideshow
application/vnd.ms-powerpoint.template.macroenabled.12
application/vnd.oasis.opendocument.text

|shortname	 
|

|id	 
|

|title	
|Tika Input Transformer

|description	
|Default Input Transformer for all mime types.
|service.ranking	
|-1
|===

====== Implementation Details
This input transformer maps the metadata common across all mime types to applicable metacard attributes in the default MetacardType.

===== GeoJSON Input Transformer
The GeoJSON input transformer is responsible for translating specific GeoJSON into a Catalog metacard. 

====== Installing and Uninstalling
Install the catalog-rest-endpoint feature using the Web Console (http://localhost:8181/system/console) or System Console.

====== Configuring
None

====== Using
Using the REST Endpoint, for example, HTTP POST a GeoJSON metacard to the Catalog.  Once the REST Endpoint receives the GeoJSON Metacard, it is converted to a Catalog metacard.  

.Example HTTP POST of a local metacard.json file using the Curl Command
----
curl -X POST -i -H "Content-Type: application/json" -d "@metacard.json" http://localhost:8181/services/catalog
----

====== Conversion
A GeoJSON object (http://geojson.org/geojson-spec.html#geojson-objects) consists of a single JSON object. The single JSON object can be a geometry, a feature, or a FeatureCollection. This input transformer only converts "feature" objects into metacards. This is a natural choice since feature objects include geometry information and a list of properties. For instance, if only a geometry object is passed, such as only a LineString, that is not enough information to create a metacard. This input transformer currently does not handle FeatureCollections either, but could be supported in the future.

[IMPORTANT]
====

.Cannot create Metacard from this limited GeoJSON
[source,javascript,linenums]
----
{ "type": "LineString",
 "coordinates": [ [100.0, 0.0], [101.0, 1.0] ]
 }
----
====

The following _sample_ will create a valid metacard:
.Sample Parseable GeoJson (Point)
[source,javascript,linenums]
----
{
    "properties": {
        "title": "myTitle",
        "thumbnail": "CA==",
        "resource-uri": "http://example.com",
        "created": "2012-09-01T00:09:19.368+0000",
        "metadata-content-type-version": "myVersion",
        "metadata-content-type": "myType",
        "metadata": "<xml></xml>",
        "modified": "2012-09-01T00:09:19.368+0000"
    },
    "type": "Feature",
    "geometry": {
        "type": "Point",
        "coordinates": [
            30.0,
            10.0
        ]
    }
} 
----

In the current implementation, `Metacard.LOCATION` is not taken from the properties list as WKT, but instead interpreted from the `geometry` JSON object. The geometry object is formatted according to the GeoJSON (http://geojson.org/geojson-spec.html)standard. Dates are in the ISO 8601 standard. White space is ignored, as in most cases with JSON. Binary data is accepted as Base64. XML must be properly escaped, such as what is proper for normal JSON. 

Only Required Attributes are recognized in the properties currently.

====== Metacard Extensibility
GeoJSON supports custom, extensible properties on the incoming GeoJSON.  It uses {branding}'s extensible metacard support to do this.  To have those customized attributes understood by the system, a corresponding MetacardType must be registered with the MetacardTypeRegistry.  That MetacardType must be specified by name in the metacard-type property of the incoming GeoJSON. If a MetacardType is specified on the GeoJSON input, the customized properties can be processed, cataloged, and indexed. 

[source,javascript,linenums]
----
{
    "properties": {
        "title": "myTitle",
        "thumbnail": "CA==",
        "resource-uri": "http://example.com",
        "created": "2012-09-01T00:09:19.368+0000",
        "metadata-content-type-version": "myVersion",
        "metadata-content-type": "myType",
        "metadata": "<xml></xml>",
        "modified": "2012-09-01T00:09:19.368+0000",
        "min-frequency": "10000000",
        "max-frequency": "20000000",
        "metacard-type": "ddf.metacard.custom.type"
 },
    "type": "Feature",
    "geometry": {
        "type": "Point",
        "coordinates": [
            30.0,
            10.0
        ]
    }
}
----
When the GeoJSON Input Transformer gets GeoJSON with the MetacardType specified, it will perform a lookup in the MetacardTypeRegistry to obtain the specified MetacardType in order to understand how to parse the GeoJSON.  If no MetacardType is specified, the GeoJSON Input Transformer will assume the default MetacardType.  If an unregistered MetacardType is specified, an exception will be returned to the client indicating that the MetacardType was not found.

====== Packaging Details
_Feature Information_

N/A

_Included Bundles_

N/A

_Services_

_Exported Services_

.ddf.catalog.transform.InputTransformer
[cols="2"]
|===

|mime-type	
|application/json

|id	
|geojson

|===

====== Implementation Details
.Exported Services
[cols="3"]
|===

|Registered Interface	
|Service Property	
|Value

|`ddf.catalog.transform.InputTransformer`	
|mime-type	
|application/json

|
|id	
|geojson

|===

====== Known Issues
Does not handle multiple geometries yet.

=== Developing an Input Transformer
==== Using Java

. Create a new Java class that implements ddf.catalog.transform.InputTransformer. +
`public class SampleInputTransformer implements ddf.catalog.transform.InputTransformer`
. Implement the transform methods. +
`public Metacard transform(InputStream input) throws IOException, CatalogTransformerException` +
`public Metacard transform(InputStream input, String id) throws IOException, CatalogTransformerException`
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.transform`
. Create an OSGi descriptor file to communicate with the OSGi Service Registry (described in the Working with OSGi section). Export the service to the OSGi Registry and declare service properties.

.Blueprint descriptor example
[source,xml,linenums]
----
...
<service ref="[[SampleInputTransformer]]" interface="ddf.catalog.transform.InputTransformer">
    <service-properties>
        <entry key="shortname" value="[[sampletransform]]" />
        <entry key="title" value="[[Sample Input Transformer]]" />
        <entry key="description" value="[[A new transformer for metacard input.]]" />
    </service-properties>
</service>
...
----
. Deploy OSGi Bundle to OSGi runtime.

===== Variable Descriptions

.Blueprint Service Properties
[cols="1,3,2" options="header"]
|===

|Key
|Description of Value
|Example

|shortname	
|(Required) An abbreviation for the return-type of the BinaryContent being sent to the user.	
|_atom_

|title	
|(Optional) A user-readable title that describes (in greater detail than the shortname) the service.	
|_Atom Entry Transformer Service_

|description	
|(Optional) A short, human-readable description that describes the functionality of the service and the output.	
|_This service converts a single metacard xml document to an atom entry element._

|===

===== Create an Input Transformer Using Apache Camel
Alternatively, make an Apache Camel route in a blueprint file and deploy it using a feature file or via hot deploy.

===== Design Pattern

====== From
When using *from* `catalog:inputtransformer?id=text/xml`, an Input Transformer will be created and registered in the OSGi registry with an id of `text/xml`.

====== To
When using *to* `catalog:inputtransformer?id=text/xml`, an Input Transformer with an id matching text/xml will be discovered from the OSGi registry and invoked.

====== Message Formats
.InputTransformer
[cols="3,2,1" optiona="header"]
|===

|Exchange Type
|Field
|Type

|Request (comes from <from> in the route)	
|body	
|java.io.InputStream

|Response (returned after called via <to> in the route)	
|body	
|`ddf.catalog.data.Metacard`

|===

====== Examples
.InputTransformer Creation
[source,xml,linenums]
----
<blueprint xmlns="http://www.osgi.org/xmlns/blueprint/v1.0.0">
    <camelContext xmlns="http://camel.apache.org/schema/blueprint">
        <route>
            <from uri="catalog:inputtransformer?mimeType=RAW(id=text/xml;id=vehicle)"/>
            <to uri="xslt:vehicle.xslt" /> <!-- must be on classpath for this bundle -->
            <to uri="catalog:inputtransformer?mimeType=RAW(id=application/json;id=geojson)" />
        </route>
    </camelContext>
</blueprint>
----
[TIP]
====
Its always a good idea to wrap the mimeType value with the RAW parameter as shown in the example above. This will ensure that the value is taken exactly as is, and is especially useful when you are using special characters.
====

[cols="1,8" options="header"]
|===

|Line Number
|Description

|1	
|Defines this as an Apache Aries blueprint file.

|2	
|Defines the Apache Camel context that contains the route.

|3	
|Defines start of an Apache Camel route.

|4	
|Defines the endpoint/consumer for the route. In this case it is the DDF custom catalog component that is an InputTransformer registered with an id of text/xml;id=vehicle meaning it can transform an InputStream of vehicle data into a metacard.

*Note that the specified XSL stylesheet must be on the classpath of the bundle that this blueprint file is packaged in.*

|5	
|Defines the XSLT to be used to transform the vehicle input into GeoJSON format using the Apache Camel provided XSLT component.

|6	
Defines the route node that accepts GeoJSON formatted input and transforms it into a Mmtacard, using the DDF custom catalog component that is an InputTransformer registered with an id of application/json;id=geojson.
|===

[NOTE]
====
An example of using an Apache Camel route to define an `InputTransformer` in a blueprint file and deploying it as a bundle to an OSGi container can be found in the DDF SDK examples at `ddf/sdk/sample-transformers/xslt-identity-input-transformer`
====

=== Included Metacard InputTransformers
A metacard transformer transforms a metacard into other data formats.

==== HTML Metacard Transformer
The HTML metacard transformer is responsible for translating a metacard into an HTML formatted document.

===== Installing and Uninstalling
Install the catalog-transformer-html feature using the Web Console (http://localhost:8181/system/console) or System Console.

===== Configuring
None

===== Using
Using the REST Endpoint for example, request a metacard with the transform option set to the HTML shortname.
----
http://localhost:8181/services/catalog/0123456789abcdef0123456789abcdef?transform=html
----

====== Example Output
----
html metacard.png
----

===== Implementation Details
[cols="3*" options="header"]
|===
|Registered Interface	
|Service Property	
|Value

1.3+^|`ddf.catalog.transform.MetacardTransformer`	
|title	
|View as html...
|description	
|Transforms query results into html
|shortname (for backwards compatibility)	
|html

|===

===== Known Issues
None

==== XML Metacard Transformer
The XML metacard transformer is responsible for translating a metacard into an XML-formatted document. The metacard element that is generated is an extension of `gml:AbstractFeatureType`, which makes the output of this transformer GML 3.1.1 compatible. 

===== Installing and Uninstalling
This transformer comes installed out of the box and is running on startup. To install or uninstall manually, use the catalog-transformer-xml feature using the Web Console (http://localhost:8181/system/console) or System Console.

===== Configuring
None

===== Using
Using the REST Endpoint for example, request a metacard with the transform option set to the XML shortname.
----
http://localhost:8181/services/catalog/ac0c6917d5ee45bfb3c2bf8cd2ebaa67?transform=xml
----

====== Example Output

[NOTE]
====
The schema file for the XML metacard format, metacard.xsd, is attached to this page.
====

.Sample Output
[source,xml,linenums]
----
<ns3:metacard ns1:id="ac0c6917d5ee45bfb3c2bf8cd2ebaa67" xmlns:ns1="http://www.opengis.net/gml" xmlns:ns3="urn:catalog:metacard">
   <ns3:type>ddf.metacard</ns3:type>
   <ns3:source>ddf</ns3:source>
   <ns3:dateTime name="modified">
      <ns3:value>2013-01-29T17:09:19.980-07:00</ns3:value>
   </ns3:dateTime>
   <ns3:stringxml name="metadata">
      <ns3:value>
         <ddms:Resource xmlns:ddms="http://metadata.dod.mil/mdr/ns/DDMS/2.0/" xmlns:ICISM="urn:us:gov:ic:ism:v2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
            <ddms:identifier ddms:qualifier="http://example.test#URI" ddms:value="http://example.test.html"/>
            <ddms:title ICISM:classification="U" ICISM:ownerProducer="USA">Example Title</ddms:title>
            <ddms:description ICISM:classification="U" ICISM:ownerProducer="USA">Example description.</ddms:description>
            <ddms:dates ddms:posted="2013-01-29"/>
            <ddms:rights ddms:copyright="true" ddms:intellectualProperty="true" ddms:privacyAct="false"/>
            <ddms:creator ICISM:classification="U" ICISM:ownerProducer="USA">
               <ddms:Person>
                  <ddms:name>John Doe</ddms:name>
                  <ddms:surname>Doe</ddms:surname>
               </ddms:Person>
            </ddms:creator>
            <ddms:subjectCoverage>
               <ddms:Subject>
                  <ddms:category ddms:code="nitf" ddms:label="nitf" ddms:qualifier="SubjectCoverageQualifier"/>
                  <ddms:keyword ddms:value="schematypesearch"/>
               </ddms:Subject>
            </ddms:subjectCoverage>
            <ddms:temporalCoverage>
               <ddms:TimePeriod>
                  <ddms:start>2013-01-29</ddms:start>
                  <ddms:end>2013-01-29</ddms:end>
               </ddms:TimePeriod>
            </ddms:temporalCoverage>
            <ddms:security ICISM:classification="U" ICISM:ownerProducer="USA"/>
         </ddms:Resource>
      </ns3:value>
   </ns3:stringxml>
   <ns3:string name="resource-size">
      <ns3:value>N/A</ns3:value>
   </ns3:string>
   <ns3:geometry name="location">
      <ns3:value>
         <ns1:Point>
            <ns1:pos>2.0 1.0</ns1:pos>
         </ns1:Point>
      </ns3:value>
   </ns3:geometry>
   <ns3:dateTime name="created">
      <ns3:value>2013-01-29T17:09:19.980-07:00</ns3:value>
   </ns3:dateTime>
   <ns3:string name="resource-uri">
      <ns3:value>http://example.com</ns3:value>
   </ns3:string>
   <ns3:string name="metadata-content-type-version">
      <ns3:value>v2.0</ns3:value>
   </ns3:string>
   <ns3:string name="title">
      <ns3:value>Example Title</ns3:value>
   </ns3:string>
   <ns3:string name="metadata-content-type">
      <ns3:value>Resource</ns3:value>
   </ns3:string>
   <ns3:dateTime name="effective">
      <ns3:value>2013-01-29T17:09:19.980-07:00</ns3:value>
   </ns3:dateTime>
</ns3:metacard>
----

===== Implementation Details

====== Metacard to XML Mappings

[cols="2*" options="header"]
|===
|Metacard Variables
|XML Element

|id	
|metacard/@gml:id

|metacardType	
|metacard/type

|sourceId	
|metacard/source

|all other attributes	
|metacard/<AttributeType>[name='<AttributeName>']/value +
For instance, the value for the metacard attribute named "title" would be found at
metacard/string[@name='title']/value 
|===

====== AttributeTypes 
[cols="1*" options="header"]
|===
|XML Adapted Attributes
|boolean
|base64Binary
|dateTime
|double
|float
|geometry
|int
|long
|object
|short
|string
|stringxml
|===

===== Known Issues
None

==== GeoJSON Metacard Transformer
GeoJSON Metacard Transformer translates a Metacard into GeoJSON.

===== Installing and Uninstalling
Install the catalog-transformer-json feature using the Web Console (http://localhost:8181/system/console) or System Console.

===== Configuring
None

===== Using
The GeoJSON Metacard Transformer can be used programmatically by requesting a MetacardTransformer with the id geojson. It can also be used within the REST Endpoint by providing the transform option as geojson. 

.Example REST GET method with the GeoJSON MetacardTransformer
----
http://localhost:8181/services/catalog/0123456789abcdef0123456789abcdef?transform=geojson 
----

.Example Output
[source,javascript,linenums]
----
{
    "properties":{
        "title":"myTitle",
        "thumbnail":"CA==",
        "resource-uri":"http:\/\/example.com",
        "created":"2012-08-31T23:55:19.518+0000",
        "metadata-content-type-version":"myVersion",
        "metadata-content-type":"myType",
        "metadata":"<xml>text<\/xml>",
        "modified":"2012-08-31T23:55:19.518+0000",
        "metacard-type": "ddf.metacard"
    },
    "type":"Feature",
    "geometry":{
        "type":"LineString",
        "coordinates":[
            [
                30.0,
                10.0
            ],
            [
                10.0,
                30.0
            ],
            [
                40.0,
                40.0
            ]
        ]
    }
}
----

===== Implementation Details
[cols="3*" options="header"]
|===
|Registered Interface	|Service Property	|Value
1.3+^|ddf.catalog.transform.MetacardTransformer	
|mime-type	|application/json
|id	|geojson
|shortname (for backwards compatibility)	|geojson

|===

==== Known Issues
None

==== Thumbnail Metacard Transformer
The Thumbnail Metacard Transformer retrieves the thumbnail bytes of a Metacard by returning the `Metacard.THUMBNAIL` attribute value.

===== Installing and Uninstalling
This transformer is installed out of the box. To uninstall the transformer, you must stop or uninstall the bundle.

===== Configuring
None

===== Using
Endpoints or other components can retrieve an instance of the Thumbnail Metacard Transformer using its id `thumbnail`.

.Sample Blueprint Reference Snippet
[source,xml,linenums]
----
<reference id="metacardTransformer" interface="ddf.catalog.transform.MetacardTransformer" filter="(id=thumbnail)"/>
----
The Thumbnail Metacard Transformer returns a `BinaryContent` object of the `Metacard.THUMBNAIL` bytes and a MIME Type of `image/jpeg`.

===== Implementation Details
[cols="2*" option="header"]
|===
|Service Property	
|Value

|id	
|thumbnail

|shortname	
|thumbnail

|mime-type	
|image/jpeg
|===

===== Known Issues
None

==== Metadata Metacard Transformer
The Metadata Metacard Transformer returns the `Metacard.METADATA` attribute when given a metacard. The MIME Type returned is text/xml.

===== Installing and Uninstalling
Catalog Transformers application will install this feature when deployed. This transformer's feature, `catalog-transformer-metadata`, can be uninstalled or installed using the normal processes described in the Configuring DDF section of this documentation.

===== Configuring
None

===== Using
The Metadata Metacard Transformer can be used programmatically by requesting a MetacardTransformer with the id metadata. It can also be used within the REST Endpoint by providing the transform option as metadata. 

.Example REST GET method with the Metadata MetacardTransformer
----
http://localhost:8181/services/catalog/0123456789abcdef0123456789abcdef?transform=metadata
----

===== Implementation Details
[cols="3" options="header"]
|===
|Registered Interface	
|Service Property	
|Value

1.3+^|ddf.catalog.transform.MetacardTransformer	
|mime-type	|text/xml
|id	|metadata
|shortname (for backwards compatibility)	
|metadata
|===

===== Known Issues
None.

==== Resource Metacard Transformer
The Resource Metacard Transformer retrieves the resource bytes of a metacard by returning the product associated with the metacard.

===== Installing and Uninstalling
This transformer is installed by installing the feature associated with the transformer "catalog-transformer-resource". To uninstall the transformer, you must uninstall the feature "catalog-transformer-resource".

===== Configuring
None

===== Using
Endpoints or other components can retrieve an instance of the Resource Metacard Transformer using its id resource.

.Sample Blueprint Reference Snippet
[source,xml]
----
<reference id="metacardTransformer" interface="ddf.catalog.transform.MetacardTransformer" filter="(id=resource)"/>
----

===== Implementation Details

[cols="3" options="header"]
|===
|Service Property	|Value

|id	
|resource

|shortname	
|resource

|mime-type	
|application/octet-stream

|title	
|Get Resource ...
|===

===== Known Issues
None

=== Developing a Metacard Transformer
In general, a `MetacardTransformer` is used to transform a `Metacard` into some desired format useful to the end user or as input to another process. Programmatically, a `MetacardTransformer` transforms a `Metacard` into a `BinaryContent` instance, which contains the translated `Metacard` into the desired final format. Metacard transformers can be used through the Catalog Framework `transform` convenience method or requested from the OSGi Service Registry by endpoints or other bundles. 

==== Create a New Metacard Transformer 
. Create a new Java class that implements `ddf.catalog.transform.MetacardTransformer`. +
`public class SampleMetacardTransformer implements ddf.catalog.transform.MetacardTransformer`
. Implement the transform method. +
`public BinaryContent transform(Metacard metacard, Map<String, Serializable> arguments) throws CatalogTransformerException`
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog,ddf.catalog.transform`
. Create an OSGi descriptor file to communicate with the OSGi Service registry (described in the Working with OSGi section). Export the service to the OSGi registry and declare service properties.

.Blueprint descriptor example
[source,xml,linenums]
----
...
<service ref="[[SampleMetacardTransformer]]" interface="ddf.catalog.transform.MetacardTransformer">
    <service-properties>
        <entry key="shortname" value="[[sampletransform]]" />
        <entry key="title" value="[[Sample Metacard Transformer]]" />
        <entry key="description" value="[[A new transformer for metacards.]]" />
    </service-properties>
</service>
...
----

Deploy OSGi Bundle to OSGi runtime.

===== Variable Descriptions

.Blueprint Service properties
[cols="3" options="header"]
|===
|Key
|Description of Value
|Example

|shortname	
|(Required) An abbreviation for the return type of the BinaryContent being sent to the user.	
|atom

|title	
|(Optional) A user-readable title that describes (in greater detail than the shortname) the service.	
|Atom Entry Transformer Service

|description	
|(Optional) A short, human-readable description that describes the functionality of the service and the output.	
|This service converts a single metacard xml document to an atom entry element.
|===

==== Included Query Response Transformers
Query Response transformers convert query responses into other data formats.

===== Atom Query Response Transformer
The Atom Query Response Transformer transforms a query response into an Atom 1.0 (http://tools.ietf.org/html/rfc4287) feed. The Atom transformer maps a `QueryResponse` object as described in the Query Result Mapping. 

===== Installing and Uninstalling
Catalog Transformers application will install this feature when deployed. This transformer's feature, `catalog-transformer-atom`, can be uninstalled or installed using the normal processes described in the Configuring DDF section.

===== Configuring
none.

===== Using
Use this transformer when Atom is the preferred medium of communicating information, such as for feed readers or federation. An integrator could use this with an endpoint to transform query responses into an Atom feed. 

For example, clients can use the OpenSearch Endpoint (https://tools.codice.org/#). The client can query with the format option set to the shortname, atom. 

.Sample OpenSearch query with Atom specified as return format
----
http://localhost:8181/services/catalog/query?q=ddf?format=atom
----

Developers could use this transformer to programmatically transform QueryResponse objects on the fly. (See Implementation Details for details about acquiring the service.)

====== Sample Results

.Sample Atom Feed from QueryResponse object
[source,xml,linenums]
----
 <feed xmlns="http://www.w3.org/2005/Atom" xmlns:os="http://a9.com/-/spec/opensearch/1.1/">
    <title type="text">Query Response</title>
    <updated>2013-01-31T23:22:37.298Z</updated>
    <id>urn:uuid:a27352c9-f935-45f0-9b8c-5803095164bb</id>
    <link href="#" rel="self" />
    <author>
        <name>Lockheed Martin</name>
    </author>
    <generator version="2.1.0.20130129-1341">ddf123</generator>
    <os:totalResults>1</os:totalResults>
    <os:itemsPerPage>10</os:itemsPerPage>
    <os:startIndex>1</os:startIndex>
    <entry xmlns:relevance="http://a9.com/-/opensearch/extensions/relevance/1.0/" xmlns:fs="http://a9.com/-/opensearch/extensions/federation/1.0/"
        xmlns:georss="http://www.georss.org/georss">
        <fs:resultSource fs:sourceId="ddf123" />
        <relevance:score>0.19</relevance:score>
        <id>urn:catalog:id:ee7a161e01754b9db1872bfe39d1ea09</id>
        <title type="text">F-15 lands in Libya; Crew Picked Up</title>
        <updated>2013-01-31T23:22:31.648Z</updated>
        <published>2013-01-31T23:22:31.648Z</published>
        <link href="http://123.45.67.123:8181/services/catalog/ddf123/ee7a161e01754b9db1872bfe39d1ea09" rel="alternate" title="View Complete Metacard" />
        <category term="Resource" />
        <georss:where xmlns:gml="http://www.opengis.net/gml">
            <gml:Point>
                <gml:pos>32.8751900768792 13.1874561309814</gml:pos>
            </gml:Point>
        </georss:where>
        <content type="application/xml">
            <ns3:metacard xmlns:ns3="urn:catalog:metacard" xmlns:ns2="http://www.w3.org/1999/xlink" xmlns:ns1="http://www.opengis.net/gml"
                xmlns:ns4="http://www.w3.org/2001/SMIL20/" xmlns:ns5="http://www.w3.org/2001/SMIL20/Language" ns1:id="4535c53fc8bc4404a1d32a5ce7a29585">
                <ns3:type>ddf.metacard</ns3:type>
                <ns3:source>ddf.distribution</ns3:source>
                <ns3:geometry name="location">
                    <ns3:value>
                        <ns1:Point>
                            <ns1:pos>32.8751900768792 13.1874561309814</ns1:pos>
                        </ns1:Point>
                    </ns3:value>
                </ns3:geometry>
                <ns3:dateTime name="created">
                    <ns3:value>2013-01-31T16:22:31.648-07:00</ns3:value>
                </ns3:dateTime>
                <ns3:dateTime name="modified">
                    <ns3:value>2013-01-31T16:22:31.648-07:00</ns3:value>
                </ns3:dateTime>
                <ns3:stringxml name="metadata">
                    <ns3:value>
                        <ns6:xml xmlns:ns6="urn:sample:namespace" xmlns="urn:sample:namespace">Example description.</ns6:xml>
                    </ns3:value>
                </ns3:stringxml>
                <ns3:string name="metadata-content-type-version">
                    <ns3:value>myVersion</ns3:value>
                </ns3:string>
                <ns3:string name="metadata-content-type">
                    <ns3:value>myType</ns3:value>
                </ns3:string>
                <ns3:string name="title">
                    <ns3:value>Example title</ns3:value>
                </ns3:string>
            </ns3:metacard>
        </content>
    </entry>
</feed>
----

====== Query Result Mapping
[cols="2,3a" options="header"]
|===

|XPath to Atom XML
|Value

|/feed/title	
|"Query Response"

|/feed/updated	
|ISO 8601 dateTime of when the feed was generated

|/feed/id	
|Generated UUID URN (http://en.wikipedia.org/wiki/Universally_Unique_Identifier)

|/feed/author/name	
|Platform Global Configuration organization

|/feed/generator	
|Platform Global Configuration site name

|/feed/generator/@version	
|Platform Global Configuration version

|/feed/os:totalResults	
|SourceResponse Number of Hits

|/feed/os:itemsPerPage	
|Request's Page Size

|/feed/os:startIndex	
|Request's Start Index

|/feed/entry/fs:resultSource/@fs:sourceId	
|Source Id from which the Result came. Metacard.getSourceId()

|/feed/entry/relevance:score	
|Result's relevance score if applicable. `Result.getRelevanceScore()`

|/feed/entry/id	
|urn:catalog:id:<Metacard.ID>

|/feed/entry/title	
|Metacard.TITLE

|/feed/entry/updated	
|ISO 8601 dateTime of Metacard.MODIFIED

|/feed/entry/published	
|ISO 8601 dateTime of Metacard.CREATED

|/feed/entry/link[@rel='related']	
|URL to retrieve underlying resource (if applicable and link is available)

|/feed/entry/link[@rel='alternate']	
|Link to alternate view of the Metacard (if a link is available)

|/feed/entry/category	
|Metacard.CONTENT_TYPE

|/feed/entry//georss:where	
|GeoRSS GML of every Metacard attribute with format AttributeFormat.GEOMETRY

|/feed/entry/content	
|Metacard XML generated by ddf.catalog.transform.MetacardTransformer with shortname=xml.
If no transformer found, /feed/entry/content/@type will be text and Metacard.ID is displayed 

.Sample Content with no Metacard Transformation
[source,xml]
----
<content type="text">4e1f38d1913b4e93ac622e6c1b258f89</content>
----
|===

===== XML Query Response Transformer
The XML Query Response Transformer is responsible for translating a query response into an XML formatted document. The metacards element that is generated is an extension of `gml:AbstractFeatureCollectionType`, which makes the output of this transformer GML 3.1.1 compatible. 

====== Installing and Uninstalling
This transformer comes installed out of the box and is running on start up. To uninstall or install manually, use the `catalog-transformer-xml` feature Web Console (http://localhost:8181/system/console) or System Console.

====== Configuring
None

====== Using
Using the OpenSearch Endpoint for example, query with the format option set to the XML shortname `xml`.
----
http://localhost:8181/services/catalog/query?q=input?format=xml
----

.Example Output
[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<ns3:metacards xmlns:ns1="http://www.opengis.net/gml" xmlns:ns2="http://www.w3.org/1999/xlink" xmlns:ns3="urn:catalog:metacard" xmlns:ns4="http://www.w3.org/2001/SMIL20/" xmlns:ns5="http://www.w3.org/2001/SMIL20/Language">
    <ns3:metacard ns1:id="000ba4dd7d974e258845a84966d766eb">
        <ns3:type>ddf.metacard</ns3:type>
        <ns3:source>southwestCatalog1</ns3:source>
        <ns3:dateTime name="created">
          <ns3:value>2013-04-10T15:30:05.702-07:00</ns3:value>
        </ns3:dateTime>
        <ns3:string name="title">
            <ns3:value>Input 1</ns3:value>
        </ns3:string>
    </ns3:metacard>
    <ns3:metacard ns1:id="00c0eb4ba9b74f8b988ef7060e18a6a7">
        <ns3:type>ddf.metacard</ns3:type>
        <ns3:source>southwestCatalog1</ns3:source>
        <ns3:dateTime name="created">
          <ns3:value>2013-04-10T15:30:05.702-07:00</ns3:value>
        </ns3:dateTime>
        <ns3:string name="title">
            <ns3:value>Input 2</ns3:value>
        </ns3:string>
    </ns3:metacard>
</ns3:metacards>
----

====== Implementation Details
[cols="3" options="header"]
|===

|Registered Interface	
|Service Property	
|Value

1.3+^|ddf.catalog.transform.QueryResponseTransformer	

|shortname	
|xml

|description	
|Transforms query results into xml

|title	
|View as XML...
|===

See XML Metacard Transformer Implementation Details as to how metacard Java object information is mapped into XML.

====== Known Issues
None

===== SearchUI
The SearchUI is a `QueryResponseTransformer` that not only provides results in html format but also provides a convenient, simple querying user interface. It is primarily used as a test tool and verification of configuration. The left pane of the SearchUI contains basic fields to query the Catalog and other Sources. The right pane consists of the results returned from the query.

====== Installing and Uninstalling
Catalog Transformers App will install this feature when deployed. This transformer's feature, `catalog-transformer-ui`, can be uninstalled or installed using the normal processes described in the Configuring DDF section.

====== Configuring
In the Admin Console the SearchUI can be configured under the Catalog HTML Query Response Transformer.

.Configurable Properties
[cols="6" options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Header	
|header	
|String	
|Specifies the header text to be rendered on the SearchUI
| 
|yes

|Footer	
|footer	
|String	
|Specifies the footer text to be rendered on the SearchUI	
| 
|yes

|Template	
|template	
|String	
|Specifies the path to the Template
|/templates/searchpage.ftl	
|`yes`

|Text Color	
|color	
|String	
|Specifies the Text Color of the Header and Footer	
|yellow	
|yes

|Background Color	
|background	
|String	
|Specifies the Background Color of the Header and Footer	
|green	
|yes

|===

===== Using
In order to obtain the SearchUI, a user must use the transformer with an endpoint that queries the Catalog such as the OpenSearch Endpoint. If a distribution is running locally, clicking on the following link http://localhost:8181/search/simple should bring up the Simple Search UI.
After the page has loaded, enter the desired search criteria in the appropriate fields. Then click the "Search" button in order to execute the search on the Catalog.
The "Clear" button will reset the query criteria specified.

====== Query Response Result Mapping
[cols="3" options="header"]
|===

|SearchUI Column Title
|Catalog Result
|Notes

|Title	
|Metacard.TITLE	
|The title maybe hyperlinked to view the full Metacard

|Source	
|Metacard.getSourceId()	
|Source where the Metacard was discoved

|Location	
|Metacard.LOCATION	
|Geographical location of the Metacard

|Time	
|Metacard.CREATED or Metacard.EFFECTIVE	
|Time received/created

|Thumbnail	
|Metacard.THUMBNAIL	
|No column shown if no results have thumbnail

|Resource	
|Metacard.RESOURCE_URI	
|No column shown if no results have a resource

|===

====== Search Criteria
The SearchUI allows for querying a Catalog in the following methods:

* Keyword Search - searching with keywords using the grammar of the underlying endpoint/Catalog.
* Temporal Search - searching based on relative or absolute time.
* Spatial search - searching spatially with a Point-Radius or Bounding Box. 
* Content Type Search - searching for specific Metacard.CONTENT_TYPE values

====== Known Issues
If the SearchUI results do not provide usable links on the metacard results, verify that a valid host has been entered in the Platform Global Configuration.

=== Developing a Query Response Transformer
A `QueryResponseTransformer` is used to transform a List of Results from a SourceResponse.  Query Response Transformers can be used through the Catalog `transform` convenience method or requested from the OSGi Service Registry by endpoints or other bundles. 

==== Create a New Query Response Transformer 
. Create a new Java class that implements `ddf.catalog.transform.QueryResponseTransformer`. +
`public class SampleResponseTransformer implements ddf.catalog.transform.QueryResponseTransformer`
. Implement the transform method. +
`public BinaryContent transform(SourceResponse upstreamResponse, Map<String, Serializable> arguments) throws CatalogTransformerException`
. Import the DDF interface packages to the bundle manifest (in addition to any other required packages). +
`Import-Package: ddf.catalog, ddf.catalog.transform`
. Create an OSGi descriptor file to communicate with the OSGi Service Registry (described in the Working with OSGi section). Export the service to the OSGi registry and declare service properties.

.Blueprint descriptor example
[source,xml,linenums]
----
...
<service ref="[[SampleResponseTransformer]]" interface="ddf.catalog.transform.QueryResponseTransformer">
    <service-properties>
        <entry key="shortname" value="[[sampletransform]]" />
        <entry key="title" value="[[Sample Response Transformer]]" />
        <entry key="description" value="[[A new transformer for response queues.]]" />
    </service-properties>
</service>
...
----
. Deploy OSGi Bundle to OSGi runtime.

==== Variable Descriptions
===== Blueprint Service properties
[cols="1,3,3" options="header"]
|===

|Key
|Description of Value
|Example

|shortname	
|An abbreviation for the return-type of the BinaryContent being sent to the user.	
|atom

|title	
|A user-readable title that describes (in greater detail than the shortname) the service.
|Atom Entry Transformer Service

|description	
|A short, human-readable description that describes the functionality of the service and the output.	
|_This service converts a single metacard xml document to an atom entry element._

|===
==== XSLT Transformer

==== XSLT Transformer Framework
The XSLT Transformer Framework allows developers to create light-weight Query Response Transformers and Metacard Transformers using only a bundle header and XSLT files.  The XSLT Transformer Framework registers bundles, following the XSLT Transformer Framework bundle pattern, as new transformer services.  The `service-xslt-transformer` feature is part of the DDF core.  

===== Examples
Examples of XSLT Transformers using the XSLT Transformer Framework include `service-atom-transformer` and `service-html-transformer`, found in the services folder of the source code trunk.

==== Developing an XSLT Transformer
The XSLT Transformer Framework allows developers to create light-weight Query Response Transformers using only a bundle header and XSLT files.  The XSLT Transformer Framework registers bundles, following the XSLT Transformer Framework bundle pattern, as new transformer services.  The `service-xslt-transformer` feature is part of the DDF core.  

===== Examples
Examples of XSLT Transformers using the XSLT Transformer Framework include `service-atom-transformer` and `service-html-transformer`, found in the services folder of the source code trunk.

===== Implement an XSLT Transformer
. Create a new Maven project.
. Configure the POM to create a bundle using the Maven bundle plugin.
.. Add the transform output MIME type to the bundle headers.
. Add XSLT files.

===== Bundle POM Configuration
Configure the Maven project to create an OSGi bundle using the `maven-bundle-plugin`.  Change the DDF-Mime-Type to match the MIME type of the transformer output.

.Example POM file
[source,xml,linenums]
----
...
<build>
    <plugins>
        <plugin>
            <groupId>org.apache.felix</groupId>
            <artifactId>maven-bundle-plugin</artifactId>
            <extensions>true</extensions>
            <configuration>
                <instructions>
                    <DDF-Mime-Type>[[Transform Result MIME Type]]</DDF-Mime-Type>
                    <Bundle-SymbolicName>${project.artifactId}</Bundle-SymbolicName>
                    <Import-Package />
                    <Export-Package />
                </instructions>
            </configuration>
        </plugin>
    </plugins>
</build>
...
----

====== Including XSLT
The XSLT Transformer Framework will scan for XSLT files inside a bundle.  The XSLT file must have a .xsl or .xslt file in the correct directory location relative to the root of the bundle.  The path depends on if the XSLT will act as a Metacard Transformer, Query Response Transformer, or both.  The name of the XSLT file will be used as the transformer's shortname.

.XSLT File Bundle Path Patterns
[source,xml,linenums]
----
// Metacard Transformer
<bundle root>
    /OSGI-INF
        /ddf
            /xslt-metacard-transformer
                /<transformer shortname>.[xsl|xslt]
  
// Query Response Transformer
<bundle root>
    /OSGI-INF
        /ddf
            /xslt-response-queue-transformer
                /<transformer shortname>.[xsl|xslt]
----

The XSLT file has access to metacard or Query Reponse XML data, depending on which folder the XSLT file is located.  The Metacard XML format will depend on the metadata schema used by the Catalog Provider.

For Query Response XSLT Transformers, the available XML data for XSLT transform has the following structure:

.Query Response XML
[source,xml,linenums]
----
<results>
    <metacard>
        <id>[[Metacard ID]]</id>
        <score>[[Relevance score]]</score>
        <distance>[[Distance from query location]]</distance>
        <site>[[Source of result]]</site>
        <type qualifier="type">[[Type]]</type>
        <updated>[[Date last updated]]</updated>
        <geometry>[[WKT geometry]]</geometry>
        <document>
            [[Metacard XML]]
        </document>
    </metacard>
    ...
</results>
----

The XSLT file has access to additional parameters.  The `Map<String, Serializable>` arguments from the transform method parameters is merged with the available XSLT parameters.

* Query Response Transformers
** `grandTotal` - total result count 
* Metacard Transformers
** `id` - metacard ID
** `siteName` - source ID
** `services` - list of displayable titles and URLs of available metacard transformers

====== RSS Example
. Create a Maven project named `service-rss-transformer`. 
. Add the following to its POM file.
 
.Example RSS POM
[source,xml,linenums]
----
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <packaging>bundle</packaging>
  <modelVersion>4.0.0</modelVersion>
  <parent>
    <artifactId>services</artifactId>
    <groupId>ddf</groupId>
    <version>[[DDF release version]]</version>
  </parent>
  <groupId>ddf.services</groupId>
  <artifactId>service-rss-transformer</artifactId>
  
  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.felix</groupId>
        <artifactId>maven-bundle-plugin</artifactId>
        <extensions>true</extensions>
        <configuration>
          <instructions>
            <DDF-Mime-Type>application/rss+xml</DDF-Mime-Type>
            <Bundle-SymbolicName>${project.artifactId}</Bundle-SymbolicName>
            <Import-Package />
            <Export-Package />
          </instructions>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
----

[cols="1,4" options="header"]
|===
|Line #
|Comment

|8	
|Use the current release version.

|21	
|Set the MIME type to the RSS MIME type.

|===

. Add service-rss-transformer/src/main/resources/OSGI-INF/ddf/xslt-response-queue-transformer/rss.xsl. The transformer will be a Query Response Transformer with the shortname rss based on the XSL filename and path.
. Add the following XSL to the new file.

.Example RSS XSLT
[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<xsl:stylesheet version="2.0"
 xmlns:xsl="http://www.w3.org/1999/XSL/Transform" 
 xmlns:gml="http://www.opengis.net/gml" exclude-result-prefixes="xsl gml">
  
  <xsl:output method="xml" version="1.0" indent="yes" />
  
  <xsl:param name="grandTotal" />
  <xsl:param name="url" />
  
  <xsl:template match="/">
    <xsl:apply-templates />
  </xsl:template>
  
  <xsl:template match="results">
    <rss version="2.0">
      <channel>
      <title>Query Results</title>
      <link><xsl:value-of select="$url" disable-output-escaping="yes" /></link>
      <description>Query Results of <xsl:value-of select="count(//metacard)" /> out of <xsl:value-of select="$grandTotal" /></description>
      <xsl:for-each select="metacard/document">
        <item>
          <guid>
            <xsl:value-of select="../id" />
          </guid>
          <title>
            <xsl:value-of select="Data/title" />
          </title>
          <link>
            <xsl:value-of select="substring-before($url,'/services')" /><xsl:text>/services/catalog/</xsl:text><xsl:value-of select="../id" /><xsl:text>?transform=html</xsl:text>
          </link>
          <description>
            <xsl:value-of select="//description" />
          </description>
          <author>
            <xsl:choose>
              <xsl:when test="Data/creator">
                <xsl:value-of select="Resource/creator//name" />
              </xsl:when>
              <xsl:when test="Data/publisher">
                <xsl:value-of select="Data/publisher//name" />
              </xsl:when>
              <xsl:when test="Data/unknown">
                <xsl:value-of select="Data/unknown//name" />
              </xsl:when>
            </xsl:choose>
          </author>
          <xsl:if test=".//@posted" >
            <pubDate>
              <xsl:value-of select=".//posted" />
            </pubDate>
          </xsl:if>
          </item>
        </xsl:for-each>
      </channel>
    </rss>
  </xsl:template>
</xsl:stylesheet> 
----
[cols="1,4" options="header"]
|===

|Line #
|Comment

|8-9	
|Example of using additional parameters and arguments.

|15	
|Example of using the Query Response XML data.

|21,27	
|Example of using the Metacard XML data.

|===

== Extending Federation

Federation provides the capability to extend the DDF enterprise to include Remote Sources, which may include other instances of DDF. The Catalog handles all aspects of federated queries as they are sent to the Catalog Provider and Remote Sources, processed, and the query results are returned. Queries can be scoped to include only the local Catalog Provider (and any Connected Sources), only specific Federated Sources, or the
entire enterprise (which includes all local and Remote Sources). If the query is supposed to be federated, the Catalog Framework passes the query to a Federation Strategy, which is responsible for querying each federated source that is specified. The Catalog Framework is also responsible for receiving the query results from each federated source and returning them to the client in the order specified by the particular federation strategy used. After the federation strategy handles the results, the Catalog returns them to the client through the Endpoint. Query results returned from a federated query are a list of metacards. The source ID in each metacard identifies the Source from which the metacard originated.

The Catalog normalizes the incoming query into an OGC Filter format. When the query is disseminated by the Catalog Framework to the sources, each source is responsible for denormalizing the OGC Filter formatted query into the format understood by the external store that the source is acting as a proxy. This normalization/denormalization is what allows any endpoint to interface with any type of source. For example, a query received by the OpenSearch Endpoint can be executed against an OpenSearch Source.

[ditaa, catalog_architecture_plugins, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       | 
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |c369        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....

[ditaa, federation, png]
....
           /------\
           |Client|
           |cDEF  |
           \------/
              ^
              |
+-------------|------------------------------------------------------------\
|DDF          |                                                       cCCC |
|             v                                                            |
|         /--------\   /-----------------\   /-------------------\         |
|         |Endpoint|<->|Catalog Framework|<->|Federation Strategy|         |
|         | cDEF   |   | cDEF            |   | cDEF              |         | 
|         \--------/   \-----------------/   \-------------------/         |
|                                                     ^ ^                  |
|                                                     | |                  |
|                                          /----------/ \---------\        |
|                                          |                      |        |
| +----------------------------------------|----------------------|------+ |
| |Enterprise Query                        v                      v      | |
| |+--------------------------------------------+ +---------------------+| |
| ||Local Query                                 | |Federated Query      || |
| ||/------------------\ /---------------------\| |/-------------------\|| |
| ||| Catalog Provider | | Connected Source(s) || ||Federated Source(s)||| |
| |||  cDEF            | |  cDEF               || || cDEF              ||| |
| ||\------------------/ \---------------------/| |\-------------------/|| |
| |+-------^----------------------^-------------+ +----^----------^-----+| |
| +--------|----------------------|--------------------|----------|------+ |
\----------|----------------------|--------------------|----------|--------/
           |                      |                    |          \-------------------\
           |                      |                    |                              |
           v                      v                    v                              v
/=-------------------\ /----------------------\ /---------=------------\     /----------------------\
|  Oracle Database   | |       Source A       | |       Source B       | ... |       Source X       |
\--------------------/ \--------------------=-/ \----------------------/     \-------=--------------/
.... 

=== Federation Strategy

A federation strategy federates a query to all of the Remote Sources in the query's list, processes the results in a unique way, then returns the results to the client. For example, implementations can choose to block until all results return then perform a mass sort or return the results back to the client as soon as they are received back from a Federated Source.

==== Usage

An endpoint can optionally specify the federation strategy to use when it invokes the query operation. Otherwise, the Catalog provides a default federation strategy that will be used.

==== Catalog Federation Strategy

The Catalog Federation Strategy is the default federation strategy and is based on sorting metacards by the sorting parameter specified in the federated query.

The possible sorting values are:

* metacard's effective date/time
* temporal data in the query result
* distance data in the query result
* relevance of the query result

The supported sorting orders are ascending and descending.

The default sorting value/order automatically used is relevance descending.

[WARNING]
====
The Catalog Federation Strategy expects the results returned from the Source to be sorted based on
whatever sorting criteria were specified. If a metadata record in the query results contains null values for the sorting criteria elements, the Catalog Federation Strategy expects that result to come at the end of the result list.
====

===== Configuration

The Catalog Federation Strategy configuration can be found in the web console under 
Configuration -> Catalog Federation Strategy.

[cols="1,1,4a,1,1" options="header"]
|===

|Property
|Type
|Description
|Default Value
|Required

|maxStartIndex
|Integer
|The maximum query offset number (any number from 1 to unlimited). Setting the number too high would allow offset queries that could result in an out of memory error because the DDF will cycle through all records in memory. Things to consider when setting this value are:

* How much memory is allocated to the DDF Server
* How many sites are being federated with.

|50000
|yes

|expirationIntervalInMinutes
|Long
|Interval that Solr Cache checks for expired documents to remove.
|10
|yes

|expirationAgeInMinutes
|Long
|The number of minutes a document will remain in the cache before it will expire. Default is 7 days.
|10080
|yes

|url
|String
|HTTP URL of Solr 4.x Server
|https://localhost:8993/solr
|yes

|===

[cols="2" options="header"]
|===

|Managed Service PID
|`ddf.catalog.federation.impl.CachingFederationStrategy`

|Managed Service Factory PID
|N/A
|===

== Extending Eventing

The Eventing capability of the Catalog allows endpoints (and thus external users) to create a "standing query" and be notified when a matching metacard is created, updated, or deleted.

Notably, the Catalog allows event evaluation on both the previous value (if available) and new value of a Metacard when an update occurs.

To better understand why this would be useful, suppose that there has been increased pirating activity off the coast of Somalia.  Because of these events, a group of intelligence analysts is interested in determining the reason for the heightened hostility and discovering its cause.  To do this, analysts need to monitor interesting events occurring in that area.  Without DDF Eventing, the analysts would need to repeatedly query for any records of events or intelligence gathered in that area.  Analysts would have to monitor changes or anything of interest.  However, with DDF Eventing, the analysts can create a subscription indicating criteria for the types of intelligence of interest.  In this scenario, analysts could specify interest in metacards added, updated, or deleted that describe data obtained around the coast of Somalia.  Through this subscription, DDF will send event notifications back to the team of analysts containing metadata of interest.  Furthermore, they could filter the records not only spatially, but by any other criteria that would zero in on the most interesting records.  For example, a fishing company that has operated ships peacefully in the same region for a long time may not be interesting.  To exclude metadata about that company, analysts may add contextual criteria indicating to return only records containing the keyword "pirate." With the subscription in place, analysts will only be notified of metadata related to the pirating activity, giving them better situational awareness.

The key components of DDF Eventing include:

* Subscription
* Delivery Method
* Event Processor

After reading this section, you will be able to:

* Create new subscriptions
* Register subscriptions
* Perform operations on event notification
* Remove a subscription

[ditaa, catalog_architecture_eventing, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       | 
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |c369   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....

=== Subscription

Subscriptions represent "standing queries" in the Catalog. Like a query, subscriptions are based on the OGC Filter specification.

==== Subscription Lifecycle

===== Creation

* Subscriptions are created directly with the Event Processor or declaratively through use of the Whiteboard Design Pattern.
* The Event Processor will invoke each Pre-Subscription Plugin and, if the subscription is not rejected, the subscription will be activated.

===== Evaluation

* When a metacard matching the subscription is created, updated, or deleted in any Source, each Pre-Delivery Plugin will be invoked.

* If the delivery is not rejected, the associated Delivery Method callback will be invoked.

===== Update Evaluation

Notably, the Catalog allows event evaluation on both the previous value (if available) and new value of a Metacard when an update occurs.

===== Durability

Subscription durability is not provided by the Event Processor.  Thus, all subscriptions are transient and will not be recreated in the event of a system restart.  It is the responsibility of Endpoints using subscriptions to persist and re-establish the subscription on startup.  This decision was made for the sake of simplicity, flexibility, and the inability of the Event Processor to recreate a fully-configured Delivery Method without being overly restrictive.

[IMPORTANT]
====
*Subscriptions are not persisted by the Catalog itself.* +
Subscriptions must be explicitly persisted by an endpoint and are not persisted by the Catalog. The Catalog Framework, or more specifically the Event Processor itself, does not persist subscriptions. Certain endpoints, however, can persist the subscriptions on their own and recreate them on system startup.
====

====== Creating a Subscription

Currently, the Catalog reference implementation does not contain a subscription endpoint. Nevertheless, an endpoint that exposes a web service interface to create, update, and delete subscriptions would provide a client's subscription's filtering criteria to be used by Catalog's Event Processor to determine which create, update, and delete events are of interest to the client. The endpoint client also provides the callback URL of the event consumer to be called when an event matching the subscription's criteria is found. This callback to the event consumer is made by a Delivery Method implementation that the client provides when the subscription is created.  Whenever an event occurs in the Catalog matching the subscription, the Delivery Method implementation will be called by the Event Processor.  The Delivery Method will, in turn, send the event notification out to the event consumer.  As part of the subscription creation process, the Catalog verifies that the event consumer at the specified callback URL is available to receive callbacks. Therefore, the client must ensure the event consumer is running prior to creating the subscription.  The Catalog completes the subscription creation by executing any pre-subscription Catalog Plugins, and then registering the subscription with the OSGi Service Registry. The Catalog does not persist subscriptions by default.

==== Delivery Method

A Delivery Method provides the operation (created, updated, deleted) for how an event's metacard can be delivered.

A Delivery Method is associated with a subscription and contains the callback URL of the event consumer to be notified of events. The Delivery 

Method encapsulates the operations to be invoked by the Event Processor when an event matches the criteria for the subscription. The Delivery Method's operations are responsible for invoking the corresponding operations on the event consumer associated with the callback URL.

==== Event Processor

The Event Processor provides an engine that creates, updates, and deletes subscriptions 
for event notification. These subscriptions optionally specify a filter criteria so that only events of interest to the subscriber are posted for notification.

An internal subscription tracker monitors the OSGi registry, looking for subscriptions to be added (or deleted). When it detects a subscription being added, it informs the Event Processor, which sets up the subscription's filtering and is responsible for posting event notifications to the subscriber when events satisfying their criteria are met.

===== Event Processing and Notification

As metacards are created, updated, and deleted, the Catalog's Event Processor is invoked (as a post-ingest plugin) for each of these events. TheEvent Processor applies the filter criteria for each registered subscription to each of these ingest events to determine if they match the criteria. If an event matches a subscription's criteria, any pre-delivery plugins that are installed are invoked, the subscription's Delivery Method is retrieved, and its operation corresponding to the type of ingest event is invoked.  For example, the DeliveryMethod's `created()` function is called when a metacard is created. The Delivery Method's operations subsequently invoke the corresponding operation in the client's event consumer service, which is specified by the callback URL provided when the Delivery Method was created.

==== Standard Event Processor

The Standard Event Processor is an implementation of the Event Processor and provides the ability to create/delete subscriptions. Events are generated by the DDF Catalog Framework as metacards are created/updated/deleted and the Standard Event Processor is called since it is also a Post-Ingest Plugin. The Standard Event Processor checks each event against each subscription's criteria.

When an event matches a subscription's criteria the Standard Event Processor:

* invokes each pre-delivery plugin on the metacard in the event
* invokes the Delivery Method's operation corresponding to the type of event being processed, e.g., created operation for the creation of a metacard

===== Installing and Uninstalling

The StandardEvent Processor is automatically installed/uninstalled when the 
Standard Catalog Framework is installed/uninstalled.

===== Known Issues

The Standard Event processor currently broadcasts federated events and should not. It should only broadcast events that were generated locally, all other events should be dropped.

==== Fanout Event Processor

The Fanout Event Processor is used when DDF is configured as a fanout proxy. The only difference between the Fanout Event Processor and the Standard Event Processor is that the source ID in the metacard of each event is overridden with the fanout's source ID. This is done to hide the source names of the Remote Sources in the fanout's enterprise. Otherwise, the Fanout Event Processor functions exactly like the Standard Event Processor. 
===== Installing and Uninstalling

The Fanout Event Processor is automatically installed/uninstalled when the Catalog Fanout Framework App is installed/uninstalled.

===== Known Issues
None

==== Working with Subscriptions

===== Creating a Subscription

====== Using DDF Implementation

If applicable, the implementation of `Subscription` that comes with DDF should be used. It is available at `ddf.catalog.event.impl.SubscriptionImpl` and offers a constructor that takes in all of the necessary objects. Specifically, all that is needed is a `Filter`, `DeliveryMethod`, `Set<String>` of source IDs, and a `boolean` for enterprise.

The following is an example code stub showing how to create a new instance of Subscription using the DDF implementation. 

[source,java,linenums]
----
// Create a new filter using an imported FilterBuilder
Filter filter = filterBuilder.attribute(Metacard.ANY_TEXT).like().text("*");
 
// Create a implementation of Delivery Method
DeliveryMethod deliveryMethod = new MyCustomDeliveryMethod();
 
// Create a set of source ids
// This set is empty as the subscription is not specific to any sources
Set<String> sourceIds = new HashSet<String>();
 
// Set the isEnterprise boolean value
// This subscription example should notifications from all sources (not just local)
boolean isEnterprise = true;

Subscription subscription = new SubscriptionImpl(filter, deliveryMethod, sourceIds,isEnterprise);
----

====== Creating a Custom Implementation

To create a subscription in DDF the developer needs to implement the `ddf.catalog.event.Subscription` interface.  This interface extends `org.opengis.filter.Filter` in order to represent the subscription's filter criteria.  Furthermore, the `Subscription` interface contains a `DeliveryMethod` implementation.  

When implementing `Subscription`, the developer will need to override the methods `accept` and `evaluate` from the `Filter`.  The `accept` method allows the visitor pattern to be applied to the `Subscription`.  A `FilterVisitor` can be passed into this method in order to process the `Subscription's Filter`. In DDF, this method is used to convert the `Subscription's Filter` into a predicate format that is understood by the Event Processor.  The second method inherited from `Filter` is `evaluate`.  This method is used to evaluate an object against the `Filter`'s criteria in order to determine if it matches the criteria.  See the Creating Filters section of the Developer's Guide for more information on OGC filters. 

[TIP]
====
The functionality of these overridden methods is typically delegated to the `Filter`
 implementation that the `Subscription` is using.
====

The developer must also define `getDeliveryMethod`. This class is called when the an event occurs that matches the filter of the subscription. More information on how to create a `DeliveryMethod` is in the Creating A Delivery Method section of this page.

The other two methods required because `Subscription` implements `Federatable` are `isEnterprise` and `getSourceIds`, which indicate that the subscription should watch for events occurring on all sources in the enterprise or on specified sources. 

The following is an implementation stub of `Subscription` that comes with DDF and is available at `ddf.catalog.event.impl.SubscriptionImpl`.

.SubscriptionImpl
[source,java,linenums]
----
public class SubscriptionImpl implements Subscription {
    private Filter filter;

    private DeliveryMethod dm;
    
    private Set<String> sourceIds;
    
    private boolean enterprise;
    
    public SubscriptionImpl(Filter filter, DeliveryMethod dm, Set<String> sourceIds,
            boolean enterprise) {
        this.filter = filter;
        this.dm = dm;
        this.sourceIds = sourceIds;
        this.enterprise = enterprise;
    }

    @Override
    public boolean evaluate(Object object) {
        return filter.evaluate(object);
    }

    @Override
    public Object accept(FilterVisitor visitor, Object extraData) {
        return filter.accept(visitor, extraData);
    }

    @Override
    public Set<String> getSourceIds() {
        return sourceIds;
    }

    @Override
    public boolean isEnterprise() {
        return enterprise;
    }

    @Override
    public DeliveryMethod getDeliveryMethod() {
        return dm;
    }
}
----

==== Registering a Subscription

Once a `Subscription` is created, it needs to be registered in the OSGi Service Registry as a `ddf.catalog.event.Subscription` service. This is necessary for the `Subscription`
 to be discovered by the Event Processor.  Typically, this is done in code after the `Subscription` is instantiated.  When the `Subscription` is registered, a unique ID will need to be specified using the key `subscription-id`. This will be used to delete the `Subscription` from the OSGi Service Registry.  Furthermore, the `ServiceRegistration`, which is the return value from registering a `Subscription`, should be monitored in order to remove the `Subscription` later.  The following code shows how to correctly register a `Subscription` implementation in the registry using the above `SubscriptionImpl` for clarity:

.Registering a Subscription
[source,java,linenums]
----
// Map to keep track of registered Subscriptions.  Used for unregistering Subscriptions.
Map<String, ServiceRegistration<Subscription>> subscriptions = new HashMap<String, ServiceRegistration<Subscription>>();

// New subscription using the DDF Implementation of subscription
Subscription subscription = new SubscriptionImpl(filter, deliveryMethod, sourceIds,isEnterprise);  

// Specify the subscription-id to uniquely identify the Subscription
String subscriptionId = "0123456789abcdef0123456789abcdef";
Dictionary<String, String> properties = new Hashtable<String, String>();
properties.put("subscription-id", subscriptionId);

// Service registration requires an instance of the OSGi bundle context
// Register subscription and keep track of the service registration
ServiceRegistration<Subscription> serviceRegistration = context.registerService(ddf.catalog.event.Subscription.class, subscription, properties );
subscriptions.put(subscriptionId, serviceRegistration);
---- 

==== Creating a Delivery Method

The Event Processor obtains the subscription's `DeliveryMethod` and invokes one of its four methods when an event occurs.  The `DeliveryMethod` then handles that invocation and communicates an event to a specified consumer service outside of DDF.

The Event Processor calls the `DeliveryMethod`'s`created` method when a new metacard matching the filter criteria is added to the Catalog.  It calls the `deleted` method when a metacard that matched the filter criteria is removed from the Catalog.  `updatedHit` is called when a metacard is updated and the new metacard matches the subscription.  `updatedMiss` is different in that it is only called if the old metacard matched the filter but the new metacard no longer does.  An example of this would be if the filter contains spatial criteria consisting of Arizona.  If a plane is flying over Arizona, the Event Processor will repeatedly call `updatedHit` as the plane flies from one side to the other while updating its position in the Catalog. This happens because the updated records continually match the specified criteria.  If the plane crosses into New Mexico, the previous metacard will have matched the filter, but the new metacard will not.  Thus, `updatedMiss` gets called.  

The following is an implementation stub for `DeliveryMethod`:

.DeliveryMethodImpl
[source,java,linenums]
----
public class DeliveryMethodImpl implements DeliveryMethod {

    @Override
    public void created(Metacard newMetacard) {
        // Perform custom code on create
    }

    @Override
    public void updatedHit(Metacard newMetacard, Metacard oldMetacard) {
		// Perform custom code on update (where both new and old metacards matched filter)
    }

    @Override
    public void updatedMiss(Metacard newMetacard, Metacard oldMetacard) {
		// Perform custom code on update (where one of the two metacards did not match the filter)
    }

    @Override
    public void deleted(Metacard oldMetacard) {
     // Perform custom code on delete
    }
}
----

==== Deleting a Subscription

To remove a subscription from DDF, the subscription ID is required.  Once this is provided, the `ServiceRegistration` for the indicated `Subscription` should be obtained from the `Subscriptions` Map. Then the `Subscription` can be removed by unregistering the service.  The following code demonstrates how this is done:

.Delete Subscription
[source,java,linenums]
----
String subscriptionId = "0123456789abcdef0123456789abcdef";

//Obtain service registration from subscriptions Map based on subscription ID
ServiceRegistration<Subscription> sr = subscriptions.get(subscriptionId);

//Unregister Subscription from OSGi Service Registry
sr.unregister();

//Remove Subscription from Map keeping track of registered Subscriptions. 
subscriptions.remove(subscriptionId);
----

== Extending Resource Components

Resource components are used when working with resources, i.e., the data that is represented by the cataloged metadata.

A resource is a URI-addressable entity that is represented by a metacard. Resources may also be known as products or data.

Resources may exist either locally or on a remote data store.

Examples of resources include:

* NITF image
* MPEG video
* Live video stream
* Audio recording
* Document

A resource object in DDF contains an `InputStream` with the binary data of the resource.  It describes that resource with a name, which could be a file name, URI, or another identifier.  It also contains a mime type or content type that a client can use to interpret the binary data.  

[ditaa, catalog_architecture_plugins, png]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       | 
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |c369   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------
....

=== Resource Readers

A resource reader retrieves resources associated with metacards via URIs. Each resource reader must know how to interpret the resource's URI and how to interact with the data store to retrieve the resource.

There can be multiple resource readers in a Catalog instance. The `Catalog Framework` selects the appropriate resource reader based on the scheme of the resource's URI. 

In order to make a resource reader available to the Catalog Framework, it must be exported to the OSGi Service Registry as a `ddf.catalog.resource.ResourceReader`. 

==== URL Resource Reader

The `URLResourceReader` is an implementation of `ResourceReader` which is included in the DDF Catalog.  It obtains a resource given an http, https, or file-based URL. The `URLResourceReader` will connect to the provided Resource URL and read the resource's bytes into an `InputStream`.  

===== Installing and Uninstalling

`URLResourceReader` is installed by default with the DDF Catalog.

===== Configuring

This `URLResourceReader` has no configurable properties. It can only be installed or uninstalled.

===== Using

`URLResourceReader` will be used by the Catalog Framework to obtain a resource whose metacard is cataloged in the local data store.  This particular `ResourceReader` will be chosen by the `CatalogFramework` if the requested resource's URL has a protocol of `http`, `https`, or `file`.  

For example, requesting a resource with the following URL will make the Catalog Framework invoke the 
	`URLResourceReader`
 to retrieve the
product.

.Example
[source,http]
----
file:///home/users/ddf_user/data/example.txt
----

If a resource was requested with the URL udp://123.45.67.89:80/SampleResourceStream, the 
`URLResourceReader` would _not_ be invoked.

===== Implementation Details

Supported Schemes:

* http
* https
* file

[NOTE]
====
If a file-based URL is passed to the `URLResourceReader`, that file path needs to be accessible by the DDF instance.
====

===== Known Issues
None

=== Developing a Resource Reader

A `ResourceReader` is a class that retrieves a resource or product from a native/external source and returns it to {branding}. A simple example is that of a File `ResourceReader`. It takes a file from the local file system and passes it back to DDF. New mplementations can be created in order to support obtaining Resources from various Resource data stores. 

==== Create a New ResourceReader

Complete the following procedure to create a `ResourceReader`.

. Create a Java class that implements the `ddf.catalog.resource.ResourceReader` interface.
. Deploy the OSGi bundled packaged service to the DDFrun-time. (Refer to the Working with OSGi - Bundles section.)

===== Implementing the ResourceReader Interface

[source,java,linenums]
----
public class TestResourceReader implements ddf.catalog.resource.ResourceReader
----

`ResourceReader` has a couple of key methods where most of the work is performed.

[NOTE]
====
*URI* +
It is recommended to become familiar with the Java API URI class in order to properly build a `ResourceReader`.  Furthermore, a URIshould be used according to its specification here: +
http://www.w3.org/Addressing/URL/uri-spec.html.
====

===== retrieveResource

[source,java,linenums]
----
public ResourceResponse retrieveResource( URI uri, Map<String, Serializable> arguments )throws IOException, ResourceNotFoundException, ResourceNotSupportedException;
----

This method is the main entry to the `ResourceReader`. It is used to retrieve a `Resource` and send it back to the caller (generally the `CatalogFramework`). Information needed to obtain the entry is contained in the `URI` reference. The URI Scheme will need to match a scheme specified in the `getSupportedSchemes` method. This is how the CatalogFramework determines which `ResourceReader` implementation to use. If there are multiple ResourceReaders supporting the same scheme, these ResourceReaders will be invoked iteratively.  Invocation of the ResourceReaders stops once one of them returns a `Resource`.

Arguments are also passed in. These can be used by the `ResourceReader` to perform additional operations on the resource.

An example of how `URLResourceReader` (located in the source code at /trunk/ddf/catalog/resource/URLResourceReader.java) implements the `getResource` method. This `ResourceReader` simply reads a file from a URI.

[NOTE]
====
The "Map<String, Serializable> arguments" parameter is passed in to support any options or additional information associated with retrieving the resource.
====

===== Implement retrieveResource()

. Define supported schemes (e.g., file, http, etc.).
. Check if the incoming URI matches a supported scheme. If it does not, throw 
`ResourceNotSupportedException`.

For example:
[source,java,linenums]
----
if ( !uri.getScheme().equals("http") )
 {
   throw new ResourceNotSupportedException("Unsupported scheme received, was expecting http")
 }
----

. Implement the business logic.
. For example, the `URLResourceReader` will obtain the resource through a connection:

[source,java,linenums]
----
URL url = uri.toURL();
URLConnection conn = url.openConnection();
String mimeType = conn.getContentType();
if ( mimeType == null ) {
    mimeType = URLConnection.guessContentTypeFromName( url.getFile() );
}
InputStream is = conn.getInputStream();
----

[NOTE]
====
The `Resource` needs to be accessible from the DDF installation.  This includes being able to find a file locally or reach out to a remote URI.  This may require Internet access, and DDF may need to be configured to use a proxy (http.proxyHost and http.proxyPort can be added to the system properties on the command line script).
====

. Return `Resource` in `ResourceResponse`.

For example:
[source,java,linenums]
----
return ResourceResponseImpl( new ResourceImpl( new BufferedInputStream( is ), new MimeType( mimeType ), url.getFile() ) );
----

If the Resource cannot be found, throw a `ResourceNotFoundException`.  

===== getSupportedSchemes

[source,java]
----
public Set<String> getSupportedSchemes();
----

This method lets the `ResourceReader` inform the CatalogFramework about the type of URI scheme that it accepts and should be passed. For single-use ResourceReaders (like a URLResourceReader), there may be only one scheme that it can accept while others may understand more than one. A ResourceReader must, at minimum, accept one qualifier.  As mentioned before, this method is used by the CatalogFramework to determine which ResourceReader to invoke. 

[NOTE]
====
*ResourceReader extends Describable* +
Additionally, there are other methods that are used to uniquely describe a `ResourceReader`. The describe methods are straight-forward and can be implemented by looking at the Javadoc.
====

===== Export to OSGi Service Registry

In order for the ResourceReader to be used by the CatalogFramework, it should be exported to the OSGi Service Registry as a `ddf.catalog.resource.ResourceReader`.

See the XML below for an example:

.Blueprint example
[source,xml,linenums]
----
<bean id="[[customResourceReaderId]]" class="[[example.resource.reader.impl.CustomResourceReader]]" />
<service ref="[[customResourceReaderId]]" interface="ddf.catalog.source.ResourceReader" />
----

=== Resource Writers

A resource writer stores a resource and produces a URI that can be used to retrieve the resource at a later time. The resource URI uniquely locates

and identifies the resource. Resource writers can interact with an underlying data store and store the resource in the proper place. Each

implementation can do this differently, providing flexibility in the data stores used to persist the resources.

==== Examples

The Catalog reference implementation currently does not include any resource writers out of the box.

=== Developing a Resource Writer

[NOTE]
====
Before implementing a Resource Writer, refer to the Content Framework for alternatives.
====

A `ResourceWriter` is an object used to store or delete a `Resource`. 
`ResourceWriter` objects should be registered within the OSGi Service Registry, so clients can retrieve an instance when clients need to store a `Resource`. 

==== Create a New ResourceWriter

Complete the following procedure to create a `ResourceWriter`.

. Create a Java class that implements the `ddf.catalog.resource.ResourceWriter` interface.

.ResourceWriter Implementation Skeleton
[source,java,linenums]
----
import java.io.IOException;
import java.net.URI;
import java.util.Map;
import ddf.catalog.resource.Resource;
import ddf.catalog.resource.ResourceNotFoundException;
import ddf.catalog.resource.ResourceNotSupportedException;
import ddf.catalog.resource.ResourceWriter;

public class SampleResourceWriter implements ResourceWriter {

	@Override
	public void deleteResource(URI uri, Map<String, Object> arguments) throws ResourceNotFoundException, IOException {
	   // WRITE IMPLEMENTATION
	 }
	 
	@Override
	public URI storeResource(Resource resource, Map<String, Object> arguments)throws ResourceNotSupportedException, IOException {
	   // WRITE IMPLEMENTATION
	   return null;
	}

	@Override
	public URI storeResource(Resource resource, String id, Map<String, Object> arguments) throws ResourceNotSupportedException, IOException {
	   // WRITE IMPLEMENTATION
	   return null;
	}

}
----
. Register the implementation as a Service in the OSGi Service Registry.

.Blueprint Service Registration Example
[source,xml,linenums]
----
...
<service ref="[[ResourceWriterReference]]" interface="ddf.catalog.resource.ResourceWriter" />
...
----

. Deploy the OSGi bundled packaged service to the DDF run-time (Refer to the Working with OSGi - Bundles section.)

[TIP]
====
*ResourceWriter Javadoc* +
Refer to the DDF Catalog API Javadoc for more information about the methods required for implementing the interface. 
====

=== Developing a Registry Client
Registry Clients create Federated Sources using the OSGi Configuration Admin. Developers should reference an individual `Source`'s (Federated, Connected, or Catalog Provider) documentation for the Configuration properties (such as a Factory PID, addresses, intervals, etc) necessary to establish that `Source` in the framework. 

==== Example

.Creating a Source Configuration
[source,java,linenums]
----
org.osgi.service.cm.ConfigurationAdmin configurationAdmin = getConfigurationAdmin() ;
org.osgi.service.cm.Configuration currentConfiguration = configurationAdmin.createFactoryConfiguration(getFactoryPid(), null);
Dictionary properties = new Dictionary() ;
properties.put(QUERY_ADDRESS_PROPERTY,queryAddress);
currentConfiguration.update( properties );
----

Note that the `QUERY_ADDRESS_PROPERTY` is specific to this Configuration and might not be required for every `Source`. The properties necessary for creating a Configuration are different for every `Source`. 

=== Working with Resources

==== Metacards and Resources

Metacards are used to describe a resource through metadata.  This metadata includes the time the resource was created, the location where the resource was created, etc.  A DDF `Metacard` contains the `getResourceUri` method, which is used to locate and retrieve its corresponding resource.

==== Retrieve Resource

When a client attempts to retrieve a resource, it must provide a metacard ID or URI corresponding to a unique resource.  As mentioned above, the resource URI is obtained from a `Metacard`'s `getResourceUri` method.  The `CatalogFramework` has three methods that can be used by clients to obtain a resource: `getEnterpriseResource`, `getResource`, and `getLocalResource`. The `getEnterpriseResource` method invokes the `retrieveResource` method on a local `ResourceReader` as well as all the `Federated` and `Connected` Sources inthe DDF enterprise.  The second method, `getResource`, takes in a source ID as a parameter and only invokes `retrieveResource` on the specified `Source`.  The third method invokes `retrieveResource` on a local `ResourceReader`. 

The parameter for each of these methods in the `CatalogFramework` is a 	`ResourceRequest`. DDF includes two implementations of `ResourceRequest`: `ResourceRequestById` and `ResourceRequestByProductUri`.  Since these implementations extend `OperationImpl`, they can pass a `Map` of generic properties through the `CatalogFramework` to customize how the resource request is carried out.  One example of this is explained in the Options section below.  The following is a basic example of how to create a `ResourceRequest` and invoke the `CatalogFramework` resource retrieval methods to process the request.   

.Retrieve Resource Example
[source,java,linenums]
----
Map<String, Serializable> properties = new HashMap<String, Serializable>();
properties.put("PropertyKey1", "propertyA"); //properties to customize Resource retrieval
ResourceRequestById resourceRequest = new ResourceRequestById("0123456789abcdef0123456789abcdef", properties); //object containing ID of Resource to be retrieved 
String sourceName = "LOCAL_SOURCE"; //the Source ID or name of the local Catalog or a Federated Source
ResourceResponse resourceResponse; //object containing the retrieved Resource and the request that was made to get it.
resourceResponse = catalogFramework.getResource(resourceRequest, sourceName); //Source-based retrieve Resource request 
Resource resource = resourceResponse.getResource(); //actual Resource object containing InputStream, mime type, and Resource name
----

`ddf.catalog.resource.ResourceReader` instances can be discovered via the OSGi Service Registry. The system can contain multiple `ResourceReaders`. The `CatalogFramework` determines which one to call based on the scheme of the resource's URI and what schemes the `ResourceReader` supports. The supported schemes are obtained by a `ResourceReader`'s `getSupportedSchemes` method.  As an example, one `ResourceReader` may know how to handle file-based URIs with the scheme 	`file`, whereas another `ResourceReader` may support HTTP-based URIs with the scheme `http`.

The `ResourceReader` or `Source` is responsible for locating the resource, reading its bytes, adding the binary data to a `Resource` implementation, then returning that `Resource` in a `ResourceResponse`. The `ResourceReader` or `Source` is also responsible for determining the `Resource`'s name and mime type, which it sends back in the `Resource` implementation.  
 
See the Developing a Resource Reader section or the Developing a Source section in the Developer's Guide for more information and examples.  

===== Options

Options can be specified on a retrieve resource request made through any of the supporting endpoint.  To specify an option for a retrieve resource request, the endpoint needs to first instantiate a `ResourceRequestByProductUri` or a `ResourceRequestById`.  Both of these `ResourceRequest` implementations allow a `Map` of properties to be specified.  Put the specified option into the `Map` under the key `RESOURCE_OPTION`.  

.Retrieve Resource with Options
[source,java,linenums]
----
Map<String, Serializable> properties = new HashMap<String, Serializable>();
properties.put("RESOURCE_OPTION", "OptionA");
ResourceRequestById resourceRequest = new ResourceRequestById("0123456789abcdef0123456789abcdef", properties);
----

Depending on the support that the `ResourceReader` or `Source` provides for options, the `properties``Map` will be checked for the `RESOURCE_OPTION` entry.  If that entry is found, the option will be handled; however, the `ResourceReader` or `Source` supports options.  If the `ResourceReader` or `Source` does not support options, that entry will be ignored.

A new `ResourceReader` or `Source` implementation can be created to support options in a way that is most appropriate.  Since the option is passed through the catalog framework as a property, the `ResourceReader` or `Source` will have access to that option as long as the endpoint supports options.       

==== Store Resource

Resources are saved using a `ResourceWriter`. `ddf.catalog.resource.ResourceWriter` instances can be discovered via the OSGi Service Registry. Once retrieved, the `ResourceWriter` instance provides clients a way to store resources and get a corresponding URI that can be used to subsequently retrieve the resource via a 
`ResourceReader`. Simply invoke either of the `storeResource` methods with a resource and any potential arguments.
 
The `ResourceWriter` implementation is responsible for determining where the resource is saved and how it is saved.  This allows flexibility for a resource to be saved in any one of  a variety of data stores or file systems.  The following is an example of how to use a generic implementation of `ResourceWriter`.

 
[source,java,linenums]
----
InputStream inputStream = <Video_Input_Stream>; //InputStream of raw Resource data
MimeType mimeType = new MimeType("video/mpeg"); //Mime Type or content type of Resource
String name = "Facility_Video";  //Descriptive Resource name
Resource resource = new ResourceImpl(inputStream, mimeType, name);
Map<String, Object> optionalArguments = new HashMap<String, Object>();
ResourceWriter writer = new ResourceWriterImpl();
URI resourceUri; //URI that can be used to retrieve Resource
resourceUri = writer.storeResource(resource, optionalArguments); //Null can be passed in here
----
 
See the Developing a Resource Writer section in the Developer's Guide for more information and examples. 

===== BinaryContent

`BinaryContent` is an object used as a container to store translated or transformed DDF components. `Resource` extends `BinaryContent` andincludes a `getName` method.  `BinaryContent` has methods to get the `InputStream`, `byte` array, MIME type, and size of the represented binary data. An implementation of `BinaryContent` (`BinaryContentImpl`) can be found in the Catalog API in the `ddf.catalog.data` package.

====== Additional Information

* URI on Wikipedia (http://en.wikipedia.org/wiki/Uniform_resource_identifier)
* URI Javadoc (http://docs.oracle.com/javase/6/docs/api/java/net/URI.html)

== Developing Catalog Components

=== Store Resource
This section describes how to create Catalog components. Use in conjunction with the Javadoc to begin extending the DDF Catalog. 
