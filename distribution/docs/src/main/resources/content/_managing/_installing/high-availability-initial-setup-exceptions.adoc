:title: High Availability Initial Setup Exceptions
:type: subInstalling
:status: published
:parent: High Availability Initial Setup
:project: ${branding}
:order: 00

==== {title}

These steps are handled differently for the initial setup of a Highly Available Cluster.

===== Failover Proxy Integration

In order to integrate with a failover proxy, the ${branding} node's system properties (in `${home_directory}/etc/system.properties`) must be changed to publish the correct port to external systems and users.
This must be done before installing the first ${branding} node. See <<{managing-prefix}high_availability_initial_setup, High Availability Initial Setup>>.

There are two internal port properties that must be changed to whatever ports the ${branding} will use on its system.
Then there are two external port properties that must be changed to whatever ports the failover proxy is forwarding traffic through.

[WARNING]
====
Make sure that the failover proxy is already running and forwarding traffic on the chosen ports before starting the ${branding}.
There may be unexpected behavior otherwise.
====

In the below example, the failover proxy with a hostname of service.org is forwarding https traffic via 8993 and http traffic via 8181.
The ${branding} node will run on 1111 for https and 2222 for http (on the host that it's hosted on).
The hostname of the ${branding} must match the hostname of the proxy.
[source]
----
org.codice.ddf.system.hostname=service.org
org.codice.ddf.system.httpsPort=1111
org.codice.ddf.system.httpPort=2222
org.codice.ddf.system.port=${org.codice.ddf.system.httpsPort}

org.codice.ddf.external.hostname=service.org
org.codice.ddf.external.httpsPort=8993
org.codice.ddf.external.httpPort=8181
org.codice.ddf.external.port=${org.codice.ddf.external.httpsPort}
----

===== Identical Directory Structures

The two ${branding} nodes need to be under identical root directories on their corresponding systems.
On Windows, this means they must be under the same drive.

===== Highly Available Security Auditing

A third party tool will have to be used to persist the logs in a highly available manner.

* Edit the `${home_directory}/etc/org.ops4j.pax.logging.cfg` file to enable log4j2, following the steps in <<{managing-prefix}enabling_fallback_audit_logging, Enabling Fallback Audit Logging>>.
* Then put the appropriate log4j2 appender in `${home_directory}/etc/log4j2.xml` to send logs to the chosen third party tool.
See https://logging.apache.org/log4j/2.x/manual/appenders.html[Log4j Appenders].

===== Shared Storage Provider

The storage provider must be in a location that is shared between the two ${branding} nodes and must be highly available.
If hardening the Highly Available Cluster, this shared storage provider must be trusted/secured.
One way to accomplish this is to use the default <<{application-prefix}org.codice.ddf.catalog.content.impl.FileSystemStorageProvider,Content File System Storage Provider>> and configure it to point to a highly available shared directory.

===== High Availability Certificates

Due to the nature of highly available environments, localhost is not suitable for use as a hostname to identify the ${branding} cluster.
The default certificate that ships with the product uses localhost as the common name, so this certificate needs to be replaced.
The following describes how to generate a certificate signed by the ${branding} Demo Certificate Authority that uses a proper hostname.

[NOTE]
====
This certificate, and any subsequent certificates signed by the Demo CA, are intended for testing purposes only,
and should not be used in production.
====

Certificates need to have Subject Alternative Names (SANs) which will include the host for the failover
proxy and for both ${branding} nodes. A certificate with SANs signed by the Demo CA can be obtained by
navigating to `${home_directory}/etc/certs/` and, assuming the proxy's hostname is service.org, running
the following for UNIX operating systems:

[source]
----
./CertNew.sh -cn service.org -san "DNS:service.org"
----

or the following for Windows operating systems:

[source]
----
CertNew -cn service.org -san "DNS:service.org"
----

[NOTE]
====
Systems that use DDF version 2.11.4 or later will automatically get a DNS SAN entry matching the CN
without the need to specify the `-san` argument to the `CertNew` command.
====

More customization for certs can be achieved by following the steps at
<<{quickstart-prefix}creating_new_server_keystore_entry_with_the_certnew_scripts,Creating New Server Keystore Entry with the CertNew Scripts>>.

===== High Availability Installation Profile

Instead of having to manually turn features on and off, there is a High Availability installation profile.
This profile will not show up in the UI Installer, but can be installed by executing `profile:install ha` on the command line *instead* of stepping through the UI Installer.
This profile will install all of the High Availability supported features.
