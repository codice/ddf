:title: ${message-broker}
:status: published
:type: applicationReference
:summary: Controls the shutdown period of components, names of queues, and routing of messages.
:order: 02

== {title} Application Reference

The ${message-broker} application gives an administrator the ability to configure and control the behavior of the ${message-broker}.
These configurations will include aspects like the graceful shutdown period of components, names of queues and topics, and routing of messages.

=== Prerequisites for ${message-broker} Application

None.

=== Installing ${message-broker} Application

Install the ${message-broker} application through the ${admin-console}.

. Navigate to the *${admin-console}*.
. Select the *System* tab.
. Select the *Features* tab.
. Install the `broker-app` feature.

=== Configuring the ${message-broker} Application

The standard installation of the ${message-broker} application has no configurable properties.

==== Configuring the ${message-broker} for a Highly Available Cluster

Prior to making these configuration changes, follow the instructions in <<{managing-prefix}installing,Installing ${branding}>> to install ${branding} on two physically-separate hosts.

. Configure each of the ${branding} installations to point to each other in a live/backup server configuration. One server will have an additional step to be designated as the backup.
. Modify custom.system.properties: +
The `${home_directory}/etc/custom.system.properties` in each of the installations needs to be updated so that the servers know about each other. The following properties need to have the values on the right side of the `=` updated.
+
[source]
----
artemis.live.host=<Hostname.or.ip.here>
artemis.backup.host=<Hostname.or.ip.here>
artemis.network.iplist=<Comma,separated,IPs>
artemis.cluster.password=<Common password across all nodes>
----
+
.Using a Non-Local IP or Host
[IMPORTANT]
====
`artemis.network.iplist` should contain a list of non-local IPs or host names that are not hosted on the same physical machine as either the live or backup machines. These IP addresses are pinged in the event of a network outage. If the backup cannot reach the live server but can successfully ping one of these hosts it will then take over as the live server. If the host list is incorrectly configured with a local IP it could break the cluster by causing both servers to go live. It is also recommended that the live server have the backups server's IP in its list and the backup server have the live server's IP in its list.
====
+
. Configure a Backup Broker: +
The installation that is going to be used as the backup needs to have an additional configuration change made so that it knows it's the backup. The `${home_directory}/etc/org.apache.activemq.artemis.cfg` should be modified to point to the provided `artemis-backup.xml` instead of `artemis.xml`. Once updated, the `config` value should look like this:
+
[source]
----
config=file:etc/artemis-backup.xml
----
+
. Restart Servers: +
The ${branding} instances should be restarted in the following order:
1. Live server
2. Backup server
+
In order to maintain connectivity to the broker during a restart, only stop and start a single server at a time. See <<{managing-prefix}starting,Starting ${branding}>> for detailed steps.
+
. Verify Cluster Replication: +
Once both servers are started, the following command can be run using curl or a https://localhost:8993/admin/jolokia/read/org.apache.activemq.artemis:broker=%22localhost%22/ReplicaSync[browser] to verify that the servers have successfully synced.
+
.Server Cluster Verification Command
[source,bash]
----
sh
curl ${secure_url}/admin/jolokia/read/org.apache.activemq.artemis:broker=%22artemis%22/ReplicaSync --user admin:admin --header "Origin: ${secure_url}" --header "X-Requested-With: XMLHttpRequest" --insecure
----

.Example ReplicaSync JSON Response
[source,json]
----
{
	"request": {
		"mbean": "org.apache.activemq.artemis:broker=\"artemis\",
		"attribute": "ReplicaSync",
		"type": "read"
	},
	"value": true,
	"timestamp": 1485967446,
	"status": 200
}
----

[IMPORTANT]
====
If LDAP has been configured then the admin user and password for the above command will need to be changed.
====

[IMPORTANT]
====
Note the `"value":true` field: if it is false, then the replication is still in progress or the logs should be consulted to see if there was an issue establishing a connection between the live and backup servers.
====

Additionally, for more details about the health of the cluster, the following command can be run using curl or a \${secure_url}/admin/jolokia/read/org.apache.activemq.artemis:broker=%22artemis%22,component=cluster-connections,name=%22my-cluster%22/Topology[browser].

.Server Health Status Command
[source]
----
sh
curl ${secure_url}/admin/jolokia/read/org.apache.activemq.artemis:broker=%22artemis%22,component=cluster-connections,name=%22broker-cluster%22/Topology --user admin:admin --header "Origin: ${secure_url}" --header "X-Requested-With: XMLHttpRequest" --insecure
----

This endpoint returns diagnostic info about the cluster that can be used for troubleshooting. Values of interest in the response are the `node=2` value which is a count of the nodes in the cluster and the port/host values for each node.

.Example Topology JSON Response for a Cluster of 2
[source,json]
----
{
	"request": {
		"mbean": "org.apache.activemq.artemis:broker=\"artemis\",component=cluster-connections,name=\"my-cluster\",
		"attribute": "Topology",
		"type": "read"
	},
	"value": "topology on Topology@750c2a56[owner=ClusterConnectionImpl@228651110[nodeUUID=17b48db9-e7ee-11e6-9d56-38c986025a6f, connector=TransportConfiguration(name=netty-connector, factory=org-apache-activemq-artemis-core-remoting-impl-netty-NettyConnectorFactory) ?port=5672&host=10-101-3-185, address=jms, server=ActiveMQServerImpl::serverUUID=17b48db9-e7ee-11e6-9d56-38c986025a6f]]:\n\t17b48db9-e7ee-11e6-9d56-38c986025a6f => TopologyMember[id = 17b48db9-e7ee-11e6-9d56-38c986025a6f, connector=Pair[a=TransportConfiguration(name=netty-connector, factory=org-apache-activemq-artemis-core-remoting-impl-netty-NettyConnectorFactory) ?port=5672&host=10-101-3-185, b=TransportConfiguration(name=netty-connector, factory=org-apache-activemq-artemis-core-remoting-impl-netty-NettyConnectorFactory) ?port=5672&host=10-101-2-97], backupGroupName=null, scaleDownGroupName=null]\n\tnodes=2\tmembers=1",
	"timestamp": 1485971158,
	"status": 200
}
----

==== Securing the ${message-broker} Application

${branding} can be configured to use Artemis to perform authentication and authorization against an LDAP server.

Artemis provides the ability to apply role-based security to queues based on addresses
(see https://activemq.apache.org/artemis/docs/${artemis.version}/security.html[the Artemis documentation] {external-link}
for details).
It can be configured to use an LDAP server to perform authentication and authorization for users who connect to it.

[IMPORTANT]
====
If you are setting up multiple ${branding} instances in a cluster for high availability, then you will need to perform these steps on each instance.
====

The ${ddf-security} STS LDAP Login and ${ddf-security} STS LDAP Claims Handler bundles are responsible for authenticating and authorizing users with your LDAP server.
To configure them for your LDAP server, follow the instructions in <<{integrating-prefix}security_sts_ldap_login,STS LDAP Login>> and <<{integrating-prefix}security_sts_ldap_claims_handler, STS LDAP Claims Handler>>.

Once the STS LDAP Login and Claims Handlers are configured, update `${home_directory}/etc/org.apache.activemq.artemis.cfg` to use the `ldap` realm (just change `domain=karaf` to `domain=ldap`):

.${home_directory}/etc/org.apachc.activemq.artemis.cfg
----
domain=ldap
----

${branding} uses two roles in the security settings for Artemis: `manager` and `broker-client`.

.${home_directory}/etc/artemis.xml
[source,xml]
----
<security-setting match="#">
    <permission type="createNonDurableQueue" roles="manager,broker-client"/>
    <permission type="deleteNonDurableQueue" roles="manager,broker-client"/>
    <permission type="createDurableQueue" roles="manager"/>
    <permission type="deleteDurableQueue" roles="manager"/>
    <permission type="consume" roles="manager,broker-client"/>
    <permission type="browse" roles="manager,broker-client"/>
    <permission type="send" roles="manager,broker-client"/>
    <permission type="manage" roles="manager"/>
</security-setting>
----

Users with the role `manager` have full permissions, but users with the role `broker-client` cannot
create or delete durable queues or invoke management operations.

Your LDAP should have groups that correspond to these roles so that members of those groups will have
the correct permissions when connecting to Artemis to send or consume messages.
Alternatively, you can choose roles other than `manager` and `broker-client`, which may be useful if your LDAP already
has groups that you would like to use as Artemis roles.
If you wish to use different roles, just replace `manager` and/or `broker-client` in the `<security-setting>` in `artemis.xml` with the roles you would like to use.

==== Artemis Broker Connection Configuration

The `Artemis Broker Connection Configuration` manages the parameters for ${branding}'s connection to
Artemis. The username and password in the `Artemis Broker Connection Configuration` need to be updated
so that they correspond to a user in your LDAP. If possible, this user should have the `manager` role
(or the role that is being used in place of `manager` if the default Artemis role has been changed).

To update the username and password:

. Navigate to the *${admin-console}*
. Select the *Broker App* application.
. Select the *Configuration* tab.
. Select the *Artemis Broker Connection Configuration*.
. Enter the username and password and select *Save changes*.

=== Using the ${message-broker} Application

The ${message-broker} app can be used through the ${admin-console}.
See the <<{reference-prefix}route_manager,Route Manager>> and the <<{reference-prefix}undelivered_messages_ui,Undelivered Messages UI>> for more information.

==== Undelivered Messages UI

The Undeliverable Messages tab gives an administrator the ability to view undeliverable messages and then decide whether to resend or delete those messages.

The Undelivered Messages UI is installed as a part of the Message Broker.

To view undelivered messages, an administrator can use the "retrieve" button, which makes an immediate call to the backend and displays all the messages.
Alternatively, the "start polling" button makes calls to the backend every 5 seconds and updates the display accordingly.

An administrator can select messages by clicking anywhere in the row of the message.
Multiple messages can be selected simply by clicking multiple messages or by clicking the "Select all" option at the head of the table.
Deselecting is done by clicking a message again or clicking the "Deselect all" option, next to the "Select all" option.

To attempt to resend messages, select the messages, and then click the "resend" button.
Currently, there is no way to identify if a message was successfully redelivered.

To delete messages, select the messages, and then click the "delete" button.

[NOTE]
====
Only 200 messages can be viewed at a time, even though there may be more than 200 undelivered messages
====

Known issues with the Undelivered Messages UI:

- If attempting to resend a message, but the listener is no longer available, the message will be "successfully" resent and removed from the UI and the Artemis DLQ but will not be successfully redelivered.

==== Route Manager

The Route Manager gives an administrator the ability to configure and deploy Camel routes, queues, and topics dynamically. The `sjms` component is available by default. If a need arises for a new route, an administrator can easily develop a new route and deploy it to satisfy the requirement, rather than spending the time to develop, compile, and test new code.

The Route Manager is installed as a part of the ${message-broker} application.

The route shutdown timeout can be configured.

To deploy a new route, simply place a route `.XML` file in the `${home_directory}/etc/routes` directory of ${branding}. To remove a route (or set of routes), delete the `.XML` file.

There are example routes in the `${home_directory}/etc/routes` directory by default.
