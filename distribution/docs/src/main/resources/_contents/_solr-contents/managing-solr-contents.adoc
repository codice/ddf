
The Solr Catalog Provider (SCP) is an implementation of the `CatalogProvider` interface using http://lucene.apache.org/solr/[Apache Solr] as a data store.

=== ${branding} Catalog Solr External Provider

==== Using

The Solr Catalog Provider is used in conjunction with an Apache Solr Server data store and acts as the client for an external Solr Server.
It is meant to be used only with the Standalone Solr Server (`catalog-solr-server`).

==== Installing and Uninstalling

===== Prerequisites

Before the ${ddf-solr} Application can be installed,

* the ${ddf-platform} Application and
* the ${ddf-catalog} Application must be installed.

===== Installing

By default, the ${ddf-solr} application installs the External Solr Provider.


===== Configuring

In order for the external Solr Catalog Provider to work, it must be pointed at the external Solr Server.
When the `catalog-solr-external-provider` feature is installed, it is in an unconfigured state until the user provides an HTTP URL to the external Solr Server. 
The configurable properties for this SCP are accessed from the Catalog External Solr Catalog Provider configurations in the Web Console.

====== Configurable Properties
[cols="1,1,1,3a,2,1" options="header"]
|===
|Title
|Property
|Type
|Description
|Default Value
|Required

|HTTP URL
|`url`
|String
|HTTP URL of the standalone, preconfigured Solr Server.
|\${secure_url}/solr
|Yes

|Force AutoCommit
|`forceAutoCommit`
|Boolean / Checkbox
|
[IMPORTANT]
====
*Performance Impact* +
Only in special cases should auto-commit be forced.
Forcing auto-commit makes the search results visible immediately.
====
|Unchecked
|No

|Disable Text Path Indexing
|
|Boolean / Checkbox
|Unchecked
|No

|===

=== ${branding} Catalog Solr Embedded Provider

==== Using

The Solr Catalog Embedded Provider is an embedded, local Solr Server instance used in conjunction with an Apache Solr Server data store.
It is a local instance that is a lightweight Catalog provider solution. However, it does not provide a Solr Admin GUI or a "REST-like HTTP/XML and JSON API." If that is necessary, see Standalone Solr Server.

==== Installing and Uninstalling

===== Prerequisites

Before the ${ddf-solr} Application can be installed:

* the ${branding} Kernel must be running,
* the ${branding} Platform Application must be installed, and
* the ${branding} Catalog Application must be installed

===== Installing

. Navigate to the ${ddf-solr} application in the Admin console.
. Under the *Features* tab, uninstall the `catalog-solr-external-provider` feature.
. Install the `catalog-solr-embedded-provider`

==== Configuring Embedded Solr Server and Solr Catalog Provider

No configuration is necessary for the embedded Solr Server and the Solr Catalog Provider.
The standard installation described above is sufficient.
When the `catalog-solr-embedded-provider` feature is installed, it stores the Solr index files to `<DISTRIBUTION_INSTALLATION_DIRECTORY>/data/solr` by default.
A user does not have to specify any parameters and the `catalog-solr-embedded-provider` feature contains all files necessary for Solr to start the server. 

However, this component _can_ be configured to specify the directory to use for data storage. 

The configurable properties for the SCP are accessed from the *Catalog Embedded Solr Catalog Provider* configurations in the Web Console.

[TIP]
====
The Embedded (Local) Solr Catalog Provider works on startup without any configuration because a local embedded Solr Server is automatically started and pre-configured.
====

===== Configurable Properties

[cols="1,1,1,4a,1,1" options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Data Directory File Path
|`dataDirectoryPath`
|String
|Specifies the directory to use for data storage. The server must be shutdown for this property to take effect. If a filepath is provided with directories that don't exist, SCP will attempt to create those directories. Out of the box (without configuration), the SCP writes to `<DISTRIBUTION_INSTALLATION_DIRECTORY>/data/solr`.

If `dataDirectoryPath` is left blank (empty string), it will default to `<DISTRIBUTION_INSTALLATION_DIRECTORY>/data/solr`.

If data directory file path is a relative string, the SCP will write the data files starting at the installation directory. For instance, if the string `scp/solr_data` is provided, the data directory will be at `<DISTRIBUTION_INSTALLATION_DIRECTORY>/scp/solr_data`.

If data directory file path is `/solr_data` in Windows, the Solr Catalog Provider will write the data files starting at the beginning of the drive, e.g., `C:\solr_data`.

It is recommended that an absolute filepath be used to minimize confusion, e.g., `/opt/solr_data` in Linux or `C:\solr_data` in Windows. Permissions are necessary to write to the directory.
|
|No

|Force Auto Commit
|`forceAutoCommit`
|Boolean / Checkbox
|[IMPORTANT]
====
*Performance Impact* +
Only in special cases should auto-commit be forced. Forcing auto-commit makes the search results visible immediately.
====
|
|No

|===

==== Solr Configuration Files

The Apache Solr product has Configuration files to customize behavior for the Solr Server. These files can be found at `<DISTRIBUTION_INSTALLATION_DIRECTORY>/etc/solr`.
Care must be taken in editing these files because they will directly affect functionality and performance of the Solr Catalog Provider.
A restart of the distribution is necessary for changes to take effect. 
 
[WARNING]
====
*Solr Configuration File Changes* +
Solr Configuration files should not be changed in most cases.
Changes to the `schema.xml` will most likely need code changes within the Solr Catalog Provider.
====

==== Move Solr Data to a New Location

If SCP has been installed for the first time, changing the Data Directory File Path property and restarting the distribution is all that is necessary because no data had been written into Solr previously.
Nonetheless, if a user needs to change the location after the user has already ingested data in a previous location, complete the following procedure:

. Change the data directory file path property within the *Catalog Embedded Solr Catalog Provider* configuration in the Admin Console to the desired future location of the Solr data files.
. Shut down the distribution.
. Find the future location on the drive. If the current location does not exist, create the directories.
. Find the location of where the current Solr data files exist and copy all the directories in that location to the future the location. For instance, if the previous Solr data files existed at C:\solr_data and it is necessary to move it to C:\solr_data_new, copy all directories within `C:\solr_data` into `C:\solr_data_new`. Usually this consists of copying the index and tlog directories into the new data directory.
. Start the distribution. SCP should recognize the index files and be able to query them again.

[WARNING]
====
*Changes Require a Distribution Restart* +
If the Data Directory File Path property is changed, no changes will occur to the SCP until the distribution has been restarted.
====

[NOTE]
====
If data directory file path property is changed to a new directory, and the previous data is not moved into that directory, no data will exist in Solr.
Instead, Solr will create an empty index.
Therefore, it is possible to have multiple places where Solr files are stored, and a user can toggle between those locations for different sets of data.
====

=== Standalone Solr Server

The Standalone Solr Server gives the user an ability to run an Apache Solr instance as a Catalog data store within the distribution. 
The Standalone Solr Server contains a Solr Web Application Bundle and pre-configured Solr configuration files.
A Solr Web Application Bundle is essentially the Apache Solr war repackaged as a bundle and configured for use within this distribution. 

==== Using

Users can use this feature to create a data store.
Users would use this style of deployment over an embedded Java Solr Server when the user wants to install a Solr Server on a separate, dedicated machine for the purpose of isolated data storage or ease of maintenance. 
The Standalone Solr Server can now run in its own JVM (separate from endpoints and other frameworks) and accept calls with its "REST-like HTTP/XML and JSON API." 

This Standalone Solr Server is meant to be used in conjunction with the Solr Catalog Provider for External Solr.
The Solr Catalog Provider acts as a client to the Solr Server.

==== Installing and Uninstalling

===== Prerequisites

Before the ${ddf-solr} Application can be installed for configuration as the Standalone Solr Server, the ${branding} Kernel must be running.

In production environments, it is recommended that Standalone Solr Server be run in isolation on a separate machine in order to maximize the Solr Server performance and use of resources such as RAM and CPU cores.
The Standalone Solr Server, as its name suggests, does not require or depend on other apps, such as the Catalog API, nor does it require their dependencies, such as Camel, CXF, etc.
Therefore, it is recommended to have the Solr Server app run on a lightweight ${branding} distribution, such as the ${branding} Distribution Kernel.
If clustering is necessary, the Solr Server application can run alongside the Platform application for clustering support.

==== Installing

By default, the features for the Standalone Solr Server and External Solr Catalog Provider are installed.

===== Remove Data from Solr Core

It is possible to remove data in the Solr index of a Solr core.  
Replace `<CORE_NAME>` in the following command with a valid Solr core to delete all data in that Solr core:

.How to delete Solr Core data with curl
----
curl '${secure_url}/solr/<CORE_NAME>/update?commit=true' -H 'Content-type: text/xml' -d '<delete><query>*:*</query></delete>'
----

Use the core selector in the Solr administration page to get a list of available Solr cores.

.Solr administration page
----
${secure_url}/solr
----

==== Configuring

The Standalone Solr Server comes pre-configured to work with Solr Catalog External Provider implementations.
For most use cases, no other configuration to the Solr Server is necessary with the standard distribution.

==== Known Issues

The standalone Solr Server fails to install if it has been previously uninstalled prior to the distribution being restarted.

==== Solr Standalone Server Meta Catalog Backup

Prior to setting up backup for the Solr Metadata catalog, it is important to plan how backup and recovery will be executed.
The amount and velocity of data entering the catalog differ depending on the use of the system.
As such, there will be varying plans depending on the need.
It is important to get a sense of how often the data changes in the catalog in order to determine how often the data should be backed up.
When something goes wrong with the system and data is corrupted, how much time is there to recover?
A plan must be put in place to remove corrupted data from the catalog and replace it with backed up data in a time span that fits deadlines.
Equipment must also be purchased to maintain backups, and this equipment may be co-located with local production systems or remotely located at a different site.
A backup schedule will also have to be determined so that it does not affect end users interacting with the production system.

===== Back Up Data from the Solr Server Standalone Metadata Catalog

The Solr server contains a built-in backup system capable of saving full snapshot backups of the catalog data upon request.
Backups are created by using a web based service.
Through making a web based service call utilizing the web browser, a time-stamped backup can be generated and saved to a local drive, or location where the backup device has been mounted. 

The URL for the web call contains three parameters that allow for the customization of the backup:

command:: allows for the command 'backup' to backup the catalog.
location:: allows for a file system location to place the backup to be specified.
numberToKeep:: allows the user to specify how many backups should be maintained. If the number of backups exceed the "numberToKeep" value, the system will replace the oldest backup with the newest one.

An example URL would look like \http://127.0.0.1:8181/solr/replication?command=backup&location=d:/solr_data&numberToKeep=5.

The IP address and port in the URL should be replaced with the IP address and port of the Solr Server.
The above URL would run a backup, save the backup file in `D:/solr_data`, and it would keep up to five backup files at any time.
To execute this backup, first ensure that the Solr server is running.
Once the server is running, create the URL and copy it into a web browser window.
Once the URL is executed, the following information is returned to the browser: 

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<response>
 <lst name="responseHeader">
  <int name="status">0</int>
  <int name="QTime">15</int>
 </lst>
 <str name="status">OK</str>
</response>
----

If the status equals 0, there was success.
Qtime shows the time it took to execute the backup (in milliseconds).
Backup files are saved in directories which are given the name `snapshot` along with a timestamp.
Within the directory are all of the files that contain the data from the catalog.

===== Restore Data to the Solr Server Standalone Metadata Catalog

Under certain circumstances, such as when data has been corrupted, information has accidentally been deleted, or a system upgrade is occurring, the catalog must be restored.
The backup files acquired from the previous section will be used to restore data into the catalog.

. The first step in the process is to choose which data backup will be used for restoring the catalog. A most recent backup maybe the correct choice, or the last stable backup may be a better option.
. At this point, one more backup may be executed to save the corrupted data just in case it needs to be revisited.
. Shut down the Solr server. The catalog cannot be restored while the server is running.
. Locate the index that contains all of the Solr data. This index is found at 
`${ddf-branding}_INSTALL/solr/collection1/data/index`
. All files within the index directory should be deleted.
. Copy the files from the chosen backup directory into the index directory.
. Restart the Solr server. The data should now be restored.

===== Suggestions for Managing Backup and Recovery

Here are some helpful suggestions for setting up data backups and recoveries:

* Acquire a backup drive that is separate from the media that runs the server. Mount this drive as a directory and save backups to that location.
* Ensure that the backup media has enough space to support the number of backups that need to be saved.
* Run a scheduler program that calls the backup URL on a timed basis.
* Put indicators in place that can detect when data corruption may have occurred.
* Testing a backup before recovery is possible. A replicated "staging" Solr server instance can be stood up, and the backup can be copied to that system for testing before moving it to the "production" system.
