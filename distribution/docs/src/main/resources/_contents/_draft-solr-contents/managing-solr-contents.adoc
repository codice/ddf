
=== ${branding} Solr

Whenever the {branding} Solr ingests data, it creates an index for it in the data directory.
This data indexing enables the data to be searchable by the {branding} Solr.

The data in the data directory can then be persisted by performing a `commit` on the {branding} Solr.
When the {branding} Solr is restarted, it reloads the data to get back the index.

The ${branding} supports three Solr Provider Types: Solr External Provider, Solr Embedded Provider, and Solr Cloud.

==== Solr Configuration Files

The Apache Solr product has Configuration files to customize behavior for the Solr Server. These files can be found at `<DISTRIBUTION_INSTALLATION_DIRECTORY>/etc/solr`.
Care must be taken in editing these files because they will directly affect functionality and performance of the Solr Provider.
A restart of the distribution is necessary for changes to take effect.

[WARNING]
====
*Solr Configuration File Changes* +
Solr Configuration files should not be changed in most cases.
Changes to the `schema.xml` will most likely need code changes within the Solr Provider.
====

=== ${branding} Solr External Provider

==== Using

The Solr External Provider provides acts as the client for an external Solr Server.

===== Prerequisites

Before the ${ddf-solr} Application can be installed,

* the ${branding} Kernel must be running,
* the ${ddf-platform} Application and
* the ${ddf-catalog} Application must be installed.

===== Installing

By default, the ${ddf-solr} application installs the External Solr Provider.

===== Configuring

. Edit the <INSTALLATION_DIR>/etc/system.properties

.. Comment out the Solr Client Configuration for *Cloud Solr Client* and *Embedded Solr Client* sections.
.. Uncomment the section for the *Http Solr Client*:

.system.properties

----

solr.client = HttpSolrClient

solr.http.url = ${org.codice.ddf.system.protocol}${org.codice.ddf.system.hostname}:${org.codice.ddf.system.httpsPort}/solr

solr.data.dir = ${karaf.home}/data/solr

----

=== ${branding} Solr Embedded Provider

==== Using

The Solr Embedded Provider is an embedded, local Solr Server instance used in conjunction with an Apache Solr Server data store.
It is a local instance that is a lightweight Solr provider solution.
However, it does not provide a Solr Admin GUI or a REST-like HTTP/XML and JSON API.
If that is necessary, see Standalone Solr Server or Solr External Provider.

==== Installing

===== Prerequisites

Before the ${ddf-solr} Application can be installed:

* the ${branding} Kernel must be running,
* the ${branding} Platform Application must be installed, and
* the ${branding} Solr Application must be installed

===== Installing

. Edit the <INSTALLATION_DIR>/etc/system.properties

.. Comment out the Solr Client Configuration for *Cloud Solr Client* and *Http Solr Client* sections.
.. Uncomment the section for the *Embedded Solr Client*:

.system.properties
----
solr.client = EmbeddedSolrServer
----

==== Configuring Embedded Solr Server

No configuration is necessary for the embedded Solr Server.
The standard installation described above is sufficient.

However, this component _can_ be configured to specify the directory to use for data storage.

The configurable properties for the Solr Provider are accessed from the *Embedded Solr Provider* configurations in the Web Console.

===== Configurable Properties

[cols="1,1,1,4a,1,1" options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Data Directory File Path
|`dataDirectoryPath`
|String
|Specifies the directory to use for data storage. The server must be shutdown for this property to take effect. If a filepath is provided with directories that don't exist, Solr Provider will attempt to create those directories. Out of the box (without configuration), the Solr Provider writes to `<DISTRIBUTION_INSTALLATION_DIRECTORY>/data/solr`.

If `dataDirectoryPath` is left blank (empty string), it will default to `<DISTRIBUTION_INSTALLATION_DIRECTORY>/data/solr`.

If data directory file path is a relative string, the Solr Provider will write the data files starting at the installation directory. For instance, if the string `scp/solr_data` is provided, the data directory will be at `<DISTRIBUTION_INSTALLATION_DIRECTORY>/scp/solr_data`.

If data directory file path is `/solr_data` in Windows, the Solr Provider will write the data files starting at the beginning of the drive, e.g., `C:\solr_data`.

It is recommended that an absolute filepath be used to minimize confusion, e.g., `/opt/solr_data` in Linux or `C:\solr_data` in Windows. Permissions are necessary to write to the directory.
|
|No

|Force Auto Commit
|`forceAutoCommit`
|Boolean / Checkbox
|
[IMPORTANT]
====
*Performance Impact* +
Only in special cases should auto-commit be forced. Forcing auto-commit makes the search results visible immediately.
====
|
|No

|===

==== Move Solr Data to a New Location

If Solr Provider has been installed for the first time, changing the Data Directory File Path property and restarting the distribution is all that is necessary because no data had been written into Solr previously.
Nonetheless, if a user needs to change the location after the user has already ingested data in a previous location, complete the following procedure:

. Change the data directory file path property within `etc/system.properties` files to the desired future location of the Solr data files.
. Shut down the distribution.
. Find the future location on the drive.
If the current location does not exist, create the directories.
. Find the location of where the current Solr data files exist and copy all the directories in that location to the future the location. For instance, if the previous Solr data files existed at C:\solr_data and it is necessary to move it to C:\solr_data_new, copy all directories within `C:\solr_data` into `C:\solr_data_new`. Usually this consists of copying the index and tlog directories into the new data directory.
. Start the distribution.
The Solr Provider should recognize the index files and be able to query them again.

[WARNING]
====
*Changes Require a Distribution Restart* +
If the Data Directory File Path property is changed, no changes will occur to the Solr Provider until the distribution has been restarted.
====

[NOTE]
====
If data directory file path property is changed to a new directory, and the previous data is not moved into that directory, no data will exist in Solr.
Instead, Solr will create an empty index.
Therefore, it is possible to have multiple places where Solr files are stored, and a user can toggle between those locations for different sets of data.
====

=== Standalone Solr Server

The Standalone Solr Server gives the user an ability to run an Apache Solr instance as a data store within the distribution.
The Standalone Solr Server contains a Solr Web Application Bundle and pre-configured Solr configuration files.
A Solr Web Application Bundle is essentially the Apache Solr war repackaged as a bundle and configured for use within this distribution.

==== Using

Users can use this feature to create a data store.
Users would use this style of deployment over an embedded Java Solr Server when the user wants to install a Solr Server on a separate, dedicated machine for the purpose of isolated data storage or ease of maintenance.
The Standalone Solr Server can now run in its own JVM (separate from endpoints and other frameworks) and accept calls with its "REST-like HTTP/XML and JSON API."

This Standalone Solr Server is meant to be used in conjunction with the Solr Provider for External Solr.
The Solr Provider acts as a client to the Solr Server.

==== Installing and Uninstalling

===== Prerequisites

Before the ${ddf-solr} Application can be installed for configuration as the Standalone Solr Server, the ${branding} Kernel must be running.

In production environments, it is recommended that Standalone Solr Server be run in isolation on a separate machine in order to maximize the Solr Server performance and use of resources such as RAM and CPU cores.
The Standalone Solr Server, as its name suggests, does not require or depend on other apps, such as the Catalog API, nor does it require their dependencies, such as Camel, CXF, etc.
Therefore, it is recommended to have the Solr Server app run on a lightweight ${branding} distribution, such as the ${branding} Distribution Kernel.
If clustering is necessary, the Solr Server application can run alongside the Platform application for clustering support.

==== Installing

By default, the features for the Standalone Solr Server and External Solr Provider are installed.

===== Remove Data from Solr Core

It is possible to remove data in the Solr index of a Solr core.
Replace `<CORE_NAME>` in the following command with a valid Solr core to delete all data in that Solr core:

.How to delete Solr Core data with curl
----
curl '${secure_url}/solr/<CORE_NAME>/update?commit=true' -H 'Content-type: text/xml' -d '<delete><query>*:*</query></delete>'
----

Use the core selector in the Solr administration page to get a list of available Solr cores.

.Solr administration page
----
${secure_url}/solr
----

==== Configuring

The Standalone Solr Server comes pre-configured to work with Solr External Provider implementations.
For most use cases, no other configuration to the Solr Server is necessary with the standard distribution.

==== Known Issues

The standalone Solr Server fails to install if it has been previously uninstalled prior to the distribution being restarted.

==== Solr Standalone Server Meta Catalog Backup

Prior to setting up backup for the Solr Metadata catalog, it is important to plan how backup and recovery will be executed.
The amount and velocity of data entering the catalog differ depending on the use of the system.
As such, there will be varying plans depending on the need.
It is important to get a sense of how often the data changes in the catalog in order to determine how often the data should be backed up.
When something goes wrong with the system and data is corrupted, how much time is there to recover?
A plan must be put in place to remove corrupted data from the catalog and replace it with backed up data in a time span that fits deadlines.
Equipment must also be purchased to maintain backups, and this equipment may be co-located with local production systems or remotely located at a different site.
A backup schedule will also have to be determined so that it does not affect end users interacting with the production system.

===== Back Up Data from the Solr Server Standalone Metadata Catalog

The Solr server contains a built-in backup system capable of saving full snapshot backups of the catalog data upon request.
Backups are created by using a web based service.
Through making a web based service call utilizing the web browser, a time-stamped backup can be generated and saved to a local drive, or location where the backup device has been mounted.

The URL for the web call contains three parameters that allow for the customization of the backup:

command:: allows for the command 'backup' to backup the catalog.
location:: allows for a file system location to place the backup to be specified.
numberToKeep:: allows the user to specify how many backups should be maintained. If the number of backups exceed the "numberToKeep" value, the system will replace the oldest backup with the newest one.

An example URL would look like \http://127.0.0.1:8181/solr/replication?command=backup&location=d:/solr_data&numberToKeep=5.

The IP address and port in the URL should be replaced with the IP address and port of the Solr Server.
The above URL would run a backup, save the backup file in `D:/solr_data`, and it would keep up to five backup files at any time.
To execute this backup, first ensure that the Solr server is running.
Once the server is running, create the URL and copy it into a web browser window.
Once the URL is executed, the following information is returned to the browser:

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<response>
 <lst name="responseHeader">
  <int name="status">0</int>
  <int name="QTime">15</int>
 </lst>
 <str name="status">OK</str>
</response>
----

If the status equals 0, there was success.
Qtime shows the time it took to execute the backup (in milliseconds).
Backup files are saved in directories which are given the name `snapshot` along with a timestamp.
Within the directory are all of the files that contain the data from the catalog.

===== Restore Data to the Solr Server Standalone Metadata Catalog

Under certain circumstances, such as when data has been corrupted, information has accidentally been deleted, or a system upgrade is occurring, the catalog must be restored.
The backup files acquired from the previous section will be used to restore data into the catalog.

. The first step in the process is to choose which data backup will be used for restoring the catalog. A most recent backup maybe the correct choice, or the last stable backup may be a better option.
. At this point, one more backup may be executed to save the corrupted data just in case it needs to be revisited.
. Shut down the Solr server. The catalog cannot be restored while the server is running.
. Locate the index that contains all of the Solr data. This index is found at
`${ddf-branding}_INSTALL/solr/collection1/data/index`
. All files within the index directory should be deleted.
. Copy the files from the chosen backup directory into the index directory.
. Restart the Solr server. The data should now be restored.

===== Suggestions for Managing Backup and Recovery

Here are some helpful suggestions for setting up data backups and recoveries:

* Acquire a backup drive that is separate from the media that runs the server. Mount this drive as a directory and save backups to that location.
* Ensure that the backup media has enough space to support the number of backups that need to be saved.
* Run a scheduler program that calls the backup URL on a timed basis.
* Put indicators in place that can detect when data corruption may have occurred.
* Testing a backup before recovery is possible. A replicated "staging" Solr server instance can be stood up, and the backup can be copied to that system for testing before moving it to the "production" system.

=== High Availability (Beta)

High Availability in ${branding} is used when a highly available Solr service is needed.
Solr Cloud is a highly available distributed capability of Solr.
In Solr Cloud, if a Solr server fails, another Solr server will be able to provide distributed indexing and search capabilities to the ${branding}.
Solr Cloud enables the ${branding} to be scalable and be fault tolerant.
The instructions on setting up High Availabilty for ${branding} only include setup in a *NIX environment.

[NOTE]
====
High Availability is currently in Beta version.
It is implemented but has not been tested thoroughly.
Bugs and feature changes may affect the final release.
====


==== Zookeeper

Zookeeper is a distributed hierarchical key-value store, which is used to provide a distributed configuration service, synchronization service, and naming registry for large distributed systems.
Zookeeper is needed because Solr Cloud uses it to manage its configuration.

===== Prerequisites for Zookeeper

ZooKeeper 3.4.5

*NIX environment

JDK 8 or greater

===== Installing Zookeeper

Refer to https://zookeeper.apache.org/doc/r3.1.2/zookeeperStarted.html#sc_Download for installation instructions.

[NOTE]
====
Minimum three Zookeeper nodes required.
Three Zookeeper nodes are needed to form a quorum.
A three Zookeeper ensemble allows for a single server to fail and the service will still be available.
====

==== Solr Cloud

Solr Cloud provides distributed capabilities needed by Solr servers to communicate and establish a highly available, fault tolerant cluster of Solr instances.

===== Prerequisites for Solr Cloud

Solr 6

*NIX environment

Zookeeper

JDK 8 or greater

====== Installing Solr Cloud

Repeat the following procedure for each node that will be part of the Solr Cloud cluster:

. Refer to https://cwiki.apache.org/confluence/display/solr/Apache+Solr+Reference+Guide for installation instructions.
. Download jar files.
The jars are needed to support geospatial and xpath queries and need to be installed on every "node" after the Solr Cloud installation instructions have been followed.

.. http://artifacts.codice.org/service/local/repositories/releases/content/org/codice/thirdparty/jts/1.12_1/jts-1.12_1.jar
.. http://artifacts.codice.org/service/local/artifact/maven/content?r=snapshots&g=ddf.platform.solr&a=solr-xpath&v=${ddf.version}

. Copy downloaded jar files to: `/opt/solr/server/solr-webapp/webapp/WEB-INF/lib/`

[NOTE]
====
Minimum two Solr Cloud instances required with each Solr Cloud instance having a two shard minimum.
Having two Solr Cloud instances guarantees that at least one Solr Cloud is available if one fails.
The two shards enables the document mapping to be restored if one shard becomes unavailable.
====

==== Setting up ${branding} to use Solr Cloud

. On the ${branding} server, edit <INSTALLATION_DIRECTORY>/etc/system.properties:
.. Set solr.client to CloudSolrClient
.. Set solr.cloud.zookeeper to <ZOOKEEPER_1_HOSTNAME>:<PORT_NUMBER>, <ZOOKEEPER_2_HOSTNAME>:<PORT_NUMBER>, <ZOOKEEPER_n_HOSTNAME>:<PORT_NUMBER>
.. Comment out `solr.http.url` and `solr.data.dir`

.system.properties
----
solr.client = CloudSolrClient
solr.cloud.zookeeper = zk1:2181,zk2:2181,zk3:2181
#solr.http.url
#solr.data.dir
----
