
=== Design

The Catalog is composed of several components and an API that connects them together.
The Catalog API is central to ${branding}'s architectural qualities of extensibility and flexibility. 
The Catalog API consists of Java interfaces that define Catalog functionality and specify interactions between components. 
These interfaces provide the ability for components to interact without a dependency on a particular underlying implementation, thus allowing the possibility of alternate implementations that can maintain interoperability and share developed components.
As such, new capabilities can be developed independently, in a modular fashion, using the Catalog API interfaces and reused by other ${branding} installations.

==== Ensuring Compatibility

The Catalog API will evolve, but great care is taken to retain backwards compatibility with developed components.
Compatibility is reflected in version numbers.

This section supports integration of the Catalog Application.

=== Integrating Endpoints

Endpoints act as a proxy between the client and the Catalog Framework.

Endpoints expose the Catalog Framework to clients using protocols and formats that they understand.

Endpoint interface formats/protocols can include a variety of formats, including (but not limited to):

* SOAP Web services

* RESTful services

* JMS

* JSON

* OpenSearch

The endpoint may transform a client request into a compatible Catalog format and then transform the response into a compatible client format.
Endpoints may use Transformers to perform these transformations.
This allows an endpoint to interact with Source(s) that have different interfaces.
For example, an OpenSearch Endpoint can send a query to the Catalog Framework, which could then query a federated source that has no OpenSearch interface.

Endpoints are meant to be the only client-accessible components in the Catalog.

.Endpoint Architecture
[ditaa, endpoint_architecture, png, ${image-width}]
....
+------------------------------------------------------------+
|                /-=-----------------\                       |
|                |      Clients      |                       |
|                \-------------------/                       |
|                          |                                 |
|                          v                                 |
|                /-------------------\                       |
|                |c369Endpoints      |                       |
|                +------------+------+                       |
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |cDEF               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------+
....

==== Existing Endpoints

The following endpoints are provided with the default Catalog out of the box:

===== ${ddf-catalog} RESTful CRUD Endpoint

The Catalog REST Endpoint allows clients to perform CRUD operations on the Catalog using REST, a simple architectural style that performs communication using HTTP. 
The URL exposing the REST functionality is located at \http://<HOST>:<PORT>/services/catalog, where `HOST` is the IP address of where the distribution is installed and `PORT` is the port number on which the distribution is listening.

====== Installing and Uninstalling

The RESTful CRUD Endpoint can be installed and uninstalled using the normal processes described in the Configuring ${branding} section.

====== Configuring

The RESTful CRUD Endpoint has no configurable properties.
It can only be installed or uninstalled.

====== Using the REST CRUD Endpoint

The RESTful CRUD Endpoint provides the capability to query, create, update, and delete metacards and associated resource in the catalog provider as follows:

[cols="2,1,3,4", options="header"]
|===

|Operation
|HTTP Request
|Details
|Example URL

|`create`
|HTTP POST
|HTTP request body contains the input to be ingested.
|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog

|`update`
|HTTP PUT
|The ID of the Metacard to be updated is appended to the end of the URL.

The updated metadata is contained in the HTTP body.

|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/<metacardId>

where `<metacardId>` is the `Metacard.ID` of the metacard to be updated

|`delete`
|HTTP DELETE
|The ID of the Metacard to be deleted is appended to the end of the URL.
|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/<metacardId>

where `<metacardId>` is the `Metacard.ID` of the metacard to be deleted


|`read`
|HTTP GET
|The ID of the Metacard to be retrieved is appended to the end of the URL. +
By default, the response body will include the XML representation of the Metacard.

|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/<metacardId>

where `<metacardId>` is the `Metacard.ID` of the metacard to be retrieved

|`federated read`
|HTTP GET
|The SOURCE ID of a federated source is appended in the URL before the ID of the Metacard to be retrieved is appended to the end.

|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/sources/<sourceId>/<metacardId>

where `<sourceid>` is the `FEDERATED SOURCE ID` and `<metacardId>` is the `Metacard.ID` of the Metacard to be retrieved

|`sources`
|HTTP GET
|Retrieves information about federated sources, including `sourceid`, `availability`, `contentTypes`,and `version`.

|\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/sources/

|===

====== Sources Operation Example

In the example below there is the local ${branding} distribution and a ${branding} OpenSearch federated source with id "${ddf-branding}-OS". 

.Sources Response Example
[source,javascript,linenums]
----
[
   {
      "id" : "${ddf-branding}-OS",
      "available" : true,
      "contentTypes" :
         [
         ],
      "version" : "2.0"
   },
   {
      "id" : "ddf.distribution",
      "available" : true,
      "contentTypes" :
         [
         ],
      "version" : "2.5.0-SNAPSHOT"
   }
] 
----

Note that for all RESTful CRUD commands only one metacard ID is supported in the URL, i.e., bulk operations are not supported.

===== Interacting with the REST CRUD Endpoint

Any web browser can be used to perform a REST read.
Various other tools and libraries can be used to perform the other HTTP operations on the REST endpoint (e.g., soapUI, cURL, etc.)

===== Metacard Transforms with the REST CRUD Endpoint

The `read` operation can be used to retrieve metadata in different formats.

. Install the appropriate feature for the desired transformer. If desired transformer is already installed such as those that come out of the box (`xml,html,etc`), then skip this step.

. Make a read request to the REST URL specifying the catalog id.

. Add a transform query parameter to the end of the URL specifying the shortname of the transformer to be used (e.g., `transform=kml`).

Example:

[source,http]
----
http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/<metacardId>?transform=<TRANSFORMER_ID>
----

[TIP]
====
Transforms also work on read operations for metacards in federated sources.
\http://<DISTRIBUTION_HOST>:<DISTRIBUTION_PORT>/services/catalog/sources/<sourceId>/<metacardId>?transform=<TRANSFORMER_ID>
====

===== Metacard Transforms Available in ${branding}

${ddf-branding} includes the following Metacard Transformers:

HTML Metacard Transformer:: transforms a Metacard into an HTML formatted document
XML Metacard Transformer:: transforms a Metacard into an XML formatted document
GeoJSON Metacard Transformer:: transforms a Metacard into GeoJSON text
Thumbnail Metacard Transformer:: retrieves the thumbnail bytes of a Metacard
Metadata Metacard Transformer:: returns the Metacard.METADATA attribute value when given a Metacard.
Resource Metacard Transformer:: retrieves the resource bytes of a Metacard product

[NOTE]
====
MetacardTransformers can be added to the system at any time.
This endpoint can make use of any registered `MetacardTransformers`.
====

====== HTML Metacard Transformer

Description::
The HTML Metacard Transformer is responsible for translating a Metacard into an HTML formatted document.

Usage::
Using the REST Endpoint, for example, request a metacard with the transform option set to the HTML shortname.

[source,http]
----
${secure_url}/services/catalog/0123456789abcdef0123456789abcdef?transform=html
----

*Installing and Uninstalling*

Install the `catalog-transformer-html` feature using the Admin console.

*Configuration*

None

*Implementation Details*

[cols="2,1,1" options="header"]
|===
|Registered Interface
|Service Property
|Value

.3+|`ddf.catalog.transform.MetacardTransformer`

|title
|View as html...

|description
|Transforms query results into html

|shortname (for backwards compatibility)
|html

|===

*Known Issues*

None

====== XML Metacard Transformer

*Description*

The XML Metacard Transformer is responsible for translating a Metacard into an XML formatted document.
The metacard element that is generated is an extension of `gml:AbstractFeatureType` which makes the output of this transformer GML 3.1.1 compatible.

*Usage*

Using the REST Endpoint for example, request a Metacard with the transform option set to the XML shortname.

[source,http]
----
${secure_url}/services/catalog/ac0c6917d5ee45bfb3c2bf8cd2ebaa67?transform=xml
----

*Installation and Uninstallation*

This transformer comes installed out of the box and is running on start up.
To uninstall or install manually, use the `catalog-transformer-xml` feature using the Admin Console.

*Configuration*

None

*Implementation Details*

.Metacard to XML Mappings
[cols="1,3" options="header"]
|===
|Metacard Variables
|XML Element

|`id`
|`metacard/${at-symbol}gml:id`

|`metacardType`
|`metacard/type`

|`sourceId`
|`metacard/source`

|all other attributes
|`metacard/<AttributeType>[name='<AttributeName>']/value`

For instance, the value for the Metacard Attribute named "`title`" would be found at:

`metacard/string[${at-symbol}name='title']/value`

|===

.AttributeTypes
[cols="1" options="header"]
|===
|XML Adapted Attributes

|boolean
|base64Binary
|dateTime
|double
|float
|geometry
|int
|long
|object
|short
|string
|stringxml
|===

*Known Issues*

None

====== GeoJSON Metacard Transformer

*Description*

The GeoJSON Metacard Transformer translates a Metacard into GeoJSON.

*Usage*

The GeoJSON Metacard Transformer can be used programmatically by requesting a `MetacardTransformer` with the id `geojson`.
It can also be used within the REST Endpoint by providing the transform option as geojson.

*Example*

.REST GET method with the GeoJSON MetacardTransformer
[source,http]
----
${secure_url}/services/catalog/0123456789abcdef0123456789abcdef?transform=geojson
----

*Installation and Uninstallation*

Install the `catalog-transformer-json` feature using the Admin Console.

*Configuration*

None

*Implementation Details*

[cols="3,2,1" options="header"]
|===

|Registered Interface
|Service Property
|Value

.3+|`ddf.catalog.transform.MetacardTransformer`
|mime-type
|application/json

|id
|geojson

|shortname (for backwards compatibility)
|geojson

|===

*Known Issues*

None.

====== Thumbnail Metacard Transformer

*Description*

The Thumbnail Metacard Transformer retrieves the thumbnail bytes of a Metacard by returning the `Metacard.THUMBNAIL` attribute value.

*Usage*

Endpoints or other components can retrieve an instance of the Thumbnail Metacard Transformer using its id thumbnail.

.Sample Blueprint Reference Snippet
[source,xml]
----
 <reference id="metacardTransformer" interface="ddf.catalog.transform.MetacardTransformer" filter="(id=thumbnail)"/>
----

The Thumbnail Metacard Transformer returns a `BinaryContent` object of the `Metacard.THUMBNAIL` bytes and a MIME Type of `image/jpeg`.

*Installation and Uninstallation*

This transformer is installed by default.
To uninstall the transformer, you must stop or uninstall the bundle.

*Configuration*

None

*Implementation Details*

[cols="2,1" options="header"]
|===
|Service Property
|Value

|id
|thumbnail

|shortname
|thumbnail

|mime-type
|image/jpeg
|===

*Known Issues*

None

====== Metadata Metacard Transformer

*Description*

The Metadata Metacard Transformer returns the `Metacard.METADATA` attribute value when given a Metacard.
The MIME Type returned is `text/xml`.

*Usage*

The Metadata Metacard Transformer can be used programmatically by requesting a `MetacardTransformer` with the id metadata.
It can also be used within the REST Endpoint by providing the transform option as metadata.

*Example*

.REST GET method with the Metadata MetacardTransformer
[source,http]
----
${secure_url}/services/catalog/0123456789abcdef0123456789abcdef?transform=metadata
----

*Installation and Uninstallation*


The Catalog Transformers App will install this feature when deployed.
This transformer's feature, `catalog-transformer-metadata`, can be uninstalled or installed.

*Configuration*

None

*Implementation Details*

[cols="3,2,1" options="header"]
|===
|Registered Interface
|Service Property
|Value

.3+|`ddf.catalog.transform.MetacardTransformer`
|mime-type
|`text/xml`

|id
|`metadata`

|shortname (for backwards compatibility)
|`metadata`

|===

*Known Issues*

None.

====== Resource Metacard Transformer

*Description*

The Resource Metacard Transformer retrieves the resource bytes of a Metacard by returning the product associated with the metacard.

*Usage*

Endpoints or other components can retrieve an instance of the Resource Metacard Transformer using its id `resource`.

.Sample Blueprint Reference Snippet
[source,xml]
----
 <reference id="metacardTransformer" interface="ddf.catalog.transform.MetacardTransformer" filter="(id=resource)"/>
----

*Installation and Uninstallation*

This transformer is installed by installing the feature associated with the transformer `catalog-transformer-resource`. To uninstall the transformer, you must uninstall the feature `catalog-transformer-resource`.

*Configuration*

None

*Implementation Details*

[cols="1,2" options="header"]
|===
|Service Property
|Value

|id
|`resource`

|shortname
|`resource`

|mime-type
|`application/octet-stream`

|title
|Get Resource ...
|===

*Known Issues*

None

===== `InputTransformers` 

The REST Endpoint uses `InputTransformers` to create Metacards from the `metacard` endpoint.
Using the REST Endpoint `create` or a `HTTP POST` operation the Catalog Framework will also use `InputTransformers` to create Metacards and associate those Metacards with the provided resource.
The REST Endpoint and Catalog Framework will dynamically find `InputTransformers` that support the mime type stated in the HTTP header of a `HTTP POST`.
`InputTransformers` register as Services with a list of Content-Type mime-types.
The REST Endpoint and Catalog Framework receive a list of `InputTransformers` that match the Content-Type and one-by-one call the `InputTransformers` until a transformer is successful and creates a Metacard.
For instance, if GeoJSON was in the body of the `HTTP POST`, then the HTTP header would need to include `application/json` in order to match the mime-type GeoJSON Input Transformer supports.
The Catalog Framework will attempt to "guess" the mime-type of a resource, if it is not provided. This functionality is provided as a best effort and it is recommended to always include the mime-type if possible.

[NOTE]
====
InputTransformers can be added to the system at any time.
====

===== Resources (Content)
The Catalog Framework can interface with Storage providers to provide storage of resources to specific types of  storage, e.g., file system, relational database, XML database.
A default file system provider is provided by default.
Storage plugins provide pluggable functionality that can be executed either immediately before or immediately after content has been stored or updated.
Storage providers act as a proxy between the Catalog Framework and the mechanism storing the content, e.g., file system, relational database.
Storage providers expose the storage mechanism to the Catalog Framework.

Storage providers provide the capability to the Catalog Framework to create, read, update, and delete content in the content repository.

.Content Data Component Architecture
[ditaa, content_data_components, png,${image.width}]
....
+------------------------------------------------------------------------------+
|                 /-=-----------------\                                        |
|                 |      Clients      |                                        |
|                 \-------------------/                                        |
|                           ^                                                  |
|                           |                                                  |
|                           v                                                  |
|                 /-------------------\                                        |
|                 |cDEF Endpoints     |                                        |
|                 +------------+------+                                        |
|                 | cDEF       | c369 |                                        |
|                 | Operations | Data |                                        |
|                 +------------+------+-----------------------\                |
|                 | cDEF              |cDEF Transformers      |                |
|                 |                   +-----------------------+                |
|                 | Catalog Framework |cDEFStorage Plugins    |                |
|                 |                   +-----------------------+                |
|                 |                   |                                        |
|                 +-------------------|                                        |
|                 |cDEF               |                                        |
|                 | Storage Provider  |                                        |
|                 \-------------------/                                        |
|                           ^                                                  |
|                           |                                                  |
|                           v                                                  |
|                   +-=-------------+                LEGEND                    |
|                   |{s}            |                /--------------------\    |
|                   |   Content     |                |cDEF${branding} Component   |    |
|                   |  Repository   |                \--------------------/    |
|                   +---------------+                /-=------------------\    |
|                                                    | External Component |    |
|                                                    \--------------------/    |
+------------------------------------------------------------------------------+
....

====== Content Item

ContentItem is the domain object populated by the Storage Provider that represents the information about the content to be stored or content that has been stored in the Storage Provider.
A ContentItem encapsulates the content's globally unique ID, mime type, and input stream (i.e., the actual content).
The unique ID of a ContentItem will always correspond to a Metacard ID.

====== Storage Plugins
The Catalog Framework calls Storage Plugins to process each request both immediately before and immediately after an item is created or updated in the content repository.

Types of Storage Plugins available out of the box:

* Video Thumbnail Plugin, which is both a PostCreateStoragePlugin and a PostUpdateStoragePlugin and is used to generate thumbnails for video files stored in the content repository.

====== Video Thumbnail Plugin

The Video Thumbnail Plugin provides the ability to generate thumbnails for video files stored in the Content Repository.

It is an implementation of both the PostCreateStoragePlugin and PostUpdateStoragePlugin interfaces. When installed, it is invoked by the Catalog Framework immediately after a content item has been created or updated by the Storage Provider.

This plugin uses a custom 32-bit LGPL build of https://ffmpeg.org/[FFmpeg] (a video processing program) to generate thumbnails. When this plugin is installed, it places the FFmpeg executable appropriate for the current operating system in `<${branding}_INSTALL_DIR>/bin_third_party/ffmpeg`. When invoked, this plugin runs the FFmpeg binary in a separate process to generate the thumbnail. The `<${branding}_INSTALL_DIR>/bin_third_party/ffmpeg` directory is deleted when the plugin is uninstalled.

NOTE: Prebuilt FFmpeg binaries are provided for Linux, Mac, and Windows only.

===== Directory Monitor

The Catalog Content Directory Monitor allows files placed in a monitored directory to be ingested into the ${ddf-catalog} Repository and/or the Metadata Catalog (MDC). 
A monitored directory is a directory configured to be polled by ${branding} periodically (typically once per second) for any new files added to the directory that should be ingested into the Catalog Framework.

The typical execution flow of the Directory Monitor is:

. A new file is detected in the monitored directory, 
. The file's contents are passed on to the Catalog Framework and processed based on whether the monitored directory's processing directive was:
.. configured to just store the file in the ${ddf-catalog} Repository,
.. configured to just process the file's metadata and ingest it into the MDC, or 
.. configured to both store the file in the Content Repository and ingest it into the MDC.
. If the response from the Catalog Framework is successful, indicating the content was stored and/or processed, the file in the monitored directory is either deleted (default behavior) or copied to a sub-directory called `.ingested` (see below for how to configure this behavior). If the response from the Catalog Framework was unsuccessful or a failure occurred, the file is moved from the monitored directory to a sub-folder named `.errors`, allowing easy identification of the ingested files that had problems.

Multiple monitored directories can be configured, each monitoring different directories.

====== Using

The Content Directory Monitor provides the capability to easily create content in the ${ddf-catalog} Repository and metacards in the MDC by simply placing a file in a directory that has been configured to be monitored by ${branding}.
For example, this would be useful for copying files from a hard drive (or directory) in a batch-like operation to the monitored directory and having all of the files processed by the Catalog Framework.

====== Sample Usage Scenarios

====== Scenario 1: Monitor single directory for storage and processing, with no file backup

* The Content Directory Monitor has the following configurations.
** The *relative* path of `inbox` for the directory path.
** The Processing Directive is set to Store and Process.
** The *Copy Ingested Files* option is not checked.
* As files are placed in the monitored directory `<${branding}_INSTALL_DIR>/inbox`, the files are ingested into the Catalog Framework.
** The Catalog Framework generates a GUID for the create request for this ingested file.
** Since the Store and Process directive was configured the ingested file is passed on to the Content File System Storage Provider, which creates a sub-directory in the Content Repository using the GUID and places the ingested file into this GUID sub-directory using the file name provided in the request.
** The Catalog Framework then invokes the Catalog Content Plugin, which looks up the Input Transformer associated with the ingested file's mime type and invokes the Catalog Framework, which inserts the metacard into the MDC. This Input Transformer creates a metacard based on the contents of the ingested file.
** The Catalog Framework sends back a successful status to the Camel route that was monitoring the directory.
** Camel route completes and deletes the file from the monitored directory.

====== Scenario 2: Monitor single directory for storage with file backup

* The Content Directory Monitor has the following configurations.
** The *absolute* path of `/usr/my/home/dir/inbox` for the directory path. 
** The Processing Directive is set to store only. 
** The *Copy Ingested Files* option is checked.
* As files are placed in the monitored directory `/usr/my/home/dir/inbox`, the files are ingested into the Catalog Framework.
** The Catalog Framework generates a GUID for the create request for this ingested file.
** Since the Store directive was configured, the ingested file is passed on to the Content File System Storage Provider, which creates a sub-directory in the Content Repository using the GUID and places the ingested file into this GUID sub-directory using the file name provided in the request.
** The Catalog Framework sends back a successful status to the Camel route that was monitoring the directory.
** The Camel route completes and moves the file from the monitored directory to its sub-directory `/usr/my/home/dir/inbox/.ingested`.

====== Scenario 3: Monitor multiple directories for processing only with file backup - errors encountered on some ingests

* Two different Content Directory Monitors have the following configurations.
** The *relative* path of `inbox` and `inbox2` for the directory path. 
** The Processing Directive on both directory monitors is set to Process.
** The Copy Ingested Files option is checked for both directory monitors.
* As files are placed in the monitored directory `<${branding}_INSTALL_DIR>/inbox`, the files are ingested into the Catalog Framework.
** The Catalog Framework generates a GUID for the create request for this ingested file.
** Since the Process directive was configured, the ingested file is passed on to the Catalog Content Plugin, which looks up the Input Transformer associated with the ingested file's mime type (but no Input Transformer is found) and an exception is thrown.
** The Catalog Framework sends back a failure status to the Camel route that was monitoring the directory.
** The Camel route completes and moves the file from the monitored directory to the `.errors` sub-directory.
* As files are placed in the monitored directory `<${branding}_INSTALL_DIR>/inbox2`, the files are ingested into the Catalog Framework.
** The Catalog Framework generates a GUID for the create request for this ingested file.
** The Catalog Framework then invokes the Catalog Content Plugin, which looks up the Input Transformer associated with the ingested file's mime type and invokes the Catalog Framework, which inserts the metacard into the MDC. This Input Transformer creates a metacard based on the contents of the ingested file.
** The Catalog Framework sends back a successful status to the Camel route that was monitoring the directory.
** The Camel route completes and moves the file from the monitored directory to its `.ingested` sub-directory.

====== Configuring

The configurable properties for the Content Directory Monitor are accessed from the *Content Directory Monitor* Configuration in the Admin Console.

====== Configuring Content Directory Monitors

Managed Service Factory PID:
`org.codice.ddf.catalog.content.monitor.ContentDirectoryMonitor`

====== Configurable Properties

[cols="1,1,1,4a,1,1," options="header"]
|===

|Title
|Property
|Type
|Description
|Default Value
|Required

|Directory Path
|`monitoredDirectoryPath`
|String
|Specifies the directory to be monitored.
Can be a fully-qualified directory or a relative path (which is relative to the ${branding} installation directory).
|N/A
|Yes

|Processing Directive
|`directive`
|String
|One of three possible values from a drop down box:

* Store only - indicates to only store content in Content Repository
* Process only - indicates to only create metacard and insert into MDC
* Store and Process - do both
|Store and Process
|Yes

|Copy Files to Backup Directory
|`copyIngestedFiles`
|Boolean
|Checking this option indicates that a backup of the file placed in the monitored directory should be made upon successful processing of the file. The file is moved into the `.ingested` sub-directory of the monitored directory.
|False
|No

|===

===== Implementation Details

====== Imported Services

[cols="3*", options="header"]
|===

|Registered Interface
|Availability
|Multiple

|`ddf.mime.MimeTypeToTransformerMapper`
|required
|false

|`ddf.catalog.CatalogFramework`
|required
|false

|`ddf.catalog.filter.FilterBuilder`
|required
|false

|===

====== Exported Services

[cols="3*", options="header"]
|===

|Registered Interface
|Service Property
|Value

|ddf.action.ActionProvider
|id
|catalog.data.metacard.view

|===

===== Known

None.

==== OpenSearch Endpoint

The OpenSearch Endpoint provides a CDR REST Search v3.0 and CDR REST Brokered Search 1.1 compliant ${branding} endpoint that a client accesses to send query parameters and receive search results.

This endpoint uses the input query parameters to create an OpenSearch query.
The client does not need to specify all of the query parameters, only the query parameters of interest.

This endpoint is a `JAX-RS` RESTful service and is compliant with the CDR IPT BrokeredSearch, CDR IPT OpenSearch, and OpenSearch specifications.

===== Installing and Uninstalling

The OpenSearch Endpoint can be installed and uninstalled using the normal processes described in the  Configuring ${branding} section.

===== Configuring

The OpenSearch Endpoint has no configurable properties.
It can only be installed or uninstalled.

===== Using the OpenSearch Endpoint

Once installed, the OpenSearch endpoint is accessible from `http://<${ddf-branding}_HOST>:<${ddf-branding}_PORT>/services/catalog/query`.

====== Using the endpoint

====== From Code:

The OpenSearch specification defines a file format to describe an OpenSearch endpoint.
This file is XML-based and is used to programatically retrieve a site's endpoint, as well as the different parameter options a site holds.
The parameters are defined via the OpenSearch and CDR IPT Specifications.

====== From a Web Browser:

Many modern web browsers currently act as OpenSearch clients.
The request call is an HTTP GET with the query options being parameters that are passed.

.Example of an OpenSearch request:
----
http://<ddf_host>:8181/services/catalog/query?q=Predator
----

This request performs a full-text search for the phrase 'Predator' on the ${branding} providers and provides the results as Atom-formatted XML for the web browser to render.

===== Parameter List

====== Main OpenSearch Standard

[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`searchTerms`
|`q`
|URL-encoded string
|Complex contextual search string.

|`count`
|`count`
|integer >= 0
|Maximum # of results to retrieve

default: 10

|`startIndex`
|`start`
|integer >= 1
|Index of first result to return.

default: 1

This value uses a one based index for the results.

|`format`
|`format`
|requires a transformer shortname as a string, possible values include, when available

	`atom`

	`html`

	`kml`

see Included Query Response Transformers for more possible values.
|default: `atom`
|===

====== Temporal Extension

[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`start`
|`dtstart`
|RFC-3399-defined value
|`yyyy-MM-dd'T'HH:mm:ss.SSSZZ`

|`end`
|`dtend`
|RFC-3399-defined value
|`yyyy-MM-dd'T'HH:mm:ss.SSSZZ`
|===

[NOTE]
====
The start and end temporal criteria must be of the format specified above. Other formats are currently not supported. Example:

`2011-01-01T12:00:00.111-04:00`.

*The start and end temporal elements are based on modified timestamps for a metacard.*
====

====== Geospatial Extension

These geospatial query parameters are used to create a geospatial `INTERSECTS` query, where `INTERSECTS` = geometries that are not `DISJOINT` of the given geospatial parameter. 

[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`lat`
|`lat`
|`EPSG:4326` decimal degrees
|Expects a latitude and a radius to be specified.

|`lon`
|`lon`
|`EPSG:4326` decimal degrees
|Expects a longitude and a radius to be specified.

|`radius`
|`radius`
|Meters along the Earth's surface > 0
|Used in conjunction with lat and lon query parameters.

|`polygon`
|`polygon`
|clockwise `lat lon` pairs ending at the first one
|example: `-80, -170, 0, -170, 80, -170, 80, 170, 0, 170, -80, 170, -80, -170`

According to the OpenSearch Geo Specification this is *deprecated*. 
Use geometry instead.

|`box`
|`bbox`
|4 comma-separated `EPSG:4326` decimal degrees
|west, south, east, north

|`geometry`
|`geometry` 
|WKT Geometries: `POINT`, `POLYGON`, `MULTIPOINT`, `MULTIPOLYGON`
|Examples:

`POINT(10 20)` where 10 is the longitude and 20 is the latitude.

`POLYGON ( ( 30 10, 10 20, 20 40, 40 40, 30 10 ) )`. 30 is longitude and 10 is latitude for the first point.
Make sure to repeat the starting point as the last point to close the polygon.

|===

.Extensions
[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`sort`
|`sort`
|`sbfield`: 'date' or 'relevance'
`sborder`: 'asc' or 'desc'
|`sort=<sbfield>:<sborder>` default: `relevance:desc`

Sorting by date will sort the effective date.

|`maxResults`
|`mr`
|Integer >= 0
|Maximum # of results to return.

If count is also specified, the count value will take precedence over the `maxResults` value

|`maxTimeout`
|`mt`
|Integer > 0
|Maximum timeout (milliseconds) for query to respond

default: 300000 (5 minutes)
|===

.Federated Search
[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`routeTo`
|`src`
|(varies depending on the names of the sites in the federation)
|comma delimited list of site names to query.

Also can specify `src=local` to query the local site.

If src is not provided, the default behavior is to execute an enterprise search to the entire federation.

|===

====== ${branding} Extensions

[cols="4*", options="header"]
|===
|OS Element
|HTTP Parameter
|Possible Values
|Comments

|`dateOffset`
|`dtoffset`
|integer > 0
|Specifies an offset, backwards from the current time, to search on the modified time field for entries. Defined in milliseconds.

|`type`
|`type`
|nitf
|Specifies the type of data to search for.

|`version`
|`version`
|20,30
|Comma-delimited list of version values to search for.

|`selector`
|`selector`
|`//namespace:example`,`//example`
|Comma-delimited list of XPath string selectors that narrow down the search.

|===

====== Supported Complex Contextual Query Format

The OpenSearch Endpoint supports the following operators: `AND`, `OR`, and `NOT`.
These operators are case sensitive.
Implicit `ANDs` are also supported.

Using parentheses to change the order of operations is supported.
Using quotes to group keywords into literal expressions is supported.

The following `EBNF` describes the grammar used for the contextual query format.

.OpenSearch Complex Contextual Query `EBNF`
----
keyword query expression = optional whitespace, term, {boolean operator, term}, optional
whitespace;
boolean operator = or | not | and;
and = (optional whitespace, "AND", optional whitespace) | mandatory whitespace;
or = (optional whitespace, "OR", optional whitespace);
not = (optional whitespace, "NOT", optional whitespace);
term = group | phrase | keyword;
phrase = optional whitespace, '"', optional whitespace, keyword, { optional whitespace,
keyword}, optional whitespace, '"';
group = optional whitespace, '(', optional whitespace, keyword query expression,
optional whitespace, ')';
optional whitespace = {' '};
mandatory whitespace = ' ', optional whitespace;
valid character = ? any printable character ? - ('"' | '(' | ')' | " ");
keyword = valid character, {valid character};
OpenSearch Description Document
----

The OpenSearch Description Document is an XML file is found inside of the OpenSearch Endpoint bundle and is named `ddf-os.xml`.

===== Implementation Details

====== Imported Services

[cols="3*", options="header"]
|===
|Registered Interface
|Availability
|Multiple

|`ddf.catalog.CatalogFramework`
|required
|false

|`ddf.catalog.filter.FilterBuilder`
|required
|false

|===
====== Exported Services

None.

====== Known Issues

None

==== FTP Endpoint

The FTP Endpoint provides a method for ingesting files directly into the ${branding} Catalog using the FTP protocol. The files sent over FTP are not first written to the file system, like the Directory Monitor, but instead the FTP stream of the file is ingested directly into the ${branding} catalog, thus avoiding extra I/O overhead.

===== Installing and Uninstalling

Use the Admin Menu to install the FTP feature in the ${branding} Catalog. The FTP Endpoint is not installed by default.

===== Configuring

The configurable properties for the FTP Endpoint are accessed from the *FTP Endpoint* Configuration in the Admin Console under the DDF Catalog application.

===== Using the FTP Endpoint

====== Using the endpoint

The FTP endpoint supports the PUT and MPUT operations. Any other operation, such as DELETE, will return a 550 action not taken response.

====== From Code:

Custom Ftplets can be implemented by extending the `DefaultFtplet` class provided by Apache FTP Server. Doing this will allow custom handling of various FTP commands by overriding the methods of the `DefaultFtplet`. Refer to `https://mina.apache.org/ftpserver-project/ftplet.html` for available methods that can be overridden.
After creating a custom Ftplet, it needs to be added to the FTP server’s Ftplets before the server is started. Any Ftplets that are registered to the FTP server will execute the FTP command in the order that they were registered.

====== From an FTP client:

The FTP endpoint can be accessed from any FTP client of choice. Some common clients are FileZilla, PuTTY, or the FTP client provided in the terminal. The default port number is *8021*. Valid usernames and password are stored in the `<INSTALL_DIR>/etc/users.properties` file.

===== Implementation Details

The FTP endpoint is implemented using the Apache FTP Server and Apache Mina. Apache Mina provides an API for transport protocols such as TCP and UDP. The FTP server is built on top of Apache Mina to transport its messages. ${branding} implements a custom Ftplet by overriding the `DefaultFtplet` class provided by Apache FTP Server.

====== Known Issues

None

==== Resource Download Endpoint

The Resource Download Endpoint provides a REST API to trigger downloading resources to the ${branding} cache only. The resource is not returned to the client.

===== Configuring

The Resource Download Endpoint has no configurable properties.

===== Using the Resource Download Endpoint

====== Using the endpoint

The Resource Download Endpoint WADL is accessible from `http://<${ddf-branding}_HOST>:<${ddf-branding}_PORT>/services/catalog/downloads?_wadl`.

[NOTE]
====
If resource caching is not enabled in ${ddf-branding}, the endpoint will return a `400 BAD REQUEST` response.
====

[cols="2,1,3,4", options="header"]
|===
|Operation
|HTTP Request
|Details
|Example URL

|`cache only`
|HTTP GET
|Resource caching must be enabled
|\http://<${ddf-branding}_HOST>:<${ddf-branding}_PORT>/services/catalog/downloads/<sourceId>/<metacardId>

|===
====== Known Issues

None

=== Developing a New Endpoint

Complete the following procedure to create an endpoint. 

. Create a Java class that implements the endpoint's business logic. Example: Creating a web service that external clients can invoke.

. Add the endpoint's business logic, invoking `CatalogFramework` calls as needed.  

. Import the ${branding} packages to the bundle's manifest for run-time (in addition to any other required packages): +
`Import-Package: ddf.catalog, ddf.catalog.*`

. Retrieve an instance of `CatalogFramework` from the OSGi registry. (Refer to the Working with OSGi - Service Registry section for examples.)

Deploy the packaged service to ${branding}.
(Refer to the Working with OSGi - Bundles section.)

[NOTE]
====
It is recommended to use the maven bundle plugin to create the Endpoint bundle's manifest as opposed to directly editing the manifest file.
====

[TIP]
====
*No implementation of an interface is required* +
Unlike other ${branding} components that require you to implement a standard interface, no implementation of an interface is required in order to create an endpoint.
====

==== Common Endpoint Business Logic

[cols="2*", options="header"]
|===
|Methods
|Use

|`Ingest`
|Add, modify, and remove metadata using the ingest-related `CatalogFramework` methods: 

create, update, and delete. 

|`Query`
|Request metadata using the `query` method.

|`Source`
|Get available `Source` information.

|`Resource`
|Retrieve products referenced in Metacards from Sources.

|`Transform`
|Convert common Catalog Framework data types to and from other data formats.

|===
// end move
=== ${branding} Data Migration

Data migration is the process of moving metadata from one catalog provider to another.
It is also the process of translating metadata from one format to another. 
Data migration is necessary when a user decides to use metadata from one catalog provider in another catalog provider.
The following steps define the procedure for transferring metadata from one catalog provider to another catalog provider.
In addition, the procedures define the steps for converting metadata to different data formats.

==== Set Up

Set up ${branding} as instructed in Starting ${branding} section.

==== Move Metadata from One Catalog Provider to Another

===== Export Metadata Out of Catalog Provider

. Configure a desired catalog provider.
. From the command line of ${branding} console, use the command to export all metadata from the catalog provider into serialized data files dump. The following example shows a command for running on Linux and a command for running on Windows.

.${branding-lowercase}${at-symbol}local
----
dump "/myDirectory/exportFolder"
or
dump "C:/myDirectory/exportFolder"
----

===== Ingest Exported Metadata into Catalog Provider

. Configure a different catalog provider.

. From the command line of ${branding} console, use the *ingest* command to import exported metadata from serialized data files into catalog provider. The following example shows a command for running on Linux and a command for running on Windows.

.${branding-lowercase}${at-symbol}local
----
ingest -p "/myDirectory/exportFolder"
or
ingest -p "C:/myDirectory/exportFolder"
----

===== Translate Metadata from One Format to Another

Metadata can be converted from one data format to another format. 
Only the data format changes, but the content of the metadata does not, as long as `option -p` is used with the ingest command.
The process for converting metadata is performed by ingesting a data file into a catalog provider in one format and dumping it out into a file in another format. 


=== Integrating Catalog Framework

[ditaa, catalog_framework_architecture, png, ${image-width}]
....
+------------------------------------------------------------+
|                /-------------------\                       |
|                |cDEFEndpoints      |                       |
|                +------------+------+                       |
|                |cDEF        |cDEF  |                       |
|                | Operations | Data |                       |
|/---------------+------------+------+------------+---------\|
||cDEF           |c369               |cDEF        |cDEF     ||
||  Transformers |                   | Federation | Sources ||
|+---------------+ Catalog Framework +------------+---------+|
||cDEF           |                   |cDEF   Eventing       ||
||   Catalog     |                   +------------+---------+|
||   Plugins     |                   |cDEF   Resources      ||
|\---------------+-------------------+----------------------/|
|                |cDEF               |                       |
|                | Catalog Provider  |                       |
|                \-------------------/                       |
+------------------------------------------------------------+
....

==== Catalog Framework

The Catalog Framework wires all Catalog components together.
It is responsible for routing Catalog requests and responses to the appropriate target.
Endpoints send Catalog requests to the Catalog Framework.
The Catalog Framework then invokes Catalog Plugins, Transformers, and Resource Components as needed before sending requests to the intended destination, such as one or more Sources. 

===== Example Catalog Frameworks

The Catalog comes with the following Catalog Frameworks out of the box:

* Catalog Framework
* Catalog Fanout Framework

===== Catalog Framework Sequence Diagrams

Because the Catalog Framework plays a central role to Catalog functionality, it interacts with many different Catalog components.
To illustrate these relationships, high level sequence diagrams with notional class names are provided below.
These examples are for illustrative purposes only and do not necessarily represent every step in each procedure.

===== Ingest

.Ingest Request
[ditaa,ingest_request,png]
....
+------+      +--------------------------------------------------------------------------------------------------------------------+
| cDEF |      |/-----------------------\/--------------------------\/---------------\/----------------\/--------------------------\|/--------------------\
|Client|      ||c369  <<Endpoint>>     ||c369<<CatalogFramework>>  ||c369           ||c369            ||c369<<CatalogProvider>>   |||c369<<External>>    |
+------+      ||Ingest Service Endpoint||Standard Catalog Framework||PreIngestPlugin||PostIngestPlugin||  Solr Catalog Provider   ||| Solr Search Server |
  :           |\-----------------------/\--------------------------/\---------------/\----------------/\--------------------------/|\--------------------/
  |Web Service|Ingest Request :                       :                       :               :                     :              |           :
  |-----------|-------------->|                       |                       |               |                     |              |           |
  |           |               |create(CreateRequest)  |                       |               |                     |              |           |
  |           |               |---------------------->|process(CreateRequest) |               |                     |              |           |
  |           |               |                       |---------------------->|               |                     |              |           |
  |           |               |                       |   CreateRequest       |               |                     |              |           |
  |           |               |                       |<----------------------|               |                     |              |           |
  |           |    cDEF       |                       |create(CreateRequest)  |               |                     |              |           |
  |           |               |                       |------------------------------------------------------------>|create        |           |
  |           |               |                       |                       :               :                     |--------------|---------->|
  |           |               |                       |                       |               |                     |              |          response
  |           |               |                       |                       |               |       CreateResponse|<-------------|-----------|
  |           |               |                       |<------------------------------------------------------------|              |           |
  |           |               |                       |process(CreateResponse):               :                     |              |           |
  |           |               |                       |-----------------------|-------------->|                     |              |           |
  |           |               |                       |                       | CreateResponse|                     |              |           |
  |           |               |         CreateResponse|<--------------------------------------|                     |              |           |
  |Web Service|Ingest Response|<----------------------|                       :               |                     |              |           |
  |<----------|---------------|                       |                       |               |                     |              |           |
  |           |               |                       |                       |               |                     |              |           |
  |           +--------------------------------------------------------------------------------------------------------------------+           |
  |                                                                                                                                            |
....

The Ingest Service Endpoint, the Catalog Framework, and the Catalog Provider are key components of the Reference Implementation.
The Endpoint bundle implements a Web service that allows clients to create, update, and delete metacards.
The Endpoint calls the `CatalogFramework` to execute the operations of its specification.
The `CatalogFramework` routes the request through optional `PreIngest` and `PostIngest` Catalog Plugins, which may modify the ingest request/response before/after the Catalog Provider executes the ingest request and provides the response. 
Note that a `CatalogProvider` must be present for any ingest requests to be successfully processed, otherwise a fault is returned.

This process is similar for updating catalog entries, with update requests calling the `update(UpdateRequest)` methods on the Endpoint, `CatalogFramework`, and Catalog Provider.
Similarly, for deletion of catalog entries, the delete requests call the `delete(DeleteRequest)` methods on the `Endpoint`, `CatalogFramework`, and `CatalogProvider`.

===== Error Handling

Any ingest attempts that fail inside the Catalog Framework (whether the failure comes from the Catalog Framework itself, pre-ingest plugin failures, or issues with the Catalog Provider) will be logged to a separate log file for ease of error handling.
The file is located at `data/log/ingest_error.log` and will log the Metacards that fail, their ID and Title name, and the stack trace associated with their failure.
By default, successful ingest attempts are not logged.
However, that functionality can be achieved by setting the log level of the `ingestLogger` to DEBUG (note that enabling DEBUG can cause a non-trivial performance hit).

[TIP]
====
To turn off logging failed ingest attempts into a separate file, execute the following
via the command line console
----
log:set
 ERROR ingestLogger
----
====

===== Query

.Ingest Request
[ditaa,query_request,png]
....
+------+      +--------------------------------------------------------------------------------------------------------------------+
|      |      |/-----------------------\/--------------------------\/---------------\/----------------\/--------------------------\|/--------------------\
|Client|      ||c369  <<Endpoint>>     ||c369<<CatalogFramework>>  ||c369           ||c369            ||c369<<CatalogProvider>>   |||c369<<External>>    |
+------+      || Query Service Endpoint||Standard Catalog Framework||PreQueryPlugin ||PostQueryPlugin ||  Solr Catalog Provider   ||| Solr Search Server |
  :           |\-----------------------/\--------------------------/\---------------/\----------------/\--------------------------/|\--------------------/
  |Web Service|Query Request  :                       :                       :               :                     :              |         :
  |-----------|-------------->|                       |                       |               |                     |              |         |
  |           |cDEF           |query(QueryRequest)    |                       |               |                     |              |         |
  |           |               |---------------------->|process(QueryRequest)  |               |                     |              |         |
  |           |               |                       |---------------------->|               |                     |              |         |
  |           |               |                       |    QueryRequest       |               |                     |              |         |
  |           |               |                       |<----------------------|               |                     |              |         |
  |           |               |                       |create(QueryRequest)   |               |                     |              |         |
  |           |               |                       |------------------------------------------------------------>|query         |         |
  |           |               |                       |                       :               |                     |--------------|-------->|
  |           |               |                       |                       |               |                     |                     response     |
  |           |               |                       |                       |               |        QueryResponse|<-------------|---------|
  |           |               |                       |<------------------------------------------------------------|              |         |
  |           |               |                       | process(QueryResponse)|               |                     |              |         |
  |           |               |                       |-----------------------:-------------->|                     |              |         |
  |           |               |                       |                       | QueryResponse |                     |              |         |
  |           |               |          QueryResponse|<--------------------------------------|                     |              |         |
  | Web Service Query Response|<----------------------|                       :               |                     |              |         |
  |<----------|---------------|                       |                       |               |                     |              |         |
  |           |               |                       |                       |               |                     |              |         |
  |           +--------------------------------------------------------------------------------------------------------------------+         |
....

The Query Service Endpoint, the Catalog Framework, and the `CatalogProvider` are key components for processing a query request as well.
The Endpoint bundle contains a Web service that exposes the interface to query for `Metacards`.
The Endpoint calls the `CatalogFramework` to execute the operations of its specification.
The `CatalogFramework` relies on the `CatalogProvider` to execute the actual query.
Optional PreQuery and PostQuery Catalog Plugins may be invoked by the `CatalogFramework` to modify the query request/response prior to the Catalog Provider processing the query request and providing the query response.
If a `CatalogProvider` is not configured and no other remote Sources are configured, a fault will be returned.
It is possible to have only remote Sources configured and no local `CatalogProvider` configured and be able to execute queries to specific remote Sources by specifying the site name(s) in the query request.

==== Product Retrieval

The Query Service Endpoint, the Catalog Framework, and the `CatalogProvider` are key components for processing a retrieve product request.
The Endpoint bundle contains a Web service that exposes the interface to retrieve products, also referred to as Resources.
The Endpoint calls the `CatalogFramework` to execute the operations of its specification.
The `CatalogFramework` relies on the Sources to execute the actual product retrieval.
Optional `PreResource` and `PostResource` Catalog Plugins may be invoked by the `CatalogFramework` to modify the product retrieval request/response prior to the Catalog Provider processing the request and providing the response. 
It is possible to retrieve products from specific remote Sources by specifying the site name(s) in the request.

===== Product Caching

The Catalog Framework optionally provides caching of products, so future requests to retrieve the same product will be serviced much quicker.
If caching is enabled, each time a retrieve product request is received, the Catalog Framework will look in its cache (default location `<INSTALL_DIR>/data/product-cache`) to see if the product has been cached locally.
If it has, the product is retrieved from the local site and returned to the client, providing a much quicker turnaround because remote product retrieval and network traffic was avoided.
If the requested product is not in the cache, the product is retrieved from the Source (local or remote) and cached locally while returning the product to the client.
The caching to a local file of the product and the streaming of the product to the client are done simultaneously so that the client does not have to wait for the caching to complete before receiving the product.
If errors are detected during the caching, caching of the product will be abandoned, and the product will be returned to the client. 

The Catalog Framework attempts to detect any network problems during the product retrieval, e.g., long pauses where no bytes are read implying a network connection was dropped.
(The amount of time defined as a "long pause" is configurable, with the default value being five seconds.)
The Catalog Framework will attempt to retrieve the product up to a configurable number of times (default = three), waiting for a configurable amount of time (default = 10 seconds) between each attempt, trying to successfully retrieve the product.
If the Catalog Framework is unable to retrieve the product, an error message is returned to the client.

If the admin has enabled the *Always Cache When Canceled* option, caching of the product will occur even if the client cancels the product retrieval so that future requests will be serviced quickly.
Otherwise, caching is canceled if the user cancels the product download.

===== Product Download Status

As part of the caching of products, the Catalog Framework also posts events to the OSGi notification framework. Information includes when the product download started, whether the download is retrying or failed (after the number of retrieval attempts configured for product caching has been exhausted), and when the download completes. These events are retrieved by the Search UI and presented to the user who initiated the download.

=== ${branding} Schematron

Custom schematron rulesets can be used to validate metacard metadata.
Multiple services can be created, and each service can have multiple rule sets associated with it.
Namespaces are used to distinguish services.
The root schematron files may be placed anywhere on the file system as long as they are configured with an absolute path.
Any root schematron files with a relative path are assumed to be relative to `${ddf-branding}_HOME/schematron`.

[TIP]
====
Schematron files may reference other schematron files using an include statement with a relative path.
However, when using the document function within a schematron ruleset to reference another file, the path must be absolute or relative to the ${ddf-branding} installation home directory.
====

==== Configuring

Schematron validation services are configured with a namespace and one or more schematron rule sets.
Additionally, warnings may be suppressed so that only errors are reported.
To create a new service, ensure that catalog-schematron-plugin is started and then click Schematron Validation Services.

=== Adding New Attribute Types, Metacard Types, and Validators Using JSON Files

[WARNING]
====
This section concerns capabilities that are considered experimental. The features described in this section may change or be removed in a future version of the application.
====

==== Definition File Format

Metacard types, attribute types, global attribute validators, and default attribute values can be defined within a definition file. A definition file follows the JSON format as specified in ECMA-404. All definition files must be valid JSON in order to be parsed. There are four main types that can be defined in a definition file.

- Metacard Types
- Attribute Types
- Global Attribute Validators
- Default Attribute Values

Within a definition file you may define as many of the four types as you wish. This means that types can be defined across multiple files for grouping or clarity. 

==== Deploying
The file must have a `.json` extension in order to be picked up by the deployer. Once the definition file is ready to be deployed, put the definition file `<filename>.json` into the `etc/definitions` folder.

* * *
==== Attribute Type Definition

To define Attribute Types, your definition file must have an `attributeTypes` key in the root object.

[source,json]
----
{
    "attributeTypes": {...}
}
----

The value of `attributeTypes` must be a map where each key is the attribute type's name and each value is a map that includes the data type and whether the attribute type is stored, indexed, tokenized, or multi-valued.

[source,json]
----
{
    "attributeTypes": {
        "temperature": {
            "type": "DOUBLE_TYPE",
            "stored": true,
            "indexed": true,
            "tokenized": false,
            "multivalued": false
        }
    }
}
----

The attributes `stored`, `indexed`, `tokenized`, and `multivalued` must be included and must have a boolean value. The `type` attribute must also be included and must have one of the following values:

 - `DATE_TYPE`
 - `STRING_TYPE`
 - `XML_TYPE`
 - `LONG_TYPE`
 - `BINARY_TYPE`
 - `GEO_TYPE`
 - `BOOLEAN_TYPE`
 - `DOUBLE_TYPE`
 - `FLOAT_TYPE`
 - `INTEGER_TYPE`
 - `OBJECT_TYPE`
 - `SHORT_TYPE`

An example with multiple attributes defined:

[source,json]
----
{
    "attributeTypes": {
        "resolution": {
            "type": "STRING_TYPE",
            "stored": true,
            "indexed": true,
            "tokenized": false,
            "multivalued": false
        },
        "target-areas": {
            "type": "GEO_TYPE",
            "stored": true,
            "indexed": true,
            "tokenized": false,
            "multivalued": true
        }
    }
}
----

* * *

==== Metacard Type Definition

To define Metacard Types, your definition file must have a `metacardTypes` key in the root object.

[source,javascript]
----
{
    "metacardTypes": [...]
}
----

The value of `metacardTypes` must be an array of Metacard Type Objects, which are composed of the `type` and `attributes` keys.

[source,json]
----
{
    "metacardTypes": [
        {
            "type": "my-metacard-type",
            "attributes": {...}
        }
    ]
}
----

The value of the `type` key is the name of the metacard type being defined.

The value of the `attributes` key is a map where each key is the name of an attribute type to include in this metacard type and each value is a map with a single key named `required` and a boolean value. Required attributes are used for metacard validation - metacards that lack required attributes will be flagged with validation errors.


[source,json]
----
{
    "metacardTypes": [
        {
            "type": "my-metacard-type",
            "attributes": {
                "resolution": {
                    "required": true
                },
                "target-areas": {
                    "required": false
                },
                "expiration": {
                    "required": false
                },
                "point-of-contact": {
                    "required": true
                }
            }
        }
    ]
}
----

[NOTE]
====
The DDF basic metacard attribute types are added to custom metacard types by default. If you wish to make any of them required by your metacard type, just include them in your `attributes` map and set `required` to `true`, as shown in the above example with `point-of-contact`.
====

You can define multiple metacard types in a single file:
[source,json]
----
{
    "metacardTypes": [
        {
            "type": "my-metacard-type",
            "attributes": {
                "resolution": {
                    "required": true
                },
                "target-areas": {
                    "required": false
                }
            }
        },
        {
            "type": "another-metacard-type",
            "attributes": {
                "effective": {
                    "required": true
                },
                "resolution": {
                    "required": false
                }
            }
        }
    ]
}
----

==== Validator Definition

To define Validators, your definition file must have a `validators` key in the root object.

[source,json]
----
{
    "validators": {...}
}
----

The value of `validators` is a map of the attribute name to a list of validators for that attribute.

[source,json]
----
{
    "validators": {
        "point-of-contact": [...]
    }
}
----

Each object in the list of validators is the validator name and list of arguments for that validator.

[source,json]
----
{
    "validators": {
        "point-of-contact": [
            {
                "validator": "pattern",
                "arguments": [".*regex.+\\s"]
            }
        ]
    }
}
----

[WARNING]
====
The value of the `arguments` key must always be an array of strings, even for numeric arguments, e.g. `["1", "10"]`
====

The `validator` key must have a value of one of the following:

 - `size` (validates the size of Strings, Arrays, Collections, and Maps)
 * `arguments`: (2) [integer: lower bound (inclusive), integer: upper bound (inclusive)]
 - `pattern`
 * `arguments`: (1) [regular expression]
 - `pastdate`
 * `arguments`: (0) [NO ARGUMENTS]
 - `futuredate`
 * `arguments`: (0) [NO ARGUMENTS]
 - `range`
 ** (2) [number (decimal or integer): inclusive lower bound, number (decimal or integer): inclusive upper bound]
 *** uses a default epsilon of 1E-6 on either side of the range to account for floating point representation inaccuracies
 ** (3) [number (decimal or integer): inclusive lower bound, number (decimal or integer): inclusive upper bound, decimal number: epsilon (the maximum tolerable error on either side of the range)]
 - `enumeration`
 * `arguments`: (unlimited) [list of strings: each argument is one case-sensitive, valid enumeration value]

Examples:
[source, json]
----
{
    "validators": {
        "title": [
            {
                "validator": "size",
                "arguments": ["1", "50"]
            },
            {
                "validator": "pattern",
                "arguments": ["\\D+"]
            }
        ],
        "created": [
            {
                "validator": "pastdate",
                "arguments": []
            }
        ],
        "expiration": [
            {
                "validator": "futuredate",
                "arguments": []
            }
        ],
        "page-count": [
            {
                "validator": "range",
                "arguments": ["1", "500"]
            }
        ],
        "temperature": [
            {
                "validator": "range",
                "arguments": ["12.2", "19.8", "0.01"]
            }
        ],
        "resolution": [
            {
                "validator": "enumeration",
                "arguments": ["1080p", "1080i", "720p"]
            }
        ]
    }
}
----

==== Default Attribute Values

To define default attribute values, your definition file must have a `defaults` key in the root object.

[source,json]
----
{
    "defaults": [...]
}
----

The value of `defaults` is a list of objects where each object contains the keys `attribute`, `value`, and optionally `metacardTypes`.

[source,json]
----
{
    "defaults": [
        {
            "attribute": ...,
            "value": ...,
            "metacardTypes": [...]
        }
    ]
}
----

The value corresponding to the `attribute` key is the name of the attribute to which the default value will be applied. The value corresponding to the `value` key is the default value of the attribute.

[NOTE]
====
The attribute's default value must be of the same type as the attribute, but it has to be written as a string (i.e., enclosed in quotation marks) in the JSON file.

Dates must be UTC datetimes in the ISO 8601 format, i.e., `yyyy-MM-ddTHH:mm:ssZ`
====

The `metacardTypes` key is optional. If it is left out, then the default attribute value will be applied to every metacard that has that attribute. It can be thought of as a 'global' default value. If the `metacardTypes` key is included, then its value must be a list of strings where each string is the name of a metacard type. In this case, the default attribute value will be applied only to metacards that match one of the types given in the list.

[NOTE]
====
In the event that an attribute has a 'global' default value as well as a default value for a specific metacard type, the default value for the specific metacard type will be applied (i.e., the more specific default value wins).
====

Example:
[source,json]
----
{
    "defaults": [
        {
            "attribute": "title",
            "value": "Default Title"
        },
        {
            "attribute": "description",
            "value": "Default video description",
            "metacardTypes": ["video"]
        },
        {
            "attribute": "expiration",
            "value": "2020-05-06T12:00:00Z",
            "metacardTypes": ["video", "nitf"]
        },
        {
            "attribute": "frame-rate",
            "value": "30"
        }
    ]
}
----
