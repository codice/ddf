////
Running Section
////

=== Running ${branding}

Follow the below steps to start and stop ${branding}.

==== Starting ${branding}

===== *NIX

Run the following script from a command shell to start the distribution and open a local console:

----
INSTALLATION_HOME/bin/${ddf-branding-lowercase}
----

===== Windows

Run the following script from a console window to start the distribution and open a local console:

----
INSTALLATION_HOME/bin/${branding-lowercase}.bat
----

==== Starting ${branding} as a Service

Alternatively, to run ${branding} as a background service, run the `start` script:

.*NIX
----
<${branding}_HOME/bin/start
----

.Windows
----
<${branding}_HOME>/bin/start.bat
----

[NOTE]
====
If console access is needed while running as a service, run the `client` script:

.*NIX
----
<${branding}_HOME/bin/client
----

.Windows
----
<${branding}_HOME>/bin/client.bat
----
====

==== Stop ${branding}

There are two options:

* Call shutdown from the console:

.Shut down with a prompt
----
${branding-lowercase}${at-symbol}local>shutdown
----

.Force Shutdown without prompt
----
${branding-lowercase}${at-symbol}local>shutdown -f
----

* Keyboard shortcut for shutdown
** `Ctrl`-`D`
** `Cmd`-`D`
* Or run the stop script:

.*NIX
----
${branding}_INSTALL/bin/stop
----

.Windows
----
${branding}_INSTALL/bin/stop.bat
----

.Shut Down
[IMPORTANT]
====
Do not shut down by closing the window (Windows, Unix) or using the `kill -9 <pid>` command (Unix).
This prevents a clean shutdown and can cause significant problems when ${branding} is restarted.
Always use the shutdown command or the shortcut from the command line console.
====

==== Automatic Start on System Boot
// This section needs to be verified. Valid?
Because ${branding} is built on top of Apache Karaf, ${branding} can use the Karaf Wrapper to enable automatic startup and shutdown.

. Create the Karaf wrapper.
+
.Within the ${branding} console
----
${branding-lowercase}${at-symbol}local> feature:install wrapper
${branding-lowercase}${at-symbol}local> wrapper:install -s AUTO_START -n ${ddf-branding-lowercase} -d ${ddf-branding-lowercase} -D "${branding} Service"
----
+
. (Windows users skip to next step) (All *NIX) If ${branding} was installed to run as a non-root user (recommended,) edit `INSTALLATION_HOME/bin/${branding-lowercase}-service`.
+
Change:
+
.INSTALLATION_HOME/bin/${branding-lowercase}-service
----
#RUN_AS_USER=
----
+
to:
+
.INSTALLATION_HOME/bin/${branding-lowercase}-service
----
RUN_AS_USER=<${ddf-branding-lowercase}-user>
----
+
. Set the memory in the wrapper config to match with ${branding} default memory setting and set additional required parameters.
+
.INSTALLATION_HOME/etc/${branding-lowercase}-wrapper.conf
[source,java,linenums]
----
#Add the following:
wrapper.java.additional.10=-D${ddf-branding-lowercase}.home=%KARAF_HOME%
wrapper.java.additional.11=-server
wrapper.java.additional.12=-Djava.security.egd=file:/dev/./urandom
wrapper.java.additional.13=-Dkaraf.instances=%KARAF_HOME%/instances
wrapper.java.additional.14=-Dkaraf.restart.jvm.supported=true
wrapper.java.additional.15=-Djava.io.tmpdir=%KARAF_HOME%/data/tmp
wrapper.java.additional.16=-Djava.util.logging.config.file=%KARAF_HOME%/etc/java.util.logging.properties
wrapper.java.additional.17=-Dfile.encoding=UTF8
wrapper.java.additional.18=-XX:+UnlockDiagnosticVMOptions
wrapper.java.additional.19=-XX:+UnsyncloadClass
wrapper.java.additional.20=-Dderby.system.home=%KARAF_HOME%/data/derby
wrapper.java.additional.21=-Dderby.storage.fileSyncTransactionLog=true

#Update the following:
wrapper.java.maxmemory=2048
----
+
. Set the `${branding}_HOME` property.
+
.INSTALLATION_HOME/etc/${branding-lowercase}-wrapper.conf
----
set.default.${branding}_HOME=%KARAF_HOME%
----
+
. Install the wrapper startup/shutdown scripts.
+
*Windows*
+
Run the following command in a console window. The command must be run with elevated permissions.
+
----
INSTALLATION_HOME/bin/${branding-lowercase}-service.bat install
----
Startup and shutdown settings can then be managed through *Services MMC Start → Control Panel → Administrative Tools → Services*.
+
*Redhat*
+
----
root${at-symbol}localhost# ln -s ${branding}_INSTALL/bin/${branding-lowercase}-service /etc/init.d/
root${at-symbol}localhost# chkconfig ${ddf-branding-lowercase}-service --add
root${at-symbol}localhost# chkconfig ${ddf-branding-lowercase}-service on
----
+
*Ubuntu*
+
----
root${at-symbol}localhost# ln -s ${branding}_INSTALL/bin/${branding-lowercase}-service /etc/init.d/
root${at-symbol}localhost# update-rc.d -f ${ddf-branding-lowercase}-service defaults
----
+
*Solaris*
+
----
root${at-symbol}localhost# ln -s ${branding}_INSTALL/bin/${branding-lowercase}-service /etc/init.d/
root${at-symbol}localhost# ln -s /etc/init.d/${branding-lowercase}-service /etc/rc0.d/K20${ddf-branding-lowercase}-service
root${at-symbol}localhost# ln -s /etc/init.d/${branding-lowercase}-service /etc/rc1.d/K20${ddf-branding-lowercase}-service
root${at-symbol}localhost# ln -s /etc/init.d/${branding-lowercase}-service /etc/rc2.d/K20${ddf-branding-lowercase}-service
root${at-symbol}localhost# ln -s /etc/init.d/${branding-lowercase}-service /etc/rc3.d/S20${ddf-branding-lowercase}-service
----
+
[WARNING]
====
While it is not a necessary step, information on how to convert the System V init scripts to the Solaris System Management Facility can be found at http://www.oracle.com/technetwork/articles/servers-storage-admin/scripts-to-smf-1641705.html
====
+
.Solaris-Specific Modification
[WARNING]
====
Due to a slight difference between the Linux and Solaris implementation of the `ps` command, the `${ddf-branding-lowercase}-service` script needs to be modified.
====
+
. Locate the following line in ${branding}_INSTALL/bin/${branding-lowercase}-service
+
.Solaris ${branding}_INSTALL/bin/${branding-lowercase}-service
----
pidtest=`$PSEXE -p $pid -o command | grep $WRAPPER_CMD | tail -1`
----
+
. Change the word command to comm.
+
.Solaris ${branding}_Install/bin/${branding-lowercase}-service
----
pidtest=`$PSEXE -p $pid -o comm | grep $WRAPPER_CMD | tail -1`
----

===== Karaf Documentation

Because ${branding} is built on Apache Karaf, more information on operating ${branding} can be found in the http://karaf.apache.org/index/documentation.html[Karaf documentation].

====  Managing Applications from ${admin-console}

The *Manage* button enables activation/deactivation and adding/removing applications.

===== Activating / Deactivating Applications

The *Deactivate* button stops individual applications and any dependent apps.
Certain applications are central to overall functionality and cannot be deactivated.
These will have the *Deactivate* button disabled.
Disabled apps will be moved to a list at the bottom of the page, with an enable button to reactivate, if desired.

The *Add Application* button is at the end of the list of currently active applications.

===== Removing Applications

To remove an application, it must first be deactivated.
This enables the *Remove Application* button.

===== Upgrading Applications

Each application tile includes an upgrade button to select a new version to install.

===== System Settings Tab

The configuration and features installed can be viewed and edited from the System tab as well; however, it is recommended that configuration be managed from the applications tab.

[IMPORTANT]
====
In general, applications should be managed via the applications tab.
Configuration via this page could result in an unstable system.
Proceed with caution!
====

==== Federation

It is recommended to use the *${ddf-catalog} App -> Sources* tab to configure and manage sites/sources.

==== Console Commands

Once the distribution has started, users will have access to a powerful command line console, the ${command-console}.
This ${command-console} can be used to manage services, install new features and applications, and manage the state of the system.

===== Access the System Console

The Command Line Console is the console that is available to the user when the distribution is started manually.
It may also be accessed by using the `bin/client.bat` or `bin/client.sh` scripts.
For more information on how to use the `client` scripts or how to remote into the the shell console, see Using Remote Instances.

===== Example Commands

====== View Bundle Status

Call `bundle:list` on the console to view the status of the bundles loaded in the distribution.

====== View Installed Features

Execute `feature:list` to view the features installed in the distribution.

[NOTE]
====
The majority of functionality and information available on the ${admin-console} is also available on the Command Line Console.
====

==== Catalog Commands

[cols="1,1,8" options="header"]
|===
|Title
|Namespace
|Description

|${ddf-branding}:: Catalog :: Core :: Commands
|catalog
|The Catalog Shell Commands are meant to be used with any `CatalogProvider` implementations.
They provide general useful queries and functions against the Catalog API that can be used for debugging, printing, or scripting.

|===

[WARNING]
====
Most commands can bypass the Catalog framework and interact directly with the Catalog provider if given the `--provider` option, if available.
No pre/post plugins are executed and no message validation is performed if the `--provider` option is used.
====

===== Commands

----
catalog:describe     catalog:dump         catalog:envlist      catalog:ingest       catalog:inspect
catalog:latest       catalog:migrate      catalog:range        catalog:remove       catalog:removeall
catalog:replicate    catalog:search       catalog:spatial      catalog:validate
----

.Command Descriptions
[cols="1,9a" options="header"]
|===

|Command
|Description

|`describe`
|Provides a basic description of the Catalog implementation.

|`dump`
|Exports metacards from the local Catalog. Does not remove them. See below for date filtering options.

|`envlist`
|[IMPORTANT]
====
Deprecated as of ddf-catalog 2.5.0. Please use `platform:envlist`.
====

Provides a list of environment variables.

|`ingest`
|Ingests data files into the Catalog.

|`inspect`
|Provides the various fields of a metacard for inspection.

|`latest`
|Retrieves the latest records from the Catalog based on the Metacard.MODIFIED date.

|`migrate`
|Allows two `CatalogProvider`s to be configured and migrates the data from the primary to the secondary.

|`range`
|Searches by the given range arguments (exclusively).

|`remove`
|Deletes a record from the local Catalog.

|`removeall`
|Attempts to delete all records from the local Catalog.

|`replicate`
|Replicates data from a federated source into the local Catalog.

|`search`
|Searches records in the local Catalog.

|`spatial`
|Searches spatially the local Catalog.

|`validate`
|Validates an XML file against all installed validators and prints out human readable errors and warnings.

|===

===== Available System Console Commands

To get a list of commands, type in the namespace of the desired extension then press the *Tab* key.

For example, type `catalog`, then press *Tab*.

===== System Console Command Help

For details on any command, type `help` then the command.
For example, `help search` (see results of this command in the example below).

.Example Help
----
${branding-lowercase}${at-symbol}local>help search
DESCRIPTION
        catalog:search

    Searches records in the Catalog Provider.

SYNTAX
        catalog:search [options] [SEARCH_PHRASE] [NUMBER_OF_ITEMS]

ARGUMENTS
        SEARCH_PHRASE
                Phrase to query the Catalog Provider. Will take precedence over --searchPhrase option.
                (defaults to *)
        NUMBER_OF_ITEMS
                Number of maximum records to display.
                (defaults to -1)

OPTIONS
        --lastMinutes, -min, -minutes
                Option to filter by the last N minutes. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.
        --cache
                Only search cached entries.
        --searchPhrase, -phrase, -like
                Option to filter by a specific phrase. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. --lastXXXX options take precedence over this option.
                (defaults to *)
        --temporal, -dt
                Option to use temporal criteria to filter. The default is to use "keyword like * ".
        --endDate, -end
                Flag to specify a start date range to by which to filter. Dates should be formatted as MM-dd-yyyy such as 06-10-2014.
        --lastMonths, -m, -months
                Option to filter by the last N months. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.
        --temporalProperty, -tp
                Option to select which temporal property by which to filter with --XXXDate and--lastXXXX options. Valid values include, but are not limited to, "modified", "created", "effective", and "expiration". Defaults to "created" if not specified or input not recognized.
        --user, -u
                Run command as a different user.
        --lastWeeks, -w, -weeks
                Option to filter by the last N weeks. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.
        --cql, -cqlFilter
                Option to filter by metacards that match a CQL Filter expression. It is recommended to use the search command (catalog:search) first to see which metacards will be filtered.

                CQL Examples:
                	Textual:   --cql "title like 'some text'"
                	Temporal:  --cql "modified before 2012-09-01T12:30:00Z"
                	Spatial:   --cql "DWITHIN(location, POINT (1 2) , 10, kilometers)"
                	Complex:   --cql "title like 'some text' AND modified before 2012-09-01T12:30:00Z"
        --lastDays, -d, -days
                Option to filter by the last N days. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.
        --lastHours, -h, -hours
                Option to filter by the last N hours. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.
        --startDate, -start
                Flag to specify a start date range to by which to filter. Dates should be formatted as MM-dd-yyyy such as 06-10-2014.
        --caseSensitive, -case
                Option to set the --searchPhrase to be case sensitive.
        --provider, -p, -provider
                Interacts with the provider directly instead of the framework.
        --help
                Display this help message
        --lastSeconds, -sec, -seconds
                Option to filter by the last N seconds. NOTE: Does not apply to CQL filters. Does not stack with other --lastXXXX options. Smaller --lastXXXX time units take precedence over larger time units.

----

The `help` command provides a description of the provided command, along with the syntax in how to use it, arguments it accepts, and available options.

===== `catalog:dump` Options

The `catalog:dump` command provides selective export of metacards based on a filter.
The `--cql` option, the `--startDate` and `--endDate` option, the `--lastXXX` options, and the `--searchPhrase` option, allow filtering on the metacard.
These options are mutually exclusive in the order just listed.

If no filtering options are provided, all metacards will be dumped.

====== Examples

----
${branding-lowercase}${at-symbol}local>// Given we've ingested a few metacards
${branding-lowercase}${at-symbol}local>catalog:latest 3
#       ID                                Modified Date              Title
1       a6e9ae09c792438e92a3c9d7452a449f  2014-06-13T09:56:18+10:00
2       b4aced45103a400da42f3b319e58c3ed  2014-06-13T09:52:12+10:00
3       a63ab22361e14cee9970f5284e8eb4e0  2014-06-13T09:49:36+10:00  myTitle

${branding-lowercase}${at-symbol}local>// CQL textural filter
${branding-lowercase}${at-symbol}local>catalog:dump --cql "title like 'myTitle'" /dump/directory/path
 1 file(s) dumped in 0.015 seconds

${branding-lowercase}${at-symbol}local>// CQL temporal filter
${branding-lowercase}${at-symbol}local>catalog:dump --cql "modified before 2012-09-01T12:30:00Z" /dump/directory/path
 2 file(s) dumped in 0.023 seconds

${branding-lowercase}${at-symbol}local>// CQL spatial filter
${branding-lowercase}${at-symbol}local>catalog:dump --cql "DWITHIN(location, POINT (1 2) , 10, kilometers)" /dump/directory/path
 1 file(s) dumped in 0.020 seconds

${branding-lowercase}${at-symbol}local>// CQL complex filter
${branding-lowercase}${at-symbol}local>catalog:dump --cql " title like 'some text' AND modified before 2012-09-01T12:30:00Z" /dump/directory/path
 1 file(s) dumped in 0.015 seconds

${branding-lowercase}${at-symbol}local>// modified between dates
${branding-lowercase}${at-symbol}local>catalog:dump --temporalProperty modified --startDate 06-10-2014 --endDate 06-10-2014 /dump/directory/path
 1 file(s) dumped in 0.024 seconds

${branding-lowercase}${at-symbol}local>// effective after date
${branding-lowercase}${at-symbol}local>catalog:dump --temporalProperty effective --endDate 06-10-2014 /dump/directory/path
 1 file(s) dumped in 0.018 seconds

${branding-lowercase}${at-symbol}local>// created in last 10 seconds
${branding-lowercase}${at-symbol}local>catalog:dump --temporalProperty created --lastSeconds 10 /dump/directory/path
 2 file(s) dumped in 0.024 seconds

${branding-lowercase}${at-symbol}local>// contains phrase
${branding-lowercase}${at-symbol}local>catalog:dump --searchPhrase “MyTitle” /dump/directory/path
 2 file(s) dumped in 0.020 seconds
${branding-lowercase}${at-symbol}local>catalog:dump --searchPhrase “MyTitle” --caseSensitive /dump/directory/path
 0 file(s) dumped in 0.0 seconds

----

===== Application Commands

Application commands are used from the ${ddf-branding} Admin application to manage applications in the ${branding}.

[NOTE]
====
The Application Commands are installed automatically with the Admin Application.
====

[cols="2,1,4"]
|===

|Title
|Namespace
|Description

|${ddf-branding} :: Admin :: Application Service
|app
|The ${ddf-admin} Application Service contains operations to work with applications.

|===

===== Listing Available System Console Commands

To get a list of commands, type in the namespace of the desired extension and press `<tab>`. For example, type in: `app`, then `<tab>`

[source]
----
${ddf-branding-lowercase}${at-symbol}local>app:
app:add       app:list      app:remove    app:start     app:status    app:stop      app:tree
----

===== Command Descriptions

[cols="1m,1m,5" options="header"]
|===

|Command
|Syntax
|Description

|add
|app:add appUri
|Adds an application with the given uri.

|remove
|app:remove appName
|Removes an application with the given name.

|start
|app:start appName
|Starts an application with the given name.

|stop
|app:stop appName
|Stops an application with the given name.

|list
|app:list
|Lists the applications that are in the system and gives their current state.

|status
|app:status appName
|Shows status of an application.
Gives information on the current state, features within the application, what required features are not started and what required bundles are not started.

|tree
|app:tree
|Creates a hierarchy tree of all of the applications.

|===

===== Command Usage Examples

Listing all applications

[source]
----
${branding-lowercase}${at-symbol}local>app:list
State      Name
[ACTIVE  ] catalog-app-<VERSION>
[ACTIVE  ] distribution-<VERSION>
[ACTIVE  ] platform-app-<VERSION>

[...]
----

This list shows all of the applications installed in ${branding}.
From here, use the name of an application to get more information on its status.

Getting status for a specific application

[source]
----
${ddf-branding-lowercase}${at-symbol}local>app:status catalog-app-<VERSION>
catalog-app-<VERSION>

Current State is: ACTIVE

Features Located within this Application:
    catalog-security-filter
    catalog-transformer-resource
    catalog-rest-endpoint
    abdera
    catalog-transformer-xml
    catalog-transformer-thumbnail
    catalog-transformer-metadata
    catalog-transformer-xsltengine
    catalog-core-fanoutframework
    catalog-transformer-tika
    catalog-core-api
    catalog-opensearch-source
    catalog-plugin-federationreplication
    catalog-opensearch-endpoint
    catalog-schematron-plugin
    catalog-transformer-geoformatter
    catalog-transformer-atom
    catalog-core-sourcemetricsplugin
    catalog-core-metricsplugin
    catalog-app
    catalog-transformer-json
    catalog-core-standardframework
    catalog-core

Required Features Not Started
    NONE

Required Bundles Not Started
    NONE

----

===== Application in Failure State

If an application is an a 'FAILED' state, it means that there is a required feature or bundle that is not started.

[source]
----
${ddf-branding-lowercase}${at-symbol}local>app:list
State      Name
[FAILED  ] catalog-app-<VERSION>
[ACTIVE  ] distribution-<VERSION>
[ACTIVE  ] platform-app-<VERSION>
----

In the above case, the catalog app is in a failure state.
Checking the status of that application will show what did not start correctly.

[source]
----
${ddf-branding-lowercase}${at-symbol}local>app:status catalog-app-<VERSION>
catalog-app-<VERSION>

Current State is: FAILED

Features Located within this Application:
    catalog-security-filter
    catalog-transformer-resource
    catalog-rest-endpoint
    abdera
    catalog-transformer-xml
    catalog-transformer-thumbnail
    catalog-transformer-metadata
    catalog-transformer-xsltengine
    catalog-core-fanoutframework
    catalog-transformer-tika
    catalog-core-api
    catalog-opensearch-source
    catalog-plugin-federationreplication
    catalog-opensearch-endpoint
    catalog-schematron-plugin
    catalog-transformer-geoformatter
    catalog-transformer-atom
    catalog-core-sourcemetricsplugin
    catalog-core-metricsplugin
    catalog-app
    catalog-transformer-json
    catalog-core-standardframework
    catalog-core

Required Features Not Started
    NONE

Required Bundles Not Started
    [261]   catalog-opensearch-endpoint
----

This status shows that bundle #261, the catalog-opensearch-endpoint, did not start. Performing a 'list' on the console verifies this:

[source]
----
[ 261] [Resolved   ] [            ] [       ] [   80] DDF :: Catalog :: OpenSearch :: Endpoint (<VERSION>)
----

Once that bundle is started by fixing its error, the catalog application will show as being in an ACTIVE state.

==== Command Scheduler

Command Scheduler is a capability exposed through the ${admin-console} (\${secure_url}/admin) that allows administrators to schedule Command Line Commands to be run at specified intervals.

===== Using the Command Scheduler

The Command Scheduler allows administrators to schedule Command Line Shell Commands to be run in a "platform-independent" method.
For instance, if an administrator wanted to use the Catalog commands to export all records of a Catalog to a directory, the administrator could write a cron job or a scheduled task to remote into the container and execute the command.
Writing these types of scripts are specific to the administrator's operating system and also requires extra logic for error handling if the container is up.
The administrator can also create a Command Schedule, which currently requires only two fields.
The Command Scheduler only runs when the container is running, so there is no need to verify if the container is up.
In addition, when the container is restarted, the commands are rescheduled and executed again.

====== Schedule a Command

. Navigate to the ${admin-console} (${secure_url}/admin).
. Select *${branding} Platform*
. Select *Platform Command Scheduler*.
. Type the command or commands to be executed in the *Command* text field. Commands can be separated by a semicolon and will execute in order from left to right.
. Type in a positive integer for the *Interval In Seconds* field.
. Select the *Save* button. Once the *Save* button is selected, the command is executed immediately. It's next scheduled execution begins after the amount of seconds specified in the *Interval In Seconds* field and repeats indefinitely until the container is shut down or the scheduled command is deleted.

[NOTE]
====
Scheduled Commands can be updated and deleted.
To delete, clear the fields and click *Save*.
To update, modify the fields and click *Save*.
====

===== Updating a Scheduled Command

. Navigate to the *${admin-console}*.
. Click on the *${ddf-platform}* application.
. Click on the *Configuration* tab.
. Under the *Platform Command Scheduler* configuration are all the scheduled commands.
Scheduled commands have the following syntax `${ddf-branding-lowercase}.platform.scheduler.Command.{GUID}` such as `${ddf-branding-lowercase}.platform.scheduler.Command.4d60c917-003a-42e8-9367-1da0f822ca6e`.
. Find the desired configuration to modify and update either the *Command* text field or the *Interval In Seconds* field or both.
. Click *Save changes*.
Once the Save button has been clicked, the command will be executed immediately.
Its next scheduled execution happens after the time specified in Interval In Seconds and repeats indefinitely until the container is shutdown or the Scheduled Command is deleted.

====== Command Output

Commands that normally write out to the console will write out to the distribution's log.
For example, if an `echo "Hello World"` command is set to run every five seconds, the log displays the following:

.Sample Command Output in the Log
----
16:01:32,582 | INFO  | heduler_Worker-1 | ${ddf-branding-lowercase}.platform.scheduler.CommandJob          68 | platform-scheduler   | Executing command [echo Hello World]
16:01:32,583 | INFO  | heduler_Worker-1 | ${ddf-branding-lowercase}.platform.scheduler.CommandJob          70 | platform-scheduler   | Execution Output: Hello World
16:01:37,581 | INFO  | heduler_Worker-4 | ${ddf-branding-lowercase}.platform.scheduler.CommandJob          68 | platform-scheduler   | Executing command [echo Hello World]
16:01:37,582 | INFO  | heduler_Worker-4 | ${ddf-branding-lowercase}.platform.scheduler.CommandJob          70 | platform-scheduler   | Execution Output: Hello World
----

In short, administrators can view the status of a run within the log as long as INFO was set as the status level.

==== Subscriptions Commands

[cols="3,1,6" options="header"]
|===

|Title
|Namespace
|Description

|`${ddf-branding} :: Catalog :: Core :: PubSub Commands`
|`subscriptions`
|The ${branding} PubSub shell commands provide functions to list the registered subscriptions in ${branding} and to delete subscriptions.

|===

[WARNING]
====
The subscriptions commands are installed when the Catalog application is installed.
====

===== Commands

----
${branding-lowercase}${at-symbol}local>subscriptions:
subscriptions:delete    subscriptions:list
----

===== Command Descriptions

[cols="1,4" options="header"]
|===

|Command
|Description

|`delete`
|Deletes the subscription(s) specified by the search phrase or LDAP filter.

|`list`
|List the subscription(s) specified by the search phrase or LDAP filter.
|===

===== List Available System Console Commands

To get a list of commands, type the namespace of the desired extension the press the Tab key.

For example, type `subscriptions` then press *Tab*.

System Console Command Help
For details on any command type `help` then the subscriptions command.
For example, `help subscriptions:list` displays the data in the following table.

.Example Help
----
${branding-lowercase}${at-symbol}local>help subscriptions:list
DESCRIPTION
        subscriptions:list
        Allows users to view registered subscriptions.
SYNTAX
        subscriptions:list [options] [search phrase or LDAP filter]
ARGUMENTS
        search phrase or LDAP filter
                Subscription ID to search for. Wildcard characters (*) can be used in the ID, e.g., my*name or *123. If an id is not provided, then
                all of the subscriptions are displayed.
OPTIONS
        filter, -f
                Allows user to specify any type of LDAP filter rather than searching on single subscription ID.
                You should enclose the LDAP filter in quotes since it will often have special characters in it.
                An example LDAP filter would be:
                (& (subscription-id=my*) (subscription-id=*169*))
                which searches for all subscriptions starting with "my" and having 169 in the ID, which can be thought of as part of an IP address.
                An example of the entire quote command would be:
                subscriptions:list -f ""(& (subscription-id=my*) (subscription-id=*169*))"
        --help
                Display this help message
----

The `help` command provides a description of the command, along with the syntax on how to use it, arguments it accepts, and available options.

===== `subscriptions:list` Command Usage Examples

Note that no arguments are required for the `subscriptions:list` command.
If no argument is provided, all subscriptions will be listed.
A count of the subscriptions found matching the list command's search phrase (or LDAP filter) is displayed first followed by each subscription's ID.

====== List All Subscriptions

----
${branding-lowercase}${at-symbol}local>subscriptions:list

Total subscriptions found: 3

Subscription ID
my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL
my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification
----

====== List a Specific Subscription by ID

----
${branding-lowercase}${at-symbol}local>subscriptions:list "my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL"

Total subscriptions found: 1

Subscription ID
my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
----

[WARNING]
====
It is recommended to always quote the search phrase (or LDAP filter) argument to the command so that any special characters are properly processed.
====

====== List Subscriptions Using Wildcards

----
${branding-lowercase}${at-symbol}local>subscriptions:list "my*"

Total subscriptions found: 3

Subscription ID
my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL
my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification


${branding-lowercase}${at-symbol}local>subscriptions:list "*json*"

Total subscriptions found: 1

Subscription ID
my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification


${branding-lowercase}${at-symbol}local>subscriptions:list "*WSDL"

Total subscriptions found: 2

Subscription ID
my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL

----

====== List Subscriptions Using an LDAP Filter
The example below illustrates searching for any subscription that has "json" or "v20" anywhere in its subscription ID.

----
${branding-lowercase}${at-symbol}local>subscriptions:list -f "(|(subscription-id=*json*) (subscription-id=*v20*))"

Total subscriptions found: 2

Subscription ID
my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification
----

The example below illustrates searching for any subscription that has `json` and `172.18.14.169` in its subscription ID. This could be a handy way of finding all subscriptions for a specific site.

----
${branding-lowercase}${at-symbol}local>subscriptions:list -f "(&(subscription-id=*json*) (subscription-id=*172.18.14.169*))"

Total subscriptions found: 1

Subscription ID
my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification
----

===== `subscriptions:delete` Command Usage Example

The arguments for the `subscriptions:delete` command are the same as for the `list` command, except that a search phrase or LDAP filter must be specified.
If one of these is not specified an error will be displayed.
When the `delete` command is executed it will display each subscription ID it is deleting.
If a subscription matches the search phrase but cannot be deleted, a message in red will be displayed with the ID.
After all matching subscriptions are processed, a summary line is displayed indicating how many subscriptions were deleted out of how many matching subscriptions were found.

====== Delete a Specific Subscription Using Its Exact ID

----
${branding-lowercase}${at-symbol}local>subscriptions:delete "my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification"

Deleted subscription for ID = my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification

Deleted 1 subscriptions out of 1 subscriptions found.
----

===== Delete Subscriptions Using Wildcards

[source,linenums]
----
${branding-lowercase}${at-symbol}local>subscriptions:delete "my*"

Deleted subscription for ID = my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
Deleted subscription for ID = my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL

Deleted 2 subscriptions out of 2 subscriptions found.

${branding-lowercase}${at-symbol}local>subscriptions:delete "*json*"

Deleted subscription for ID = my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification

Deleted 1 subscriptions out of 1 subscriptions found.
----

===== Delete All Subscriptions

[source,linenums]
----
${branding-lowercase}${at-symbol}local>subscriptions:delete *

Deleted subscription for ID = my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL
Deleted subscription for ID = my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
Deleted subscription for ID = my.contextual.id.json|http://172.18.14.169:8088/services/json/local/event/notification

Deleted 3 subscriptions out of 3 subscriptions found.
----

===== Delete Subscriptions Using an LDAP Filter

----
${branding-lowercase}${at-symbol}local>subscriptions:delete -f "(&(subscription-id=*WSDL) (subscription-id=*172.18.14.169*))"

Deleted subscription for ID = my.contextual.id.v20|http://172.18.14.169:8088/mockCatalogEventConsumerBinding?WSDL
Deleted subscription for ID = my.contextual.id.v30|http://172.18.14.169:8088/mockEventConsumerBinding?WSDL

Deleted 2 subscriptions out of 2 subscriptions found.
----

==== Platform Commands

[cols="2,1,7" options="header"]
|===

|Title
|Namespace
|Description

|${branding} Platform Commands
|`platform`
|The ${branding} Platform Shell Commands provide generic platform management functions

|===

[WARNING]
====
The Platform Commands are installed when the Platform application is installed.
====

===== Commands

====== Command Descriptions

----
${branding-lowercase}${at-symbol}local>platform:
platform:describe    platform:envlist
----

[cols="2" options="header"]
|===

|Command
|Description

|`config-export`
|Exports the current configurations.

|`config-status`
|Lists import status of configuration files.

|`describe`
|Shows the current platform configuration.

|`envlist`
|Provides a list of environment variables.

|===

====== List Available System Console Commands

To view a list of commands, type the namespace of the desired extension and press the *Tab* key.

For example, type *platform* then press *Tab*.

===== System Console Command Help

For details on any command type `help` followed by the platform command.

For example, help `platform:envlist`

===== Example Help

----
${branding-lowercase}${at-symbol}local>help platform:envlist
DESCRIPTION
        platform:envlist

        Provides a list of environment variables

SYNTAX
        platform:envlist [options]

OPTIONS
        --help
                Display this help message
----

The `help` command provides a description of the provided command, along with the syntax in how to use it, arguments it accepts, and available options.

==== Persistence Commands

[cols="2,1,7" options="header"]
|===
|Title
|Namespace
|Description

|${branding}:: Persistence :: Core :: Commands
|store
|The Persistence Shell Commands are meant to be used with any PersistentStore implementations. They provide the ability to query and delete entries from the persistence store.

|===

===== Commands

----
store:delete    store:list
----

====== Command Descriptions

[cols="2,6"]
|===

|Command
|Description

|`delete`
|Delete entries from the persistence store that match a given CQL statement

|`list`
|Lists entries that are stored in the persistence store.

|===

====== Available System Console Commands

To get a list of commands, type in the namespace of the desired extension then press the *Tab* key.

For example, type _store_, then press *Tab*.

===== System Console Command Help

For details on any command, type help then the command.
For example, help `store:list` (see results of this command in the example below).

====== Example Help

----
${branding-lowercase}${at-symbol}local>help store:list
DESCRIPTION
        store:list

    Lists entries that are available in the persistent store.

SYNTAX
        store:list [options]

OPTIONS
        User ID, -u, --user
                User ID to search for notifications. If an id is not provided, then all of the notifications for all users are displayed.
        --help
                Display this help message
        Persistence Type, -t, --type
                Type of item to retrieve from the persistence store.
                Options: metacard, saved_query, notification, task, or workspace
        CQL, -c, --cql
                OGC CQL statement to query the persistence store. Not specifying returns all entries. More information on CQL is available at:
                http://docs.geoserver.org/stable/en/user/tutorials/cql/cql_tutorial.html
----

The `help` command provides a description of the provided command, along with the syntax in how to use it, arguments it accepts, and available options.

==== CQL Syntax

The CQL syntax used should follow the OGC CQL format.
Examples and a description of the grammar is located at http://docs.geoserver.org/stable/en/user/tutorials/cql/cql_tutorial.html[CQL Tutorial].

===== Examples

----
Finding all notifications that were sent due to a download:
${branding-lowercase}${at-symbol}local>store:list --cql "application='Downloads'" --type notification

Deleting a specific notification:
${branding-lowercase}${at-symbol}local>store:delete --cql "id='fdc150b157754138a997fe7143a98cfa'" --type notification
----

==== Ingesting Data

Ingesting is the process of getting metadata into the Catalog Framework.
Ingested files are "transformed" into a neutral format that can be search against as well as migrated to other formats and systems.
There are multiple methods available for ingesting files into the ${branding}.

See <<_file_formats_supported, File Formats Supported>> for details on file formats available and supported by ${branding}.

==== Methods of Ingest

===== Easy (for fewer records or manual ingesting)

====== Ingest command (console)

The ${branding} console application has a command line option for ingesting files

====== Usage

The syntax for the ingest command is `ingest -t <transformer type> <file path>` relative to the installation path.

For XML data, run this command:
----
ingest -t xml examples/metacards/xml
----

====== Directory Monitor

The ${ddf-catalog} application contains a Directory Monitor feature that allows files placed in a single directory to be monitored and ingested automatically.
For more information about configuring a directory to be monitored, consult Directory Monitor.

====== Using Directory Monitor

Simply place the desired files in the monitored directory and it will be ingested automatically.
If, for any reason, the files cannot be ingested, they will be moved to an automatically created sub-folder named `.errors`.
Optionally, ingested files can be automatically moved to a sub-folder called `.ingested`.

===== Medium

====== External Methods

Several third-party tools, such as cURL.exe and the Chrome Advanced Rest Client, can be used to send files and other types of data to ${branding} for ingest.

.Windows Example
----
curl -H "Content-type: application/json;id=geojson" -i -X POST -d ${at-symbol}"C:\path\to\geojson_valid.json" ${secure_url}/services/catalog
----
+
.*NIX Example
----
curl -H "Content-type: application/json;id=geojson" -i -X POST -d ${at-symbol}geojson_valid.json ${secure_url}/services/catalog
----
+
Where:
*-H* adds an HTTP header. In this case, Content-type header `application/json;id=geojson` is added to match the data being sent in the request.
*-i* requests that HTTP headers are displayed in the response.
*-X* specifies the type of HTTP operation. For this example, it is necessary to POST (ingest) data to the server.
*-d* specifies the data sent in the POST request. The `${at-symbol}` character is necessary to specify that the data is a file.
+
The last parameter is the URL of the server that will receive the data.
+
This should return a response similar to the following (the actual catalog ID in the id and Location URL fields will be different):
+
.Sample Response
[source,http,linenums]
----
HTTP/1.1 201 Created
Content-Length: 0
Date: Mon, 22 Apr 2015 22:02:22 GMT
id: 44dc84da101c4f9d9f751e38d9c4d97b
Location: ${secure_url}/services/catalog/44dc84da101c4f9d9f751e38d9c4d97b
Server: Jetty(7.5.4.v20111024)
----
+
. Verify the entry was successfully ingested by entering in a browser the URL returned in the POST response's HTTP header. For instance in our example, it was `/services/catalog/44dc84da101c4f9d9f751e38d9c4d97b`. This should display the catalog entry in XML within the browser.
. Verify the catalog entry exists by executing a query via the OpenSearch endpoint.
. Enter the following URL in a browser /services/catalog/query?q=ddf. A single result, in Atom format, should be returned.

===== Verifying Ingest

. Verify GeoJson file was stored using the Content REST endpoint.
.. Send a GET command to read the content from the content repository using the Content REST endpoint. This can be done using `cURL` command below. Note that the GUID will be different for each ingest. The GUID can be determined by going to the `<DISTRIBUTION_INSTALL_DIR>/content/store` directory and copying the sub-directory in this folder (there should only be one).

.Windows Example
[source,terminal]
----
curl -X GET ${secure_url}/services/content/c90147bf86294d46a9d35ebbd44992c5
----

.*NIX Example
[source,terminal]
----
curl -X GET ${secure_url}/services/content/c90147bf86294d46a9d35ebbd44992c5
----

The response to the GET command will be the contents of the `geojson_valid.json` file originally ingested.

===== Advanced (more records, automated ingest)

The ${branding} provides endpoints for both REST and SOAP services, allowing integration with other data systems and the ability to further automate ingesting data into the catalog.

==== Removing Expired Records from Catalog

${branding} has many ways to remove expired records from the underlying Catalog data store.
Nevertheless, the benefits of data standardization is that an attempt can be made to remove records without the need to know any vendor-specific information.
Whether the data store is a search server, a No-SQL database, or a relational database, expired records can be removed universally using the Catalog API and the Catalog Commands.

===== Universal Expired Records Removal

====== Manual Removal

To manually remove expired records from the Catalog, execute in the Command Line Console,

----
catalog:removeall --expired
----

When prompted, type yes to remove all expired records.

[TIP]
====
For help on the removeall command, execute

`help catalog:removeall`
====

====== Automated Removal

By default, the ${branding} runs a scheduled command every 24 hours to remove expired records.
The command is executed and scheduled <<Using the Command Scheduler>>.
To change the configuration out of the box, follow the <<Updating a Scheduled Command>> instructions.
If an administrator wants to create additional scheduled tasks to remove records from the local Catalog, the administrator can follow the steps provided in the Scheduling a Command section.
In the Command text field, type the following

`catalog:removeall --force --expired`

If it is intended to have this run daily, type 86400 for the amount of seconds.
(60 seconds/min x 60 minutes/hr x 24 hours/day = 86400 seconds for one day)

===== Explanation of Command to Remove Expired Records

The `catalog:removeall` command states you want to remove records from the local Catalog.

The `--force` option is used to suppress the confirmation message which asks a user if the user intentionally wants to permanently remove records from the Catalog.

The `--expired` option is to remove only expired records.

[IMPORTANT]
====
If the `--expired` option is omitted, then all records will be removed from the Catalog.
====

===== Non-Universal or Catalog Specific Removal

Using the Catalog Commands is convenient for achieving many goals such as removing expired records, but is not always the most efficient since not all Catalog implementation details are known.
The Catalog API does not allow for every special nuance of a specific data store.
Therefore, whether an administrator's data store is from Oracle, Solr, or any other vendor, the administrator should consult the specific Catalog implementation's documentation on the best method to remove metadata.
Many specific Catalog implementations might come with their own custom scripts for removing expired metadata such as the SQL scripts provided for the Oracle Catalog implementation.

===== Automatic Catalog Backup

To backup local catalog records.
A backup plugin is disabled by default for performance reasons.
It can be enabled and configured in the:

*${admin-console} -> ${ddf-catalog} -> Configuration -> Backup Post-Ingest Plugin.*

==== Metrics Reporting

Metrics are available in several formats and levels of detail.

Complete the following procedure now that several queries have been executed.

. Select *${branding}-Platform*
. Select *Metrics* tab
. For individual metrics, choose the format desired from the desired timeframe column
.. PNG
.. CSV
.. XLS
. For a detailed report of all metrics, at the bottom of the page are selectors to choose time frame and summary level.
A report is generated in _xls_ format.

==== Monitoring ${branding}

The ${branding} contains many tools to monitor system functionality, usage, and overall system health.

===== Managing Logging

The ${branding} supports a dynamic and customizable logging system including log level, log format, log output destinations, roll over, etc.

====== Configuring Logging

Edit the configuration file `[${branding-lowercase}_install_dir]/etc/org.ops4j.pax.logging.cfg]`

====== ${branding} log file

The name and location of the log file can be changed with the following setting:

`log4j.appender.out.file=<KARAF.DATA>/log/${branding-lowercase}.log`

====== [[controlling_log_level]]Controlling log level

A useful way to debug and detect issues is to change the log level:

`log4j.rootLogger=DEBUG, out, osgi:VmLogAppender`

====== Controlling the size of the log file

Set the maximum size of the log file before it is rolled over by editing the value of this setting:

`log4j.appender.out.maxFileSize=20MB`

====== Number of backup log files to keep

Adjust the number of backup files to keep by editing the value of the of this setting:

`log4j.appender.out.maxBackupIndex=10`

====== Enabling logging of inbound and outbound SOAP messages for the ${branding} SOAP endpoints

By default, the ${branding} start scripts include a system property enabling logging of inbound and outbound SOAP messages.

`-Dcom.sun.xml.ws.transport.http.HttpAdapter.dump=true`

In order to see the messages in the log, one must set the logging level for `org.apache.cxf.services` to `INFO`. By default, the logging level for `org.apache.cxf` is set to `WARN`.

`${branding-lowercase}${at-symbol}local>log:set INFO org.apache.cxf.services`

===== External Resources

Other appenders can be selected and configured.

For more detail on configuring the log file and what is logged to the console a handy reference is `http://karaf.apache.org/manual/latest-2.2.x/users-guide/logging-system.html`

==== Enabling HTTP Access Logging

===== Configuring

To enable access logs for the current ${branding}, do the following:

* Update the `jetty.xml` file located in `etc/` adding the following xml:

[source,xml,linenums]
----
<Get name="handler">
    <Call name="addHandler">
      <Arg>
        <New class="org.eclipse.jetty.server.handler.RequestLogHandler">
          <Set name="requestLog">
            <New id="RequestLogImpl" class="org.eclipse.jetty.server.NCSARequestLog">
              <Arg><SystemProperty name="jetty.logs" default="data/log/"/>/yyyy_mm_dd.request.log</Arg>
              <Set name="retainDays">90</Set>
              <Set name="append">true</Set>
              <Set name="extended">false</Set>
              <Set name="LogTimeZone">GMT</Set>
            </New>
          </Set>
        </New>
      </Arg>
    </Call>
  </Get>
----

Change the location of the logs to the desired location. In the settings above, location will default to data/log (same place where the log is located).

The log is using _National Center for Supercomputing Association Applications (NCSA)_ or Common format (hence the class 'NCSARequestLog').
This is the most popular format for access logs and can be parsed by many web server analytics tools. Here is a sample output:

[source]
----
127.0.0.1 -  -  [14/Jan/2013:16:21:24 +0000] "GET /favicon.ico HTTP/1.1" 200 0
127.0.0.1 -  -  [14/Jan/2013:16:21:33 +0000] "GET /services/ HTTP/1.1" 200 0
127.0.0.1 -  -  [14/Jan/2013:16:21:33 +0000] "GET /services//?stylesheet=1 HTTP/1.1" 200 0
127.0.0.1 -  -  [14/Jan/2013:16:21:33 +0000] "GET /favicon.ico HTTP/1.1" 200 0
----

===== External Resources

http://team.ops4j.org/wiki/display/paxweb/Advanced+Jetty+Configuration[Advanced Jetty Configuration]
http://wiki.eclipse.org/Jetty/Tutorial/RequestLog[Jetty Request Log Tutorial]

===== Using the LogViewer

Monitor system logs with the *LogViewer*, a convenient "viewing portal" for incoming logs.

<<<<<<< HEAD

=======
>>>>>>> master
* Navigate to the LogViewer at \${secure_url}/admin/logviewer

The LogViewer displays the most recent 500 log messages by default, but will grow to a maximum of 5000 messages.

The top left button labeled LIVE/PAUSED will toggle live retrieval of incoming logs from the backend.

Log events can be filtered by:

* Log level (`ERROR`, `WARNING`, etc).
<<<<<<< HEAD
** The LogViewer will display at the currently configured log level for the System logs.
=======
** The LogViewer will display at the currently configured log level for the Karaf logs.
>>>>>>> master
*** See <<controlling_log_level, Controlling Log Level>> to change log level.
* Log message text.
* Bundle generating the message.

[NOTE]
====
The LogViewer settings don't change any of the underlying logging settings, only which messages are displayed.
It does not affect the logs generated or events captured by the system logger.
====

[WARNING]
====
It is not recommended to use the LogViewer if the system logger is set to a low reporting level such as `TRACE`.
The volume of messages logged will exceed the polling rate, and incoming logs may be missed.

Logs may also be missed by the LogViewer if polling is paused for an extended period of time.

The actual logs being polled by the LogViewer can still be accessed at `<INSTALL_HOME>/data/log`
====
